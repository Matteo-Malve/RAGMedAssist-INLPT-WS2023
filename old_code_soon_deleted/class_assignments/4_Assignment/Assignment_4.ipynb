{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be9f7653"
      },
      "source": [
        "**Heidelberg University**\n",
        "\n",
        "**Data Science  Group**\n",
        "    \n",
        "Prof. Dr. Michael Gertz  \n",
        "\n",
        "Ashish Chouhan, Satya Almasian, John Ziegler, Jayson Salazar, Nicolas Reuter\n",
        "    \n",
        "January 16, 2024\n",
        "    \n",
        "Natural Language Processing with Transformers\n",
        "\n",
        "Winter Semster 2023/2024     \n",
        "***"
      ],
      "id": "be9f7653"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "258e9648"
      },
      "source": [
        "# **Assignment 4: Question Answering**\n",
        "**Due**: Monday, January 29, 2024, 2pm, via [Moodle](https://moodle.uni-heidelberg.de/course/view.php?id=19251)\n",
        "\n"
      ],
      "id": "258e9648"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc27ad9e"
      },
      "source": [
        "### **Submission Guidelines**\n",
        "\n",
        "- Solutions need to be uploaded as a **single** Jupyter notebook. You will find several pre-filled code segments in the notebook, your task is to fill in the missing cells.\n",
        "- For the written solution, use LaTeX in markdown inside the same notebook. Do **not** hand in a separate file for it.\n",
        "- Download the .zip file containing the dataset but do **not** upload it with your solution.\n",
        "- It is sufficient if one person per group uploads the solution to Moodle, but make sure that the full names of all team members are given in the notebook.\n",
        "\n",
        "***"
      ],
      "id": "fc27ad9e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HETm7VsBkmLq"
      },
      "source": [
        "## **Task 1: Retrieval Augmented Generation (RAG)** ( 4.5 + 3 + 4 + 3 + 1.5 = 16 points)"
      ],
      "id": "HETm7VsBkmLq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ODkKBIRkrfe"
      },
      "source": [
        "In this task, we look at using the open source `Llama-13b-chat` model for creating a RAG system. You must first apply for access to Llama 2 models via [this](https://ai.meta.com/resources/models-and-libraries/llama-downloads/) form (access is typically granted within a few hours). etrieval augmented generation you also need to request to use the model on Hugging Face by going to the [model](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf) card. ***Note that the emails you provide for your Hugging Face account must match the email you used to request Llama 2.***\n",
        "\n",
        "The final piece that you need is a Hugging Face authentication token. You can find such a token by going to the `setting` in your Hugging Face profile, under the `Access Token` menu you can generate a new token.\n",
        "\n",
        "To store the document you will need a free Pinecone [API key](https://app.pinecone.io/).\n",
        "Make sure you have these pieces ready before starting to work on this task.\n",
        "\n",
        "----\n",
        "When ready, let's start by downloading the necessary packages.\n",
        "\n",
        "It is advised to proceed with this notebook with a GPU (if you are on Colab make sure that a GPU environment is activated.)\n"
      ],
      "id": "0ODkKBIRkrfe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO1OwuHTMo75"
      },
      "source": [
        "Place all the access tokens in the `.env` file and upload it to the working directory (if you are running this notebook locally, you can change the path to fit your working directory). Please use the following format:\n",
        "\n",
        "\n",
        "```\n",
        "HF_AUTH= \"Hugging Face Authentication Key\"\n",
        "PINECONE_API_KEY=\"Pincone API Key\"\n",
        "PINECONE_ENVIRONMENT=\"Pinecone Environment\"\n",
        "```\n",
        "\n",
        "Run the cell below to load the access tokens into the environment variables."
      ],
      "id": "yO1OwuHTMo75"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive\n",
        "\n",
        "#drive.mount('/gdrive')\n",
        "#%cd /gdrive/My Drive/NLPT_Assignment4\n"
      ],
      "metadata": {
        "id": "al0_YMALFu7h"
      },
      "id": "al0_YMALFu7h",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1Dxt-e1bg73b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4874000b-61d4-4f41-8022-c80c80b0d951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "%pip install python-dotenv"
      ],
      "id": "1Dxt-e1bg73b"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EqmnxgpALbVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6418c0d3-8237-4fe8-bd9b-e4005aaa636f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n",
            "ef3c0e05-aa05-48f5-a328-775167493ef1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# load environment variables from .env file\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "print(os.environ.get('HF_AUTH'))\n",
        "print(os.environ.get('PINECONE_API_KEY'))"
      ],
      "id": "EqmnxgpALbVV"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pinecone-client==2.2.4\n",
        "#%pip install -U pinecone-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExAvvcR92AbI",
        "outputId": "98ef489a-d587-4d40-fdc1-ace088c5f622"
      },
      "id": "ExAvvcR92AbI",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pinecone-client==2.2.4\n",
            "  Downloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (6.0.1)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client==2.2.4)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (4.5.0)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client==2.2.4)\n",
            "  Downloading dnspython-2.5.0-py3-none-any.whl (305 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.4/305.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client==2.2.4) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client==2.2.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client==2.2.4) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client==2.2.4) (2023.11.17)\n",
            "Installing collected packages: loguru, dnspython, pinecone-client\n",
            "Successfully installed dnspython-2.5.0 loguru-0.7.2 pinecone-client-2.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yE3EOlhTrKo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4280088-c672-4804-d2f6-1ba03aa7be7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting litellm\n",
            "  Downloading litellm-1.18.9-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from litellm) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (7.0.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm) (3.1.3)\n",
            "Collecting openai>=1.0.0 (from litellm)\n",
            "  Downloading openai-1.9.0-py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (1.0.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (2.31.0)\n",
            "Collecting tiktoken>=0.4.0 (from litellm)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm) (0.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm) (2.1.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0.0->litellm) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.0.0->litellm) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.0.0->litellm)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0.0->litellm) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.0.0->litellm) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0.0->litellm) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai>=1.0.0->litellm)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm) (2023.11.17)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.4.0->litellm) (2023.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (4.0.3)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->litellm) (0.20.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.0.0->litellm) (1.2.0)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.0.0->litellm)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->litellm)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (23.2)\n",
            "Installing collected packages: typing-extensions, h11, tiktoken, httpcore, httpx, openai, litellm\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 litellm-1.18.9 openai-1.9.0 tiktoken-0.5.2 typing-extensions-4.9.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m638.4/638.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.5/229.5 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.8/680.8 kB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.4/635.4 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for millify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=b6319202a7fd01cafe65400a7756f7d62bcc11c36b48897e0c36b16b24b1bfff\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (2.2.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (6.0.1)\n",
            "Requirement already satisfied: loguru>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (0.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.9.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2023.11.17)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: multiprocess, datasets\n",
            "Successfully installed datasets-2.16.1 multiprocess-0.70.15\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.26.1\n",
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.14 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.14)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.14 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.14)\n",
            "Requirement already satisfied: langsmith<0.0.84,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.5.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.14->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.14->langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.14->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.14->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Collecting xformers\n",
            "  Downloading xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.23.5)\n",
            "Collecting torch==2.1.2 (from xformers)\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m807.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2->xformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->xformers) (2.1.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->xformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2->xformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2->xformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.1.2 xformers-0.0.23.post1\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->bitsandbytes) (1.23.5)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.42.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.4.22-py3-none-any.whl (509 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.0/509.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.0.3)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.5.3)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.109.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.5)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.3.2-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.9.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.22.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.22.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.22.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.6.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.1)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.60.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.35.1)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.17.3)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
            "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.22.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.22.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.22.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.22.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.43b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.14.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.36.0,>=0.35.0->fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.36.0,>=0.35.0->fastapi>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.36.0,>=0.35.0->fastapi>=0.95.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=782bcfb901edd4fcb3d5b9a190ef746075f9e6656a1728cb9afa87fe442db2a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, pulsar-client, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, humanfriendly, httptools, chroma-hnswlib, bcrypt, asgiref, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "Successfully installed asgiref-3.7.2 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.22 coloredlogs-15.0.1 httptools-0.6.1 humanfriendly-10.0 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.16.3 opentelemetry-api-1.22.0 opentelemetry-exporter-otlp-proto-common-1.22.0 opentelemetry-exporter-otlp-proto-grpc-1.22.0 opentelemetry-instrumentation-0.43b0 opentelemetry-instrumentation-asgi-0.43b0 opentelemetry-instrumentation-fastapi-0.43b0 opentelemetry-proto-1.22.0 opentelemetry-sdk-1.22.0 opentelemetry-semantic-conventions-0.43b0 opentelemetry-util-http-0.43b0 overrides-7.6.0 posthog-3.3.2 pulsar-client-3.4.0 pypika-0.48.9 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: responses, evaluate\n",
            "Successfully installed evaluate-0.4.1 responses-0.18.0\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.23.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=5ac8650986783b0f85b0a889d28831984cf9b9e3031ccc53815597bfbd731b7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.1.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.5.3)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.35.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.66.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert_score) (12.3.101)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.20.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert_score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Installing collected packages: bert_score\n",
            "Successfully installed bert_score-0.3.13\n"
          ]
        }
      ],
      "source": [
        "%pip install litellm\n",
        "%pip install -qU trulens_eval pydantic fastapi kaleido python-multipart uvicorn cohere openai tiktoken \"llama-index\"\n",
        "%pip install transformers\n",
        "%pip install sentence-transformers\n",
        "%pip install pinecone-client\n",
        "%pip install datasets\n",
        "%pip install accelerate\n",
        "%pip install einops\n",
        "%pip install langchain\n",
        "%pip install xformers\n",
        "%pip install bitsandbytes\n",
        "%pip install matplotlib seaborn tqdm\n",
        "%pip install chromadb\n",
        "%pip install evaluate\n",
        "%pip install rouge_score\n",
        "%pip install bert_score"
      ],
      "id": "yE3EOlhTrKo6"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "has_gpu = torch.cuda.is_available()\n",
        "has_mps = torch.backends.mps.is_built()\n",
        "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnOGtWWJbc32",
        "outputId": "7b918116-444c-4395-ff48-5d42e5782235"
      },
      "id": "fnOGtWWJbc32",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLDAPMVST2Ds"
      },
      "source": [
        "\n",
        "\n",
        "## Subtask 1.1: Data Preparation\n",
        "\n"
      ],
      "id": "dLDAPMVST2Ds"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b9odZyFLDin"
      },
      "source": [
        "We need a collection of documents to perform our retrieval on. To make it closer to your final project, you will be downloading and using a subset of the LangChain documentation. We get some of the `.html` files located on the site. The code below will download all HTML files from the links on the webpage into a `docs` directory. `-l1` limits the download to only the first level of depth.\n"
      ],
      "id": "9b9odZyFLDin"
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "JXe86ZKVFfrm"
      },
      "id": "JXe86ZKVFfrm",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qiodFLkaLUsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0758af9b-d2c3-44a5-d8b5-3dfe844e3c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-23 08:22:21--  https://api.python.langchain.com/en/stable/langchain_api_reference.html\n",
            "Resolving api.python.langchain.com (api.python.langchain.com)... 104.17.33.82, 104.17.32.82, 2606:4700::6811:2152, ...\n",
            "Connecting to api.python.langchain.com (api.python.langchain.com)|104.17.33.82|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/langchain_api_reference.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 256.55K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-01-23 08:22:21 (9.86 MB/s) - ‘docs/api.python.langchain.com/en/stable/langchain_api_reference.html’ saved [262709]\n",
            "\n",
            "Loading robots.txt; please ignore errors.\n",
            "--2024-01-23 08:22:21--  https://api.python.langchain.com/robots.txt\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 130 [text/plain]\n",
            "Saving to: ‘docs/api.python.langchain.com/robots.txt.tmp’\n",
            "\n",
            "api.python.langchai 100%[===================>]     130  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:21 (71.0 MB/s) - ‘docs/api.python.langchain.com/robots.txt.tmp’ saved [130/130]\n",
            "\n",
            "Removing docs/api.python.langchain.com/robots.txt.tmp.\n",
            "--2024-01-23 08:22:21--  https://api.python.langchain.com/en/latest/langchain_api_reference.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/latest/langchain_api_reference.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 253.37K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2024-01-23 08:22:21 (28.9 MB/s) - ‘docs/api.python.langchain.com/en/latest/langchain_api_reference.html’ saved [259449]\n",
            "\n",
            "--2024-01-23 08:22:21--  https://api.python.langchain.com/en/stable/core_api_reference.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/core_api_reference.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 171.08K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:21 (32.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/core_api_reference.html’ saved [175186]\n",
            "\n",
            "--2024-01-23 08:22:21--  https://api.python.langchain.com/en/stable/community_api_reference.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/community_api_reference.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 664.56K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-01-23 08:22:22 (32.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/community_api_reference.html’ saved [680512]\n",
            "\n",
            "--2024-01-23 08:22:22--  https://api.python.langchain.com/en/stable/experimental_api_reference.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/experimental_api_reference.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 129.77K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:22:22 (35.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/experimental_api_reference.html’ saved [132886]\n",
            "\n",
            "--2024-01-23 08:22:22--  https://api.python.langchain.com/en/stable/google_genai_api_reference.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/google_genai_api_reference.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  15.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:22 (234 MB/s) - ‘docs/api.python.langchain.com/en/stable/google_genai_api_reference.html’ saved [15539]\n",
            "\n",
            "--2024-01-23 08:22:22--  https://api.python.langchain.com/en/stable/anthropic_api_reference.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/anthropic_api_reference.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.35K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:23 (149 MB/s) - ‘docs/api.python.langchain.com/en/stable/anthropic_api_reference.html’ saved [11623]\n",
            "\n",
            "--2024-01-23 08:22:23--  https://api.python.langchain.com/en/stable/nvidia_trt_api_reference.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/nvidia_trt_api_reference.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:23 (217 MB/s) - ‘docs/api.python.langchain.com/en/stable/nvidia_trt_api_reference.html’ saved [12456]\n",
            "\n",
            "--2024-01-23 08:22:23--  https://api.python.langchain.com/en/stable/mistralai_api_reference.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/mistralai_api_reference.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.79K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:23 (183 MB/s) - ‘docs/api.python.langchain.com/en/stable/mistralai_api_reference.html’ saved [12070]\n",
            "\n",
            "--2024-01-23 08:22:23--  https://api.python.langchain.com/en/stable/together_api_reference.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/together_api_reference.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  10.95K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:23 (163 MB/s) - ‘docs/api.python.langchain.com/en/stable/together_api_reference.html’ saved [11208]\n",
            "\n",
            "--2024-01-23 08:22:23--  https://api.python.langchain.com/en/stable/nvidia_ai_endpoints_api_reference.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/nvidia_ai_endpoints_api_reference.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:23 (192 MB/s) - ‘docs/api.python.langchain.com/en/stable/nvidia_ai_endpoints_api_reference.html’ saved [13446]\n",
            "\n",
            "--2024-01-23 08:22:23--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent.Agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.Agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  58.94K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:22:24 (23.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.Agent.html’ saved [60351]\n",
            "\n",
            "--2024-01-23 08:22:24--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent.AgentExecutor.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.AgentExecutor.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 179.57K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:24 (33.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.AgentExecutor.html’ saved [183881]\n",
            "\n",
            "--2024-01-23 08:22:24--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent.AgentOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.AgentOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 123.14K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:22:24 (46.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.AgentOutputParser.html’ saved [126099]\n",
            "\n",
            "--2024-01-23 08:22:24--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent.BaseMultiActionAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.BaseMultiActionAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  49.49K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:22:24 (22.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.BaseMultiActionAgent.html’ saved [50677]\n",
            "\n",
            "--2024-01-23 08:22:24--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent.BaseSingleActionAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.BaseSingleActionAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  52.27K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:24 (50.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.BaseSingleActionAgent.html’ saved [53526]\n",
            "\n",
            "--2024-01-23 08:22:24--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent.ExceptionTool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.ExceptionTool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 138.25K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:22:24 (31.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.ExceptionTool.html’ saved [141565]\n",
            "\n",
            "--2024-01-23 08:22:24--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent.LLMSingleActionAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.LLMSingleActionAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  55.49K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:25 (108 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.LLMSingleActionAgent.html’ saved [56817]\n",
            "\n",
            "--2024-01-23 08:22:25--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent.MultiActionAgentOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.MultiActionAgentOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 123.67K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:22:25 (30.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.MultiActionAgentOutputParser.html’ saved [126640]\n",
            "\n",
            "--2024-01-23 08:22:25--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent.RunnableAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.RunnableAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  52.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:25 (226 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.RunnableAgent.html’ saved [54182]\n",
            "\n",
            "--2024-01-23 08:22:25--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent.RunnableMultiActionAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.RunnableMultiActionAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  51.14K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:25 (44.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent.RunnableMultiActionAgent.html’ saved [52367]\n",
            "\n",
            "--2024-01-23 08:22:25--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent_iterator.AgentExecutorIterator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_iterator.AgentExecutorIterator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.32K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:26 (66.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_iterator.AgentExecutorIterator.html’ saved [26948]\n",
            "\n",
            "--2024-01-23 08:22:26--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.toolkit.VectorStoreInfo.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.toolkit.VectorStoreInfo.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  41.05K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:26 (48.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.toolkit.VectorStoreInfo.html’ saved [42032]\n",
            "\n",
            "--2024-01-23 08:22:26--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.toolkit.VectorStoreRouterToolkit.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.toolkit.VectorStoreRouterToolkit.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  42.60K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:26 (44.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.toolkit.VectorStoreRouterToolkit.html’ saved [43621]\n",
            "\n",
            "--2024-01-23 08:22:26--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.toolkit.VectorStoreToolkit.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.toolkit.VectorStoreToolkit.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  42.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:26 (88.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.toolkit.VectorStoreToolkit.html’ saved [43244]\n",
            "\n",
            "--2024-01-23 08:22:26--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent_types.AgentType.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_types.AgentType.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.59K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:26 (81.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_types.AgentType.html’ saved [30303]\n",
            "\n",
            "--2024-01-23 08:22:26--  https://api.python.langchain.com/en/stable/agents/langchain.agents.chat.base.ChatAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.chat.base.ChatAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  71.35K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:22:27 (43.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.chat.base.ChatAgent.html’ saved [73067]\n",
            "\n",
            "--2024-01-23 08:22:27--  https://api.python.langchain.com/en/stable/agents/langchain.agents.chat.output_parser.ChatOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.chat.output_parser.ChatOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 123.71K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:22:27 (39.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.chat.output_parser.ChatOutputParser.html’ saved [126680]\n",
            "\n",
            "--2024-01-23 08:22:27--  https://api.python.langchain.com/en/stable/agents/langchain.agents.conversational.base.ConversationalAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.conversational.base.ConversationalAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  82.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:27 (174 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.conversational.base.ConversationalAgent.html’ saved [84735]\n",
            "\n",
            "--2024-01-23 08:22:27--  https://api.python.langchain.com/en/stable/agents/langchain.agents.conversational.output_parser.ConvoOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.conversational.output_parser.ConvoOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 125.16K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:22:27 (33.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.conversational.output_parser.ConvoOutputParser.html’ saved [128160]\n",
            "\n",
            "--2024-01-23 08:22:27--  https://api.python.langchain.com/en/stable/agents/langchain.agents.conversational_chat.base.ConversationalChatAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.conversational_chat.base.ConversationalChatAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  81.03K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:22:27 (35.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.conversational_chat.base.ConversationalChatAgent.html’ saved [82973]\n",
            "\n",
            "--2024-01-23 08:22:27--  https://api.python.langchain.com/en/stable/agents/langchain.agents.conversational_chat.output_parser.ConvoOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.conversational_chat.output_parser.ConvoOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 125.20K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:22:27 (37.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.conversational_chat.output_parser.ConvoOutputParser.html’ saved [128209]\n",
            "\n",
            "--2024-01-23 08:22:27--  https://api.python.langchain.com/en/stable/agents/langchain.agents.mrkl.base.ChainConfig.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.mrkl.base.ChainConfig.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  15.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:28 (311 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.mrkl.base.ChainConfig.html’ saved [15826]\n",
            "\n",
            "--2024-01-23 08:22:28--  https://api.python.langchain.com/en/stable/agents/langchain.agents.mrkl.base.MRKLChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.mrkl.base.MRKLChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 177.32K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:28 (36.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.mrkl.base.MRKLChain.html’ saved [181573]\n",
            "\n",
            "--2024-01-23 08:22:28--  https://api.python.langchain.com/en/stable/agents/langchain.agents.mrkl.base.ZeroShotAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.mrkl.base.ZeroShotAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  68.16K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:22:28 (41.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.mrkl.base.ZeroShotAgent.html’ saved [69792]\n",
            "\n",
            "--2024-01-23 08:22:28--  https://api.python.langchain.com/en/stable/agents/langchain.agents.mrkl.output_parser.MRKLOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.mrkl.output_parser.MRKLOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 123.01K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:22:28 (38.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.mrkl.output_parser.MRKLOutputParser.html’ saved [125967]\n",
            "\n",
            "--2024-01-23 08:22:28--  https://api.python.langchain.com/en/stable/agents/langchain.agents.openai_assistant.base.OpenAIAssistantAction.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_assistant.base.OpenAIAssistantAction.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  51.32K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:28 (53.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_assistant.base.OpenAIAssistantAction.html’ saved [52552]\n",
            "\n",
            "--2024-01-23 08:22:28--  https://api.python.langchain.com/en/stable/agents/langchain.agents.openai_assistant.base.OpenAIAssistantFinish.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_assistant.base.OpenAIAssistantFinish.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  49.71K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:32 (280 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_assistant.base.OpenAIAssistantFinish.html’ saved [50903]\n",
            "\n",
            "--2024-01-23 08:22:32--  https://api.python.langchain.com/en/stable/agents/langchain.agents.openai_assistant.base.OpenAIAssistantRunnable.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_assistant.base.OpenAIAssistantRunnable.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 136.40K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:33 (27.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_assistant.base.OpenAIAssistantRunnable.html’ saved [139670]\n",
            "\n",
            "--2024-01-23 08:22:33--  https://api.python.langchain.com/en/stable/agents/langchain.agents.openai_functions_agent.agent_token_buffer_memory.AgentTokenBufferMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_functions_agent.agent_token_buffer_memory.AgentTokenBufferMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  60.18K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:33 (44.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_functions_agent.agent_token_buffer_memory.AgentTokenBufferMemory.html’ saved [61629]\n",
            "\n",
            "--2024-01-23 08:22:33--  https://api.python.langchain.com/en/stable/agents/langchain.agents.openai_functions_agent.base.OpenAIFunctionsAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_functions_agent.base.OpenAIFunctionsAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  63.42K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:22:33 (36.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_functions_agent.base.OpenAIFunctionsAgent.html’ saved [64941]\n",
            "\n",
            "--2024-01-23 08:22:33--  https://api.python.langchain.com/en/stable/agents/langchain.agents.openai_functions_multi_agent.base.OpenAIMultiFunctionsAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_functions_multi_agent.base.OpenAIMultiFunctionsAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  63.06K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:33 (45.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_functions_multi_agent.base.OpenAIMultiFunctionsAgent.html’ saved [64572]\n",
            "\n",
            "--2024-01-23 08:22:33--  https://api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.json.JSONAgentOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.json.JSONAgentOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 124.26K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:22:33 (29.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.json.JSONAgentOutputParser.html’ saved [127239]\n",
            "\n",
            "--2024-01-23 08:22:33--  https://api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.openai_functions.OpenAIFunctionsAgentOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.openai_functions.OpenAIFunctionsAgentOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 128.23K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:22:33 (36.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.openai_functions.OpenAIFunctionsAgentOutputParser.html’ saved [131304]\n",
            "\n",
            "--2024-01-23 08:22:33--  https://api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.openai_tools.OpenAIToolAgentAction.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.openai_tools.OpenAIToolAgentAction.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  51.67K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:34 (44.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.openai_tools.OpenAIToolAgentAction.html’ saved [52907]\n",
            "\n",
            "--2024-01-23 08:22:34--  https://api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.openai_tools.OpenAIToolsAgentOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.openai_tools.OpenAIToolsAgentOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 127.64K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:22:34 (39.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.openai_tools.OpenAIToolsAgentOutputParser.html’ saved [130708]\n",
            "\n",
            "--2024-01-23 08:22:34--  https://api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.react_json_single_input.ReActJsonSingleInputOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.react_json_single_input.ReActJsonSingleInputOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 129.59K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:22:34 (33.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.react_json_single_input.ReActJsonSingleInputOutputParser.html’ saved [132702]\n",
            "\n",
            "--2024-01-23 08:22:34--  https://api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.react_single_input.ReActSingleInputOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.react_single_input.ReActSingleInputOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 127.70K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:22:34 (36.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.react_single_input.ReActSingleInputOutputParser.html’ saved [130767]\n",
            "\n",
            "--2024-01-23 08:22:34--  https://api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.self_ask.SelfAskOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.self_ask.SelfAskOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 126.88K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:22:34 (35.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.self_ask.SelfAskOutputParser.html’ saved [129922]\n",
            "\n",
            "--2024-01-23 08:22:34--  https://api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.xml.XMLAgentOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.xml.XMLAgentOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 124.38K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:22:34 (38.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.xml.XMLAgentOutputParser.html’ saved [127360]\n",
            "\n",
            "--2024-01-23 08:22:34--  https://api.python.langchain.com/en/stable/agents/langchain.agents.react.base.DocstoreExplorer.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.react.base.DocstoreExplorer.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  15.60K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:34 (27.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.react.base.DocstoreExplorer.html’ saved [15978]\n",
            "\n",
            "--2024-01-23 08:22:34--  https://api.python.langchain.com/en/stable/agents/langchain.agents.react.base.ReActChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.react.base.ReActChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 174.77K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:34 (33.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.react.base.ReActChain.html’ saved [178962]\n",
            "\n",
            "--2024-01-23 08:22:34--  https://api.python.langchain.com/en/stable/agents/langchain.agents.react.base.ReActDocstoreAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.react.base.ReActDocstoreAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  58.35K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:34 (39.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.react.base.ReActDocstoreAgent.html’ saved [59750]\n",
            "\n",
            "--2024-01-23 08:22:34--  https://api.python.langchain.com/en/stable/agents/langchain.agents.react.base.ReActTextWorldAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.react.base.ReActTextWorldAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  58.47K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:34 (51.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.react.base.ReActTextWorldAgent.html’ saved [59870]\n",
            "\n",
            "--2024-01-23 08:22:34--  https://api.python.langchain.com/en/stable/agents/langchain.agents.react.output_parser.ReActOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.react.output_parser.ReActOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 123.06K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:22:34 (34.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.react.output_parser.ReActOutputParser.html’ saved [126012]\n",
            "\n",
            "--2024-01-23 08:22:34--  https://api.python.langchain.com/en/stable/agents/langchain.agents.schema.AgentScratchPadChatPromptTemplate.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.schema.AgentScratchPadChatPromptTemplate.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 146.16K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:22:35 (51.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.schema.AgentScratchPadChatPromptTemplate.html’ saved [149668]\n",
            "\n",
            "--2024-01-23 08:22:35--  https://api.python.langchain.com/en/stable/agents/langchain.agents.self_ask_with_search.base.SelfAskWithSearchAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.self_ask_with_search.base.SelfAskWithSearchAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  59.60K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:35 (192 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.self_ask_with_search.base.SelfAskWithSearchAgent.html’ saved [61029]\n",
            "\n",
            "--2024-01-23 08:22:35--  https://api.python.langchain.com/en/stable/agents/langchain.agents.self_ask_with_search.base.SelfAskWithSearchChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.self_ask_with_search.base.SelfAskWithSearchChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 179.12K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:35 (33.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.self_ask_with_search.base.SelfAskWithSearchChain.html’ saved [183424]\n",
            "\n",
            "--2024-01-23 08:22:35--  https://api.python.langchain.com/en/stable/agents/langchain.agents.structured_chat.base.StructuredChatAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.structured_chat.base.StructuredChatAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  72.52K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:22:42 (37.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.structured_chat.base.StructuredChatAgent.html’ saved [74259]\n",
            "\n",
            "--2024-01-23 08:22:42--  https://api.python.langchain.com/en/stable/agents/langchain.agents.structured_chat.output_parser.StructuredChatOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.structured_chat.output_parser.StructuredChatOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 125.62K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:22:42 (35.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.structured_chat.output_parser.StructuredChatOutputParser.html’ saved [128640]\n",
            "\n",
            "--2024-01-23 08:22:42--  https://api.python.langchain.com/en/stable/agents/langchain.agents.structured_chat.output_parser.StructuredChatOutputParserWithRetries.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.structured_chat.output_parser.StructuredChatOutputParserWithRetries.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 131.83K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:22:43 (38.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.structured_chat.output_parser.StructuredChatOutputParserWithRetries.html’ saved [134995]\n",
            "\n",
            "--2024-01-23 08:22:43--  https://api.python.langchain.com/en/stable/agents/langchain.agents.tools.InvalidTool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.tools.InvalidTool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 138.99K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:22:43 (32.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.tools.InvalidTool.html’ saved [142321]\n",
            "\n",
            "--2024-01-23 08:22:43--  https://api.python.langchain.com/en/stable/agents/langchain.agents.xml.base.XMLAgent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.xml.base.XMLAgent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  55.30K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:43 (44.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.xml.base.XMLAgent.html’ saved [56627]\n",
            "\n",
            "--2024-01-23 08:22:43--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.conversational_retrieval.openai_functions.create_conversational_retrieval_agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.conversational_retrieval.openai_functions.create_conversational_retrieval_agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:43 (61.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.conversational_retrieval.openai_functions.create_conversational_retrieval_agent.html’ saved [17015]\n",
            "\n",
            "--2024-01-23 08:22:43--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.base.create_vectorstore_agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.base.create_vectorstore_agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.31K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:43 (60.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.base.create_vectorstore_agent.html’ saved [19778]\n",
            "\n",
            "--2024-01-23 08:22:43--  https://api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.base.create_vectorstore_router_agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.base.create_vectorstore_router_agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:44 (53.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.agent_toolkits.vectorstore.base.create_vectorstore_router_agent.html’ saved [19661]\n",
            "\n",
            "--2024-01-23 08:22:44--  https://api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.log.format_log_to_str.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.log.format_log_to_str.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.37K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:44 (237 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.log.format_log_to_str.html’ saved [12666]\n",
            "\n",
            "--2024-01-23 08:22:44--  https://api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.log_to_messages.format_log_to_messages.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.log_to_messages.format_log_to_messages.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.45K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:44 (140 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.log_to_messages.format_log_to_messages.html’ saved [12752]\n",
            "\n",
            "--2024-01-23 08:22:44--  https://api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.openai_functions.format_to_openai_function_messages.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.openai_functions.format_to_openai_function_messages.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:44 (117 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.openai_functions.format_to_openai_function_messages.html’ saved [12833]\n",
            "\n",
            "--2024-01-23 08:22:44--  https://api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.openai_functions.format_to_openai_functions.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.openai_functions.format_to_openai_functions.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:45 (110 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.openai_functions.format_to_openai_functions.html’ saved [12540]\n",
            "\n",
            "--2024-01-23 08:22:45--  https://api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.openai_tools.format_to_openai_tool_messages.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.openai_tools.format_to_openai_tool_messages.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.45K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:45 (165 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.openai_tools.format_to_openai_tool_messages.html’ saved [12745]\n",
            "\n",
            "--2024-01-23 08:22:45--  https://api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.xml.format_xml.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.xml.format_xml.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.73K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:45 (162 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.format_scratchpad.xml.format_xml.html’ saved [12009]\n",
            "\n",
            "--2024-01-23 08:22:45--  https://api.python.langchain.com/en/stable/agents/langchain.agents.initialize.initialize_agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.initialize.initialize_agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.76K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:45 (41.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.initialize.initialize_agent.html’ saved [28428]\n",
            "\n",
            "--2024-01-23 08:22:45--  https://api.python.langchain.com/en/stable/agents/langchain.agents.json_chat.base.create_json_chat_agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.json_chat.base.create_json_chat_agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:45 (157 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.json_chat.base.create_json_chat_agent.html’ saved [16412]\n",
            "\n",
            "--2024-01-23 08:22:45--  https://api.python.langchain.com/en/stable/agents/langchain.agents.load_tools.get_all_tool_names.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.load_tools.get_all_tool_names.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  10.83K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:46 (132 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.load_tools.get_all_tool_names.html’ saved [11090]\n",
            "\n",
            "--2024-01-23 08:22:46--  https://api.python.langchain.com/en/stable/agents/langchain.agents.load_tools.load_huggingface_tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.load_tools.load_huggingface_tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.54K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:46 (171 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.load_tools.load_huggingface_tool.html’ saved [13862]\n",
            "\n",
            "--2024-01-23 08:22:46--  https://api.python.langchain.com/en/stable/agents/langchain.agents.load_tools.load_tools.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.load_tools.load_tools.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.03K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:46 (14.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.load_tools.load_tools.html’ saved [22562]\n",
            "\n",
            "--2024-01-23 08:22:46--  https://api.python.langchain.com/en/stable/agents/langchain.agents.loading.load_agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.loading.load_agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.29K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:46 (88.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.loading.load_agent.html’ saved [12590]\n",
            "\n",
            "--2024-01-23 08:22:46--  https://api.python.langchain.com/en/stable/agents/langchain.agents.loading.load_agent_from_config.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.loading.load_agent_from_config.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.81K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:47 (247 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.loading.load_agent_from_config.html’ saved [14139]\n",
            "\n",
            "--2024-01-23 08:22:47--  https://api.python.langchain.com/en/stable/agents/langchain.agents.openai_functions_agent.base.create_openai_functions_agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_functions_agent.base.create_openai_functions_agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.39K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:47 (49.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_functions_agent.base.create_openai_functions_agent.html’ saved [16779]\n",
            "\n",
            "--2024-01-23 08:22:47--  https://api.python.langchain.com/en/stable/agents/langchain.agents.openai_tools.base.create_openai_tools_agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_tools.base.create_openai_tools_agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:47 (36.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.openai_tools.base.create_openai_tools_agent.html’ saved [16403]\n",
            "\n",
            "--2024-01-23 08:22:47--  https://api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.openai_tools.parse_ai_message_to_openai_tool_action.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.openai_tools.parse_ai_message_to_openai_tool_action.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:47 (152 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.output_parsers.openai_tools.parse_ai_message_to_openai_tool_action.html’ saved [12473]\n",
            "\n",
            "--2024-01-23 08:22:47--  https://api.python.langchain.com/en/stable/agents/langchain.agents.react.agent.create_react_agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.react.agent.create_react_agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  15.58K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:47 (52.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.react.agent.create_react_agent.html’ saved [15953]\n",
            "\n",
            "--2024-01-23 08:22:47--  https://api.python.langchain.com/en/stable/agents/langchain.agents.self_ask_with_search.base.create_self_ask_with_search_agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.self_ask_with_search.base.create_self_ask_with_search_agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  15.34K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:48 (38.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.self_ask_with_search.base.create_self_ask_with_search_agent.html’ saved [15706]\n",
            "\n",
            "--2024-01-23 08:22:48--  https://api.python.langchain.com/en/stable/agents/langchain.agents.structured_chat.base.create_structured_chat_agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.structured_chat.base.create_structured_chat_agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:48 (35.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.structured_chat.base.create_structured_chat_agent.html’ saved [16551]\n",
            "\n",
            "--2024-01-23 08:22:48--  https://api.python.langchain.com/en/stable/agents/langchain.agents.utils.validate_tools_single_input.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.utils.validate_tools_single_input.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:48 (155 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.utils.validate_tools_single_input.html’ saved [11706]\n",
            "\n",
            "--2024-01-23 08:22:48--  https://api.python.langchain.com/en/stable/agents/langchain.agents.xml.base.create_xml_agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.xml.base.create_xml_agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  15.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:48 (203 MB/s) - ‘docs/api.python.langchain.com/en/stable/agents/langchain.agents.xml.base.create_xml_agent.html’ saved [15907]\n",
            "\n",
            "--2024-01-23 08:22:48--  https://api.python.langchain.com/en/stable/callbacks/langchain.callbacks.file.FileCallbackHandler.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/callbacks/langchain.callbacks.file.FileCallbackHandler.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  67.21K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:49 (48.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/callbacks/langchain.callbacks.file.FileCallbackHandler.html’ saved [68820]\n",
            "\n",
            "--2024-01-23 08:22:49--  https://api.python.langchain.com/en/stable/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  70.84K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:22:49 (38.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html’ saved [72540]\n",
            "\n",
            "--2024-01-23 08:22:49--  https://api.python.langchain.com/en/stable/callbacks/langchain.callbacks.streaming_aiter_final_only.AsyncFinalIteratorCallbackHandler.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/callbacks/langchain.callbacks.streaming_aiter_final_only.AsyncFinalIteratorCallbackHandler.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  78.66K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:22:49 (49.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/callbacks/langchain.callbacks.streaming_aiter_final_only.AsyncFinalIteratorCallbackHandler.html’ saved [80546]\n",
            "\n",
            "--2024-01-23 08:22:49--  https://api.python.langchain.com/en/stable/callbacks/langchain.callbacks.streaming_stdout_final_only.FinalStreamingStdOutCallbackHandler.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/callbacks/langchain.callbacks.streaming_stdout_final_only.FinalStreamingStdOutCallbackHandler.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  58.60K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:50 (51.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/callbacks/langchain.callbacks.streaming_stdout_final_only.FinalStreamingStdOutCallbackHandler.html’ saved [60007]\n",
            "\n",
            "--2024-01-23 08:22:50--  https://api.python.langchain.com/en/stable/callbacks/langchain.callbacks.tracers.logging.LoggingCallbackHandler.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/callbacks/langchain.callbacks.tracers.logging.LoggingCallbackHandler.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  73.64K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:22:50 (45.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/callbacks/langchain.callbacks.tracers.logging.LoggingCallbackHandler.html’ saved [75409]\n",
            "\n",
            "--2024-01-23 08:22:50--  https://api.python.langchain.com/en/stable/chains/langchain.chains.api.base.APIChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.api.base.APIChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 169.28K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:22:50 (37.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.api.base.APIChain.html’ saved [173338]\n",
            "\n",
            "--2024-01-23 08:22:50--  https://api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.chain.OpenAPIEndpointChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.chain.OpenAPIEndpointChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 172.80K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:50 (36.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.chain.OpenAPIEndpointChain.html’ saved [176944]\n",
            "\n",
            "--2024-01-23 08:22:50--  https://api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.requests_chain.APIRequesterChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.requests_chain.APIRequesterChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 200.40K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:22:51 (32.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.requests_chain.APIRequesterChain.html’ saved [205206]\n",
            "\n",
            "--2024-01-23 08:22:51--  https://api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.requests_chain.APIRequesterOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.requests_chain.APIRequesterOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 124.29K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:22:55 (36.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.requests_chain.APIRequesterOutputParser.html’ saved [127271]\n",
            "\n",
            "--2024-01-23 08:22:55--  https://api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.response_chain.APIResponderChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.response_chain.APIResponderChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 200.12K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:55 (37.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.response_chain.APIResponderChain.html’ saved [204926]\n",
            "\n",
            "--2024-01-23 08:22:55--  https://api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.response_chain.APIResponderOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.response_chain.APIResponderOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 124.29K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:22:55 (39.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.api.openapi.response_chain.APIResponderOutputParser.html’ saved [127273]\n",
            "\n",
            "--2024-01-23 08:22:55--  https://api.python.langchain.com/en/stable/chains/langchain.chains.base.Chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.base.Chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 161.37K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:56 (30.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.base.Chain.html’ saved [165241]\n",
            "\n",
            "--2024-01-23 08:22:56--  https://api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.base.AnalyzeDocumentChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.base.AnalyzeDocumentChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 160.87K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:22:56 (24.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.base.AnalyzeDocumentChain.html’ saved [164735]\n",
            "\n",
            "--2024-01-23 08:22:56--  https://api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.base.BaseCombineDocumentsChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.base.BaseCombineDocumentsChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 167.72K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:56 (35.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.base.BaseCombineDocumentsChain.html’ saved [171741]\n",
            "\n",
            "--2024-01-23 08:22:56--  https://api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.map_reduce.MapReduceDocumentsChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.map_reduce.MapReduceDocumentsChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 182.66K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:56 (37.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.map_reduce.MapReduceDocumentsChain.html’ saved [187048]\n",
            "\n",
            "--2024-01-23 08:22:56--  https://api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.map_rerank.MapRerankDocumentsChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.map_rerank.MapRerankDocumentsChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 177.67K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:57 (35.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.map_rerank.MapRerankDocumentsChain.html’ saved [181932]\n",
            "\n",
            "--2024-01-23 08:22:57--  https://api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.AsyncCombineDocsProtocol.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.AsyncCombineDocsProtocol.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.35K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:57 (201 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.AsyncCombineDocsProtocol.html’ saved [12648]\n",
            "\n",
            "--2024-01-23 08:22:57--  https://api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.CombineDocsProtocol.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.CombineDocsProtocol.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.28K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:22:57 (281 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.CombineDocsProtocol.html’ saved [12573]\n",
            "\n",
            "--2024-01-23 08:22:57--  https://api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.ReduceDocumentsChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.ReduceDocumentsChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 179.00K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:57 (35.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.ReduceDocumentsChain.html’ saved [183294]\n",
            "\n",
            "--2024-01-23 08:22:57--  https://api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.refine.RefineDocumentsChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.refine.RefineDocumentsChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 178.39K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:58 (37.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.refine.RefineDocumentsChain.html’ saved [182675]\n",
            "\n",
            "--2024-01-23 08:22:58--  https://api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.stuff.StuffDocumentsChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.stuff.StuffDocumentsChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 175.79K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:58 (35.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.stuff.StuffDocumentsChain.html’ saved [180007]\n",
            "\n",
            "--2024-01-23 08:22:58--  https://api.python.langchain.com/en/stable/chains/langchain.chains.constitutional_ai.base.ConstitutionalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.constitutional_ai.base.ConstitutionalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 233.25K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-01-23 08:22:58 (30.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.constitutional_ai.base.ConstitutionalChain.html’ saved [238851]\n",
            "\n",
            "--2024-01-23 08:22:58--  https://api.python.langchain.com/en/stable/chains/langchain.chains.constitutional_ai.models.ConstitutionalPrinciple.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.constitutional_ai.models.ConstitutionalPrinciple.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  40.61K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:22:58 (23.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.constitutional_ai.models.ConstitutionalPrinciple.html’ saved [41580]\n",
            "\n",
            "--2024-01-23 08:22:58--  https://api.python.langchain.com/en/stable/chains/langchain.chains.conversation.base.ConversationChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.conversation.base.ConversationChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 200.77K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:22:58 (121 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.conversation.base.ConversationChain.html’ saved [205589]\n",
            "\n",
            "--2024-01-23 08:22:58--  https://api.python.langchain.com/en/stable/chains/langchain.chains.conversational_retrieval.base.BaseConversationalRetrievalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.conversational_retrieval.base.BaseConversationalRetrievalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 170.51K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:59 (35.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.conversational_retrieval.base.BaseConversationalRetrievalChain.html’ saved [174600]\n",
            "\n",
            "--2024-01-23 08:22:59--  https://api.python.langchain.com/en/stable/chains/langchain.chains.conversational_retrieval.base.ChatVectorDBChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.conversational_retrieval.base.ChatVectorDBChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 176.27K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:22:59 (35.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.conversational_retrieval.base.ChatVectorDBChain.html’ saved [180497]\n",
            "\n",
            "--2024-01-23 08:22:59--  https://api.python.langchain.com/en/stable/chains/langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 186.08K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:22:59 (33.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain.html’ saved [190547]\n",
            "\n",
            "--2024-01-23 08:22:59--  https://api.python.langchain.com/en/stable/chains/langchain.chains.conversational_retrieval.base.InputType.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.conversational_retrieval.base.InputType.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  40.33K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:22:59 (37.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.conversational_retrieval.base.InputType.html’ saved [41300]\n",
            "\n",
            "--2024-01-23 08:22:59--  https://api.python.langchain.com/en/stable/chains/langchain.chains.elasticsearch_database.base.ElasticsearchDatabaseChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.elasticsearch_database.base.ElasticsearchDatabaseChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 173.63K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:00 (34.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.elasticsearch_database.base.ElasticsearchDatabaseChain.html’ saved [177799]\n",
            "\n",
            "--2024-01-23 08:23:00--  https://api.python.langchain.com/en/stable/chains/langchain.chains.flare.base.FlareChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.flare.base.FlareChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 166.71K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:00 (111 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.flare.base.FlareChain.html’ saved [170712]\n",
            "\n",
            "--2024-01-23 08:23:00--  https://api.python.langchain.com/en/stable/chains/langchain.chains.flare.base.QuestionGeneratorChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.flare.base.QuestionGeneratorChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 198.38K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:23:00 (34.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.flare.base.QuestionGeneratorChain.html’ saved [203142]\n",
            "\n",
            "--2024-01-23 08:23:00--  https://api.python.langchain.com/en/stable/chains/langchain.chains.flare.prompts.FinishedOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.flare.prompts.FinishedOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 123.78K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:00 (39.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.flare.prompts.FinishedOutputParser.html’ saved [126751]\n",
            "\n",
            "--2024-01-23 08:23:00--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.arangodb.ArangoGraphQAChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.arangodb.ArangoGraphQAChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 190.19K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:00 (33.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.arangodb.ArangoGraphQAChain.html’ saved [194757]\n",
            "\n",
            "--2024-01-23 08:23:00--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.base.GraphQAChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.base.GraphQAChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 166.39K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:00 (34.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.base.GraphQAChain.html’ saved [170387]\n",
            "\n",
            "--2024-01-23 08:23:00--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher.GraphCypherQAChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher.GraphCypherQAChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 172.95K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:01 (37.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher.GraphCypherQAChain.html’ saved [177101]\n",
            "\n",
            "--2024-01-23 08:23:01--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher_utils.CypherQueryCorrector.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher_utils.CypherQueryCorrector.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  32.04K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:01 (51.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher_utils.CypherQueryCorrector.html’ saved [32811]\n",
            "\n",
            "--2024-01-23 08:23:01--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher_utils.Schema.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher_utils.Schema.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  14.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:01 (43.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher_utils.Schema.html’ saved [15005]\n",
            "\n",
            "--2024-01-23 08:23:01--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.falkordb.FalkorDBQAChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.falkordb.FalkorDBQAChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 170.70K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:01 (36.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.falkordb.FalkorDBQAChain.html’ saved [174792]\n",
            "\n",
            "--2024-01-23 08:23:01--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.hugegraph.HugeGraphQAChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.hugegraph.HugeGraphQAChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 168.60K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:01 (33.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.hugegraph.HugeGraphQAChain.html’ saved [172644]\n",
            "\n",
            "--2024-01-23 08:23:01--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.kuzu.KuzuQAChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.kuzu.KuzuQAChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 168.85K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:02 (34.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.kuzu.KuzuQAChain.html’ saved [172905]\n",
            "\n",
            "--2024-01-23 08:23:02--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.nebulagraph.NebulaGraphQAChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.nebulagraph.NebulaGraphQAChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 171.75K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:02 (34.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.nebulagraph.NebulaGraphQAChain.html’ saved [175867]\n",
            "\n",
            "--2024-01-23 08:23:02--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.neptune_cypher.NeptuneOpenCypherQAChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.neptune_cypher.NeptuneOpenCypherQAChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 172.61K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:02 (39.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.neptune_cypher.NeptuneOpenCypherQAChain.html’ saved [176750]\n",
            "\n",
            "--2024-01-23 08:23:02--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.sparql.GraphSparqlQAChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.sparql.GraphSparqlQAChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 181.49K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:02 (36.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.sparql.GraphSparqlQAChain.html’ saved [185846]\n",
            "\n",
            "--2024-01-23 08:23:02--  https://api.python.langchain.com/en/stable/chains/langchain.chains.hyde.base.HypotheticalDocumentEmbedder.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.hyde.base.HypotheticalDocumentEmbedder.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 171.10K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:02 (35.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.hyde.base.HypotheticalDocumentEmbedder.html’ saved [175206]\n",
            "\n",
            "--2024-01-23 08:23:02--  https://api.python.langchain.com/en/stable/chains/langchain.chains.llm.LLMChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.llm.LLMChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 202.29K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:23:02 (31.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.llm.LLMChain.html’ saved [207150]\n",
            "\n",
            "--2024-01-23 08:23:02--  https://api.python.langchain.com/en/stable/chains/langchain.chains.llm_checker.base.LLMCheckerChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.llm_checker.base.LLMCheckerChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 172.15K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:03 (32.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.llm_checker.base.LLMCheckerChain.html’ saved [176280]\n",
            "\n",
            "--2024-01-23 08:23:03--  https://api.python.langchain.com/en/stable/chains/langchain.chains.llm_math.base.LLMMathChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.llm_math.base.LLMMathChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 165.94K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:03 (37.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.llm_math.base.LLMMathChain.html’ saved [169919]\n",
            "\n",
            "--2024-01-23 08:23:03--  https://api.python.langchain.com/en/stable/chains/langchain.chains.llm_requests.LLMRequestsChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.llm_requests.LLMRequestsChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 159.55K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:03 (35.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.llm_requests.LLMRequestsChain.html’ saved [163381]\n",
            "\n",
            "--2024-01-23 08:23:03--  https://api.python.langchain.com/en/stable/chains/langchain.chains.llm_summarization_checker.base.LLMSummarizationCheckerChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.llm_summarization_checker.base.LLMSummarizationCheckerChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 188.75K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:23:03 (30.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.llm_summarization_checker.base.LLMSummarizationCheckerChain.html’ saved [193282]\n",
            "\n",
            "--2024-01-23 08:23:03--  https://api.python.langchain.com/en/stable/chains/langchain.chains.mapreduce.MapReduceChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.mapreduce.MapReduceChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 163.39K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:03 (36.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.mapreduce.MapReduceChain.html’ saved [167314]\n",
            "\n",
            "--2024-01-23 08:23:03--  https://api.python.langchain.com/en/stable/chains/langchain.chains.moderation.OpenAIModerationChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.moderation.OpenAIModerationChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 161.48K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:04 (35.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.moderation.OpenAIModerationChain.html’ saved [165356]\n",
            "\n",
            "--2024-01-23 08:23:04--  https://api.python.langchain.com/en/stable/chains/langchain.chains.natbot.base.NatBotChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.natbot.base.NatBotChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 164.60K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:04 (31.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.natbot.base.NatBotChain.html’ saved [168546]\n",
            "\n",
            "--2024-01-23 08:23:04--  https://api.python.langchain.com/en/stable/chains/langchain.chains.natbot.crawler.Crawler.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.natbot.crawler.Crawler.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.74K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:04 (118 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.natbot.crawler.Crawler.html’ saved [20210]\n",
            "\n",
            "--2024-01-23 08:23:04--  https://api.python.langchain.com/en/stable/chains/langchain.chains.natbot.crawler.ElementInViewPort.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.natbot.crawler.ElementInViewPort.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  15.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:04 (156 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.natbot.crawler.ElementInViewPort.html’ saved [16077]\n",
            "\n",
            "--2024-01-23 08:23:04--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.citation_fuzzy_match.FactWithEvidence.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.citation_fuzzy_match.FactWithEvidence.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  41.60K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:04 (53.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.citation_fuzzy_match.FactWithEvidence.html’ saved [42595]\n",
            "\n",
            "--2024-01-23 08:23:04--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.citation_fuzzy_match.QuestionAnswer.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.citation_fuzzy_match.QuestionAnswer.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  40.61K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:04 (46.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.citation_fuzzy_match.QuestionAnswer.html’ saved [41582]\n",
            "\n",
            "--2024-01-23 08:23:04--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.openapi.SimpleRequestChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.openapi.SimpleRequestChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 162.18K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:05 (31.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.openapi.SimpleRequestChain.html’ saved [166068]\n",
            "\n",
            "--2024-01-23 08:23:05--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.qa_with_structure.AnswerWithSources.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.qa_with_structure.AnswerWithSources.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  40.15K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:05 (49.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.qa_with_structure.AnswerWithSources.html’ saved [41117]\n",
            "\n",
            "--2024-01-23 08:23:05--  https://api.python.langchain.com/en/stable/chains/langchain.chains.prompt_selector.BasePromptSelector.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.prompt_selector.BasePromptSelector.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  39.63K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:05 (64.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.prompt_selector.BasePromptSelector.html’ saved [40578]\n",
            "\n",
            "--2024-01-23 08:23:05--  https://api.python.langchain.com/en/stable/chains/langchain.chains.prompt_selector.ConditionalPromptSelector.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.prompt_selector.ConditionalPromptSelector.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  43.37K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:23:05 (23.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.prompt_selector.ConditionalPromptSelector.html’ saved [44412]\n",
            "\n",
            "--2024-01-23 08:23:05--  https://api.python.langchain.com/en/stable/chains/langchain.chains.qa_generation.base.QAGenerationChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.qa_generation.base.QAGenerationChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 166.02K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:05 (31.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.qa_generation.base.QAGenerationChain.html’ saved [170009]\n",
            "\n",
            "--2024-01-23 08:23:05--  https://api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 197.51K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:23:06 (33.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain.html’ saved [202250]\n",
            "\n",
            "--2024-01-23 08:23:06--  https://api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.base.QAWithSourcesChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.base.QAWithSourcesChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 196.68K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:06 (36.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.base.QAWithSourcesChain.html’ saved [201398]\n",
            "\n",
            "--2024-01-23 08:23:06--  https://api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.loading.LoadingCallable.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.loading.LoadingCallable.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.22K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:06 (211 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.loading.LoadingCallable.html’ saved [12510]\n",
            "\n",
            "--2024-01-23 08:23:06--  https://api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 202.78K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:23:06 (32.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain.html’ saved [207646]\n",
            "\n",
            "--2024-01-23 08:23:06--  https://api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.vector_db.VectorDBQAWithSourcesChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.vector_db.VectorDBQAWithSourcesChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 202.96K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:23:06 (32.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.vector_db.VectorDBQAWithSourcesChain.html’ saved [207832]\n",
            "\n",
            "--2024-01-23 08:23:06--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.StructuredQueryOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.StructuredQueryOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 129.90K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:06 (38.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.StructuredQueryOutputParser.html’ saved [133018]\n",
            "\n",
            "--2024-01-23 08:23:06--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Comparator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Comparator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.68K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:06 (40.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Comparator.html’ saved [17076]\n",
            "\n",
            "--2024-01-23 08:23:06--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Comparison.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Comparison.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  41.48K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:07 (46.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Comparison.html’ saved [42478]\n",
            "\n",
            "--2024-01-23 08:23:07--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Expr.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Expr.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  39.06K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:07 (52.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Expr.html’ saved [39994]\n",
            "\n",
            "--2024-01-23 08:23:07--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.FilterDirective.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.FilterDirective.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  39.54K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:07 (51.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.FilterDirective.html’ saved [40492]\n",
            "\n",
            "--2024-01-23 08:23:07--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Operation.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Operation.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  41.14K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:07 (39.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Operation.html’ saved [42124]\n",
            "\n",
            "--2024-01-23 08:23:07--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Operator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Operator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.33K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:07 (107 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Operator.html’ saved [13647]\n",
            "\n",
            "--2024-01-23 08:23:07--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.StructuredQuery.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.StructuredQuery.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  42.07K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:08 (61.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.StructuredQuery.html’ saved [43081]\n",
            "\n",
            "--2024-01-23 08:23:08--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Visitor.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Visitor.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.96K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:08 (175 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.ir.Visitor.html’ saved [17366]\n",
            "\n",
            "--2024-01-23 08:23:08--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.parser.ISO8601Date.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.parser.ISO8601Date.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:08 (52.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.parser.ISO8601Date.html’ saved [26037]\n",
            "\n",
            "--2024-01-23 08:23:08--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.schema.AttributeInfo.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.schema.AttributeInfo.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  42.44K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:08 (51.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.schema.AttributeInfo.html’ saved [43455]\n",
            "\n",
            "--2024-01-23 08:23:08--  https://api.python.langchain.com/en/stable/chains/langchain.chains.retrieval_qa.base.BaseRetrievalQA.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.retrieval_qa.base.BaseRetrievalQA.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 165.56K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:08 (47.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.retrieval_qa.base.BaseRetrievalQA.html’ saved [169537]\n",
            "\n",
            "--2024-01-23 08:23:08--  https://api.python.langchain.com/en/stable/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 169.76K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:09 (36.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html’ saved [173833]\n",
            "\n",
            "--2024-01-23 08:23:09--  https://api.python.langchain.com/en/stable/chains/langchain.chains.retrieval_qa.base.VectorDBQA.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.retrieval_qa.base.VectorDBQA.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 167.90K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:09 (31.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.retrieval_qa.base.VectorDBQA.html’ saved [171925]\n",
            "\n",
            "--2024-01-23 08:23:09--  https://api.python.langchain.com/en/stable/chains/langchain.chains.router.base.MultiRouteChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.base.MultiRouteChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 159.78K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2024-01-23 08:23:09 (17.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.base.MultiRouteChain.html’ saved [163613]\n",
            "\n",
            "--2024-01-23 08:23:09--  https://api.python.langchain.com/en/stable/chains/langchain.chains.router.base.Route.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.base.Route.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  14.31K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:09 (183 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.base.Route.html’ saved [14655]\n",
            "\n",
            "--2024-01-23 08:23:09--  https://api.python.langchain.com/en/stable/chains/langchain.chains.router.base.RouterChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.base.RouterChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 162.83K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:09 (33.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.base.RouterChain.html’ saved [166742]\n",
            "\n",
            "--2024-01-23 08:23:09--  https://api.python.langchain.com/en/stable/chains/langchain.chains.router.embedding_router.EmbeddingRouterChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.embedding_router.EmbeddingRouterChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 169.69K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:10 (31.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.embedding_router.EmbeddingRouterChain.html’ saved [173766]\n",
            "\n",
            "--2024-01-23 08:23:10--  https://api.python.langchain.com/en/stable/chains/langchain.chains.router.llm_router.LLMRouterChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.llm_router.LLMRouterChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 166.16K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:10 (37.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.llm_router.LLMRouterChain.html’ saved [170149]\n",
            "\n",
            "--2024-01-23 08:23:10--  https://api.python.langchain.com/en/stable/chains/langchain.chains.router.llm_router.RouterOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.llm_router.RouterOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 125.82K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:10 (144 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.llm_router.RouterOutputParser.html’ saved [128839]\n",
            "\n",
            "--2024-01-23 08:23:10--  https://api.python.langchain.com/en/stable/chains/langchain.chains.router.multi_prompt.MultiPromptChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.multi_prompt.MultiPromptChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 164.39K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:10 (33.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.multi_prompt.MultiPromptChain.html’ saved [168340]\n",
            "\n",
            "--2024-01-23 08:23:10--  https://api.python.langchain.com/en/stable/chains/langchain.chains.router.multi_retrieval_qa.MultiRetrievalQAChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.multi_retrieval_qa.MultiRetrievalQAChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 167.25K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:10 (33.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.router.multi_retrieval_qa.MultiRetrievalQAChain.html’ saved [171268]\n",
            "\n",
            "--2024-01-23 08:23:10--  https://api.python.langchain.com/en/stable/chains/langchain.chains.sequential.SequentialChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.sequential.SequentialChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 158.42K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:10 (33.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.sequential.SequentialChain.html’ saved [162220]\n",
            "\n",
            "--2024-01-23 08:23:10--  https://api.python.langchain.com/en/stable/chains/langchain.chains.sequential.SimpleSequentialChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.sequential.SimpleSequentialChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 159.76K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:10 (35.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.sequential.SimpleSequentialChain.html’ saved [163590]\n",
            "\n",
            "--2024-01-23 08:23:10--  https://api.python.langchain.com/en/stable/chains/langchain.chains.sql_database.query.SQLInput.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.sql_database.query.SQLInput.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  10.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:11 (115 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.sql_database.query.SQLInput.html’ saved [11254]\n",
            "\n",
            "--2024-01-23 08:23:11--  https://api.python.langchain.com/en/stable/chains/langchain.chains.sql_database.query.SQLInputWithTables.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.sql_database.query.SQLInputWithTables.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.74K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:11 (129 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.sql_database.query.SQLInputWithTables.html’ saved [12025]\n",
            "\n",
            "--2024-01-23 08:23:11--  https://api.python.langchain.com/en/stable/chains/langchain.chains.transform.TransformChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.transform.TransformChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 162.12K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:11 (32.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.transform.TransformChain.html’ saved [166012]\n",
            "\n",
            "--2024-01-23 08:23:11--  https://api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.acollapse_docs.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.acollapse_docs.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:11 (65.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.acollapse_docs.html’ saved [13571]\n",
            "\n",
            "--2024-01-23 08:23:11--  https://api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.collapse_docs.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.collapse_docs.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:11 (51.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.collapse_docs.html’ saved [13437]\n",
            "\n",
            "--2024-01-23 08:23:11--  https://api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.split_list_of_docs.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.split_list_of_docs.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:12 (73.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.reduce.split_list_of_docs.html’ saved [13440]\n",
            "\n",
            "--2024-01-23 08:23:12--  https://api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:12 (60.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html’ saved [18880]\n",
            "\n",
            "--2024-01-23 08:23:12--  https://api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.convert_python_function_to_ernie_function.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.convert_python_function_to_ernie_function.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:12 (90.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.convert_python_function_to_ernie_function.html’ saved [12029]\n",
            "\n",
            "--2024-01-23 08:23:12--  https://api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.convert_to_ernie_function.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.convert_to_ernie_function.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.51K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:12 (147 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.convert_to_ernie_function.html’ saved [12808]\n",
            "\n",
            "--2024-01-23 08:23:12--  https://api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.create_ernie_fn_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.create_ernie_fn_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:13 (307 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.create_ernie_fn_chain.html’ saved [22079]\n",
            "\n",
            "--2024-01-23 08:23:13--  https://api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.create_ernie_fn_runnable.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.create_ernie_fn_runnable.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.66K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:13 (67.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.create_ernie_fn_runnable.html’ saved [22180]\n",
            "\n",
            "--2024-01-23 08:23:13--  https://api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.create_structured_output_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.create_structured_output_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.72K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:13 (63.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.create_structured_output_chain.html’ saved [20190]\n",
            "\n",
            "--2024-01-23 08:23:13--  https://api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.create_structured_output_runnable.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.create_structured_output_runnable.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.47K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:13 (105 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.create_structured_output_runnable.html’ saved [19941]\n",
            "\n",
            "--2024-01-23 08:23:13--  https://api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.get_ernie_output_parser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.get_ernie_output_parser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.33K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:13 (229 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.ernie_functions.base.get_ernie_output_parser.html’ saved [13655]\n",
            "\n",
            "--2024-01-23 08:23:13--  https://api.python.langchain.com/en/stable/chains/langchain.chains.example_generator.generate_example.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.example_generator.generate_example.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.97K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:14 (155 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.example_generator.generate_example.html’ saved [12256]\n",
            "\n",
            "--2024-01-23 08:23:14--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher.construct_schema.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher.construct_schema.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.85K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:23:14 (5.36 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher.construct_schema.html’ saved [12137]\n",
            "\n",
            "--2024-01-23 08:23:14--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher.extract_cypher.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher.extract_cypher.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:14 (111 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.cypher.extract_cypher.html’ saved [11450]\n",
            "\n",
            "--2024-01-23 08:23:14--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.falkordb.extract_cypher.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.falkordb.extract_cypher.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:14 (136 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.falkordb.extract_cypher.html’ saved [11384]\n",
            "\n",
            "--2024-01-23 08:23:14--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.neptune_cypher.extract_cypher.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.neptune_cypher.extract_cypher.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.00K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:14 (2.78 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.neptune_cypher.extract_cypher.html’ saved [11269]\n",
            "\n",
            "--2024-01-23 08:23:14--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.neptune_cypher.trim_query.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.neptune_cypher.trim_query.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  10.97K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:14 (111 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.neptune_cypher.trim_query.html’ saved [11231]\n",
            "\n",
            "--2024-01-23 08:23:14--  https://api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.neptune_cypher.use_simple_prompt.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.neptune_cypher.use_simple_prompt.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.28K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:14 (182 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.graph_qa.neptune_cypher.use_simple_prompt.html’ saved [11549]\n",
            "\n",
            "--2024-01-23 08:23:14--  https://api.python.langchain.com/en/stable/chains/langchain.chains.history_aware_retriever.create_history_aware_retriever.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.history_aware_retriever.create_history_aware_retriever.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:15 (42.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.history_aware_retriever.create_history_aware_retriever.html’ saved [18043]\n",
            "\n",
            "--2024-01-23 08:23:15--  https://api.python.langchain.com/en/stable/chains/langchain.chains.loading.load_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.loading.load_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:15 (151 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.loading.load_chain.html’ saved [12310]\n",
            "\n",
            "--2024-01-23 08:23:15--  https://api.python.langchain.com/en/stable/chains/langchain.chains.loading.load_chain_from_config.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.loading.load_chain_from_config.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.30K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:15 (16.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.loading.load_chain_from_config.html’ saved [11567]\n",
            "\n",
            "--2024-01-23 08:23:15--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.convert_python_function_to_openai_function.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.convert_python_function_to_openai_function.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.77K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:15 (60.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.convert_python_function_to_openai_function.html’ saved [12052]\n",
            "\n",
            "--2024-01-23 08:23:15--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.convert_to_openai_function.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.convert_to_openai_function.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:15 (80.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.convert_to_openai_function.html’ saved [12833]\n",
            "\n",
            "--2024-01-23 08:23:15--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.create_openai_fn_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.create_openai_fn_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:15 (62.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.create_openai_fn_chain.html’ saved [23248]\n",
            "\n",
            "--2024-01-23 08:23:15--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.create_openai_fn_runnable.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.create_openai_fn_runnable.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.48K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:16 (57.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.create_openai_fn_runnable.html’ saved [23016]\n",
            "\n",
            "--2024-01-23 08:23:16--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.create_structured_output_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.create_structured_output_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:16 (53.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.create_structured_output_chain.html’ saved [20398]\n",
            "\n",
            "--2024-01-23 08:23:16--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.create_structured_output_runnable.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.create_structured_output_runnable.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.68K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:16 (50.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.create_structured_output_runnable.html’ saved [20148]\n",
            "\n",
            "--2024-01-23 08:23:16--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.get_openai_output_parser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.get_openai_output_parser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.36K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:16 (147 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.base.get_openai_output_parser.html’ saved [13678]\n",
            "\n",
            "--2024-01-23 08:23:16--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.citation_fuzzy_match.create_citation_fuzzy_match_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.citation_fuzzy_match.create_citation_fuzzy_match_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.41K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:16 (137 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.citation_fuzzy_match.create_citation_fuzzy_match_chain.html’ saved [12708]\n",
            "\n",
            "--2024-01-23 08:23:16--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.extraction.create_extraction_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.extraction.create_extraction_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  14.64K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:17 (191 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.extraction.create_extraction_chain.html’ saved [14993]\n",
            "\n",
            "--2024-01-23 08:23:17--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.extraction.create_extraction_chain_pydantic.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.extraction.create_extraction_chain_pydantic.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  14.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:17 (155 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.extraction.create_extraction_chain_pydantic.html’ saved [14384]\n",
            "\n",
            "--2024-01-23 08:23:17--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.openapi.get_openapi_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.openapi.get_openapi_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.74K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:17 (163 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.openapi.get_openapi_chain.html’ saved [17141]\n",
            "\n",
            "--2024-01-23 08:23:17--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.openapi.openapi_spec_to_openai_fn.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.openapi.openapi_spec_to_openai_fn.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:17 (32.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.openapi.openapi_spec_to_openai_fn.html’ saved [12713]\n",
            "\n",
            "--2024-01-23 08:23:17--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.qa_with_structure.create_qa_with_sources_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.qa_with_structure.create_qa_with_sources_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.24K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:17 (131 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.qa_with_structure.create_qa_with_sources_chain.html’ saved [13561]\n",
            "\n",
            "--2024-01-23 08:23:17--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.qa_with_structure.create_qa_with_structure_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.qa_with_structure.create_qa_with_structure_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  15.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:17 (92.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.qa_with_structure.create_qa_with_structure_chain.html’ saved [15493]\n",
            "\n",
            "--2024-01-23 08:23:17--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.tagging.create_tagging_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.tagging.create_tagging_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.71K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:17 (55.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.tagging.create_tagging_chain.html’ saved [14040]\n",
            "\n",
            "--2024-01-23 08:23:17--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.tagging.create_tagging_chain_pydantic.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.tagging.create_tagging_chain_pydantic.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.59K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:18 (186 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.tagging.create_tagging_chain_pydantic.html’ saved [13914]\n",
            "\n",
            "--2024-01-23 08:23:18--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.utils.get_llm_kwargs.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.utils.get_llm_kwargs.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.27K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:18 (112 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_functions.utils.get_llm_kwargs.html’ saved [11544]\n",
            "\n",
            "--2024-01-23 08:23:18--  https://api.python.langchain.com/en/stable/chains/langchain.chains.openai_tools.extraction.create_extraction_chain_pydantic.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_tools.extraction.create_extraction_chain_pydantic.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  14.72K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:18 (216 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.openai_tools.extraction.create_extraction_chain_pydantic.html’ saved [15076]\n",
            "\n",
            "--2024-01-23 08:23:18--  https://api.python.langchain.com/en/stable/chains/langchain.chains.prompt_selector.is_chat_model.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.prompt_selector.is_chat_model.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.45K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:18 (181 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.prompt_selector.is_chat_model.html’ saved [11723]\n",
            "\n",
            "--2024-01-23 08:23:18--  https://api.python.langchain.com/en/stable/chains/langchain.chains.prompt_selector.is_llm.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.prompt_selector.is_llm.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.36K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:18 (161 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.prompt_selector.is_llm.html’ saved [11633]\n",
            "\n",
            "--2024-01-23 08:23:18--  https://api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.loading.load_qa_with_sources_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.loading.load_qa_with_sources_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:18 (39.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.qa_with_sources.loading.load_qa_with_sources_chain.html’ saved [14247]\n",
            "\n",
            "--2024-01-23 08:23:18--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.construct_examples.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.construct_examples.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.79K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:19 (189 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.construct_examples.html’ saved [12078]\n",
            "\n",
            "--2024-01-23 08:23:19--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.fix_filter_directive.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.fix_filter_directive.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  14.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:19 (194 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.fix_filter_directive.html’ saved [15049]\n",
            "\n",
            "--2024-01-23 08:23:19--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.get_query_constructor_prompt.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.get_query_constructor_prompt.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  14.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:19 (179 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.get_query_constructor_prompt.html’ saved [14791]\n",
            "\n",
            "--2024-01-23 08:23:19--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.load_query_constructor_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.load_query_constructor_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  14.52K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:19 (80.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.load_query_constructor_chain.html’ saved [14872]\n",
            "\n",
            "--2024-01-23 08:23:19--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.load_query_constructor_runnable.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.load_query_constructor_runnable.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  14.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:19 (160 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.base.load_query_constructor_runnable.html’ saved [15281]\n",
            "\n",
            "--2024-01-23 08:23:19--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.parser.get_parser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.parser.get_parser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.45K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:19 (212 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.parser.get_parser.html’ saved [13775]\n",
            "\n",
            "--2024-01-23 08:23:19--  https://api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.parser.v_args.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.parser.v_args.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:20 (129 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.query_constructor.parser.v_args.html’ saved [11503]\n",
            "\n",
            "--2024-01-23 08:23:20--  https://api.python.langchain.com/en/stable/chains/langchain.chains.retrieval.create_retrieval_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.retrieval.create_retrieval_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.27K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:20 (76.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.retrieval.create_retrieval_chain.html’ saved [16659]\n",
            "\n",
            "--2024-01-23 08:23:20--  https://api.python.langchain.com/en/stable/chains/langchain.chains.sql_database.query.create_sql_query_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.sql_database.query.create_sql_query_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  15.80K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:20 (43.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/chains/langchain.chains.sql_database.query.create_sql_query_chain.html’ saved [16182]\n",
            "\n",
            "--2024-01-23 08:23:20--  https://api.python.langchain.com/en/stable/embeddings/langchain.embeddings.cache.CacheBackedEmbeddings.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/embeddings/langchain.embeddings.cache.CacheBackedEmbeddings.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.34K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:20 (74.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/embeddings/langchain.embeddings.cache.CacheBackedEmbeddings.html’ saved [26977]\n",
            "\n",
            "--2024-01-23 08:23:20--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.loading.load_evaluators.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.loading.load_evaluators.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:20 (135 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.loading.load_evaluators.html’ saved [16380]\n",
            "\n",
            "--2024-01-23 08:23:20--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.loading.load_evaluator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.loading.load_evaluator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  15.79K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:20 (197 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.loading.load_evaluator.html’ saved [16170]\n",
            "\n",
            "--2024-01-23 08:23:20--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.EvaluatorType.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.EvaluatorType.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:21 (210 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.EvaluatorType.html’ saved [24737]\n",
            "\n",
            "--2024-01-23 08:23:21--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.loading.load_dataset.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.loading.load_dataset.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.32K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:21 (139 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.loading.load_dataset.html’ saved [12615]\n",
            "\n",
            "--2024-01-23 08:23:21--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.qa.eval_chain.QAEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.qa.eval_chain.QAEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 211.43K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:21 (43.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.qa.eval_chain.QAEvalChain.html’ saved [216501]\n",
            "\n",
            "--2024-01-23 08:23:21--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.comparison.eval_chain.PairwiseStringEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.comparison.eval_chain.PairwiseStringEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 217.40K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-01-23 08:23:21 (28.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.comparison.eval_chain.PairwiseStringEvalChain.html’ saved [222620]\n",
            "\n",
            "--2024-01-23 08:23:21--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.comparison.eval_chain.LabeledPairwiseStringEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.comparison.eval_chain.LabeledPairwiseStringEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 215.14K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-01-23 08:23:21 (30.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.comparison.eval_chain.LabeledPairwiseStringEvalChain.html’ saved [220302]\n",
            "\n",
            "--2024-01-23 08:23:21--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 186.15K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:22 (38.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain.html’ saved [190619]\n",
            "\n",
            "--2024-01-23 08:23:22--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.CriteriaEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.CriteriaEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 225.49K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-01-23 08:23:22 (33.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.CriteriaEvalChain.html’ saved [230905]\n",
            "\n",
            "--2024-01-23 08:23:22--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.LabeledCriteriaEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.LabeledCriteriaEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 218.82K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:23:22 (32.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.LabeledCriteriaEvalChain.html’ saved [224069]\n",
            "\n",
            "--2024-01-23 08:23:22--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.embedding_distance.base.EmbeddingDistanceEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.embedding_distance.base.EmbeddingDistanceEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 173.28K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:22 (32.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.embedding_distance.base.EmbeddingDistanceEvalChain.html’ saved [177441]\n",
            "\n",
            "--2024-01-23 08:23:22--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.embedding_distance.base.PairwiseEmbeddingDistanceEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.embedding_distance.base.PairwiseEmbeddingDistanceEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 174.19K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:22 (53.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.embedding_distance.base.PairwiseEmbeddingDistanceEvalChain.html’ saved [178366]\n",
            "\n",
            "--2024-01-23 08:23:22--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.string_distance.base.StringDistanceEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.string_distance.base.StringDistanceEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 175.17K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:23 (47.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.string_distance.base.StringDistanceEvalChain.html’ saved [179377]\n",
            "\n",
            "--2024-01-23 08:23:23--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.string_distance.base.PairwiseStringDistanceEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.string_distance.base.PairwiseStringDistanceEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 175.41K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:23 (31.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.string_distance.base.PairwiseStringDistanceEvalChain.html’ saved [179615]\n",
            "\n",
            "--2024-01-23 08:23:23--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.StringEvaluator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.StringEvaluator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.89K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:23 (183 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.StringEvaluator.html’ saved [20370]\n",
            "\n",
            "--2024-01-23 08:23:23--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.PairwiseStringEvaluator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.PairwiseStringEvaluator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.49K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:23 (180 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.PairwiseStringEvaluator.html’ saved [20983]\n",
            "\n",
            "--2024-01-23 08:23:23--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.AgentTrajectoryEvaluator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.AgentTrajectoryEvaluator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.95K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:23 (195 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.AgentTrajectoryEvaluator.html’ saved [21452]\n",
            "\n",
            "--2024-01-23 08:23:23--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEval.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEval.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:23 (133 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEval.html’ saved [12163]\n",
            "\n",
            "--2024-01-23 08:23:23--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 126.11K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:23:24 (53.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryOutputParser.html’ saved [129134]\n",
            "\n",
            "--2024-01-23 08:23:24--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.comparison.eval_chain.PairwiseStringResultOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.comparison.eval_chain.PairwiseStringResultOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 126.68K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:24 (37.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.comparison.eval_chain.PairwiseStringResultOutputParser.html’ saved [129717]\n",
            "\n",
            "--2024-01-23 08:23:24--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.Criteria.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.Criteria.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.29K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:24 (189 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.Criteria.html’ saved [19757]\n",
            "\n",
            "--2024-01-23 08:23:24--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.CriteriaResultOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.CriteriaResultOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 125.02K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:24 (38.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.CriteriaResultOutputParser.html’ saved [128021]\n",
            "\n",
            "--2024-01-23 08:23:24--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.embedding_distance.base.EmbeddingDistance.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.embedding_distance.base.EmbeddingDistance.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.51K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:24 (87.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.embedding_distance.base.EmbeddingDistance.html’ saved [16907]\n",
            "\n",
            "--2024-01-23 08:23:24--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.exact_match.base.ExactMatchStringEvaluator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.exact_match.base.ExactMatchStringEvaluator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.08K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:24 (120 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.exact_match.base.ExactMatchStringEvaluator.html’ saved [24661]\n",
            "\n",
            "--2024-01-23 08:23:24--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.parsing.base.JsonEqualityEvaluator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.parsing.base.JsonEqualityEvaluator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.43K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:24 (6.90 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.parsing.base.JsonEqualityEvaluator.html’ saved [27069]\n",
            "\n",
            "--2024-01-23 08:23:24--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.parsing.base.JsonValidityEvaluator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.parsing.base.JsonValidityEvaluator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:24 (62.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.parsing.base.JsonValidityEvaluator.html’ saved [24725]\n",
            "\n",
            "--2024-01-23 08:23:24--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.parsing.json_distance.JsonEditDistanceEvaluator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.parsing.json_distance.JsonEditDistanceEvaluator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.84K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:25 (175 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.parsing.json_distance.JsonEditDistanceEvaluator.html’ saved [28507]\n",
            "\n",
            "--2024-01-23 08:23:25--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.parsing.json_schema.JsonSchemaEvaluator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.parsing.json_schema.JsonSchemaEvaluator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:25 (51.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.parsing.json_schema.JsonSchemaEvaluator.html’ saved [24711]\n",
            "\n",
            "--2024-01-23 08:23:25--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.qa.eval_chain.ContextQAEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.qa.eval_chain.ContextQAEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 212.79K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:23:25 (33.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.qa.eval_chain.ContextQAEvalChain.html’ saved [217894]\n",
            "\n",
            "--2024-01-23 08:23:25--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.qa.eval_chain.CotQAEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.qa.eval_chain.CotQAEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 210.86K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:23:25 (34.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.qa.eval_chain.CotQAEvalChain.html’ saved [215922]\n",
            "\n",
            "--2024-01-23 08:23:25--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.qa.generate_chain.QAGenerateChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.qa.generate_chain.QAGenerateChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 199.64K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:23:25 (33.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.qa.generate_chain.QAGenerateChain.html’ saved [204432]\n",
            "\n",
            "--2024-01-23 08:23:25--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.regex_match.base.RegexMatchStringEvaluator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.regex_match.base.RegexMatchStringEvaluator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  23.45K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:25 (64.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.regex_match.base.RegexMatchStringEvaluator.html’ saved [24013]\n",
            "\n",
            "--2024-01-23 08:23:25--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.LLMEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.LLMEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 158.90K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:26 (29.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.schema.LLMEvalChain.html’ saved [162715]\n",
            "\n",
            "--2024-01-23 08:23:26--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.scoring.eval_chain.LabeledScoreStringEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.scoring.eval_chain.LabeledScoreStringEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 216.31K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:23:26 (32.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.scoring.eval_chain.LabeledScoreStringEvalChain.html’ saved [221501]\n",
            "\n",
            "--2024-01-23 08:23:26--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.scoring.eval_chain.ScoreStringEvalChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.scoring.eval_chain.ScoreStringEvalChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 217.80K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:23:26 (34.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.scoring.eval_chain.ScoreStringEvalChain.html’ saved [223030]\n",
            "\n",
            "--2024-01-23 08:23:26--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.scoring.eval_chain.ScoreStringResultOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.scoring.eval_chain.ScoreStringResultOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 125.91K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:26 (32.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.scoring.eval_chain.ScoreStringResultOutputParser.html’ saved [128934]\n",
            "\n",
            "--2024-01-23 08:23:26--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.string_distance.base.StringDistance.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.string_distance.base.StringDistance.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:26 (108 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.string_distance.base.StringDistance.html’ saved [17417]\n",
            "\n",
            "--2024-01-23 08:23:26--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.comparison.eval_chain.resolve_pairwise_criteria.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.comparison.eval_chain.resolve_pairwise_criteria.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  14.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:26 (166 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.comparison.eval_chain.resolve_pairwise_criteria.html’ saved [14591]\n",
            "\n",
            "--2024-01-23 08:23:26--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.resolve_criteria.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.resolve_criteria.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.81K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:27 (171 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.criteria.eval_chain.resolve_criteria.html’ saved [14146]\n",
            "\n",
            "--2024-01-23 08:23:27--  https://api.python.langchain.com/en/stable/evaluation/langchain.evaluation.scoring.eval_chain.resolve_criteria.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.scoring.eval_chain.resolve_criteria.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.97K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:27 (160 MB/s) - ‘docs/api.python.langchain.com/en/stable/evaluation/langchain.evaluation.scoring.eval_chain.resolve_criteria.html’ saved [14308]\n",
            "\n",
            "--2024-01-23 08:23:27--  https://api.python.langchain.com/en/stable/hub/langchain.hub.pull.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/hub/langchain.hub.pull.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.35K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:27 (153 MB/s) - ‘docs/api.python.langchain.com/en/stable/hub/langchain.hub.pull.html’ saved [12646]\n",
            "\n",
            "--2024-01-23 08:23:27--  https://api.python.langchain.com/en/stable/hub/langchain.hub.push.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/hub/langchain.hub.push.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  14.27K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:27 (55.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/hub/langchain.hub.push.html’ saved [14611]\n",
            "\n",
            "--2024-01-23 08:23:27--  https://api.python.langchain.com/en/stable/indexes/langchain.indexes.base.RecordManager.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/indexes/langchain.indexes.base.RecordManager.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  40.48K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:27 (52.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/indexes/langchain.indexes.base.RecordManager.html’ saved [41449]\n",
            "\n",
            "--2024-01-23 08:23:27--  https://api.python.langchain.com/en/stable/indexes/langchain.indexes.graph.GraphIndexCreator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/indexes/langchain.indexes.graph.GraphIndexCreator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  53.41K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:27 (47.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/indexes/langchain.indexes.graph.GraphIndexCreator.html’ saved [54691]\n",
            "\n",
            "--2024-01-23 08:23:27--  https://api.python.langchain.com/en/stable/indexes/langchain.indexes.vectorstore.VectorStoreIndexWrapper.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/indexes/langchain.indexes.vectorstore.VectorStoreIndexWrapper.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  44.33K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:28 (254 MB/s) - ‘docs/api.python.langchain.com/en/stable/indexes/langchain.indexes.vectorstore.VectorStoreIndexWrapper.html’ saved [45390]\n",
            "\n",
            "--2024-01-23 08:23:28--  https://api.python.langchain.com/en/stable/indexes/langchain.indexes.vectorstore.VectorstoreIndexCreator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/indexes/langchain.indexes.vectorstore.VectorstoreIndexCreator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  46.45K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:28 (42.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/indexes/langchain.indexes.vectorstore.VectorstoreIndexCreator.html’ saved [47561]\n",
            "\n",
            "--2024-01-23 08:23:28--  https://api.python.langchain.com/en/stable/memory/langchain.memory.buffer.ConversationBufferMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.buffer.ConversationBufferMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  58.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:28 (247 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.buffer.ConversationBufferMemory.html’ saved [59629]\n",
            "\n",
            "--2024-01-23 08:23:28--  https://api.python.langchain.com/en/stable/memory/langchain.memory.buffer.ConversationStringBufferMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.buffer.ConversationStringBufferMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  53.15K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:28 (38.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.buffer.ConversationStringBufferMemory.html’ saved [54426]\n",
            "\n",
            "--2024-01-23 08:23:28--  https://api.python.langchain.com/en/stable/memory/langchain.memory.buffer_window.ConversationBufferWindowMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.buffer_window.ConversationBufferWindowMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  57.88K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:28 (55.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.buffer_window.ConversationBufferWindowMemory.html’ saved [59267]\n",
            "\n",
            "--2024-01-23 08:23:28--  https://api.python.langchain.com/en/stable/memory/langchain.memory.chat_memory.BaseChatMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.chat_memory.BaseChatMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  51.93K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:28 (41.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.chat_memory.BaseChatMemory.html’ saved [53177]\n",
            "\n",
            "--2024-01-23 08:23:28--  https://api.python.langchain.com/en/stable/memory/langchain.memory.combined.CombinedMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.combined.CombinedMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  49.86K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:28 (39.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.combined.CombinedMemory.html’ saved [51056]\n",
            "\n",
            "--2024-01-23 08:23:28--  https://api.python.langchain.com/en/stable/memory/langchain.memory.entity.BaseEntityStore.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.entity.BaseEntityStore.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  43.43K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:29 (42.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.entity.BaseEntityStore.html’ saved [44475]\n",
            "\n",
            "--2024-01-23 08:23:29--  https://api.python.langchain.com/en/stable/memory/langchain.memory.entity.ConversationEntityMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.entity.ConversationEntityMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  73.15K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:23:29 (41.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.entity.ConversationEntityMemory.html’ saved [74903]\n",
            "\n",
            "--2024-01-23 08:23:29--  https://api.python.langchain.com/en/stable/memory/langchain.memory.entity.InMemoryEntityStore.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.entity.InMemoryEntityStore.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  44.32K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:29 (54.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.entity.InMemoryEntityStore.html’ saved [45386]\n",
            "\n",
            "--2024-01-23 08:23:29--  https://api.python.langchain.com/en/stable/memory/langchain.memory.entity.RedisEntityStore.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.entity.RedisEntityStore.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  47.53K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:29 (50.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.entity.RedisEntityStore.html’ saved [48669]\n",
            "\n",
            "--2024-01-23 08:23:29--  https://api.python.langchain.com/en/stable/memory/langchain.memory.entity.SQLiteEntityStore.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.entity.SQLiteEntityStore.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  45.46K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:29 (42.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.entity.SQLiteEntityStore.html’ saved [46556]\n",
            "\n",
            "--2024-01-23 08:23:29--  https://api.python.langchain.com/en/stable/memory/langchain.memory.entity.UpstashRedisEntityStore.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.entity.UpstashRedisEntityStore.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  44.17K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:30 (40.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.entity.UpstashRedisEntityStore.html’ saved [45231]\n",
            "\n",
            "--2024-01-23 08:23:30--  https://api.python.langchain.com/en/stable/memory/langchain.memory.kg.ConversationKGMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.kg.ConversationKGMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  78.20K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-01-23 08:23:30 (10.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.kg.ConversationKGMemory.html’ saved [80077]\n",
            "\n",
            "--2024-01-23 08:23:30--  https://api.python.langchain.com/en/stable/memory/langchain.memory.motorhead_memory.MotorheadMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.motorhead_memory.MotorheadMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  59.40K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:30 (19.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.motorhead_memory.MotorheadMemory.html’ saved [60826]\n",
            "\n",
            "--2024-01-23 08:23:30--  https://api.python.langchain.com/en/stable/memory/langchain.memory.readonly.ReadOnlySharedMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.readonly.ReadOnlySharedMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  49.91K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:30 (39.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.readonly.ReadOnlySharedMemory.html’ saved [51104]\n",
            "\n",
            "--2024-01-23 08:23:30--  https://api.python.langchain.com/en/stable/memory/langchain.memory.simple.SimpleMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.simple.SimpleMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  49.23K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:30 (41.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.simple.SimpleMemory.html’ saved [50416]\n",
            "\n",
            "--2024-01-23 08:23:30--  https://api.python.langchain.com/en/stable/memory/langchain.memory.summary.ConversationSummaryMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.summary.ConversationSummaryMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  64.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:31 (131 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.summary.ConversationSummaryMemory.html’ saved [66108]\n",
            "\n",
            "--2024-01-23 08:23:31--  https://api.python.langchain.com/en/stable/memory/langchain.memory.summary.SummarizerMixin.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.summary.SummarizerMixin.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  46.58K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:31 (39.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.summary.SummarizerMixin.html’ saved [47695]\n",
            "\n",
            "--2024-01-23 08:23:31--  https://api.python.langchain.com/en/stable/memory/langchain.memory.summary_buffer.ConversationSummaryBufferMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.summary_buffer.ConversationSummaryBufferMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  66.12K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:23:31 (29.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.summary_buffer.ConversationSummaryBufferMemory.html’ saved [67711]\n",
            "\n",
            "--2024-01-23 08:23:31--  https://api.python.langchain.com/en/stable/memory/langchain.memory.token_buffer.ConversationTokenBufferMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.token_buffer.ConversationTokenBufferMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  58.40K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:31 (347 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.token_buffer.ConversationTokenBufferMemory.html’ saved [59798]\n",
            "\n",
            "--2024-01-23 08:23:31--  https://api.python.langchain.com/en/stable/memory/langchain.memory.vectorstore.VectorStoreRetrieverMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.vectorstore.VectorStoreRetrieverMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  54.47K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:31 (48.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.vectorstore.VectorStoreRetrieverMemory.html’ saved [55776]\n",
            "\n",
            "--2024-01-23 08:23:31--  https://api.python.langchain.com/en/stable/memory/langchain.memory.zep_memory.ZepMemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.zep_memory.ZepMemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  59.21K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:31 (44.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.zep_memory.ZepMemory.html’ saved [60632]\n",
            "\n",
            "--2024-01-23 08:23:31--  https://api.python.langchain.com/en/stable/memory/langchain.memory.utils.get_prompt_input_key.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.utils.get_prompt_input_key.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.76K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:32 (285 MB/s) - ‘docs/api.python.langchain.com/en/stable/memory/langchain.memory.utils.get_prompt_input_key.html’ saved [12038]\n",
            "\n",
            "--2024-01-23 08:23:32--  https://api.python.langchain.com/en/stable/model_laboratory/langchain.model_laboratory.ModelLaboratory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/model_laboratory/langchain.model_laboratory.ModelLaboratory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:32 (45.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/model_laboratory/langchain.model_laboratory.ModelLaboratory.html’ saved [19931]\n",
            "\n",
            "--2024-01-23 08:23:32--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.boolean.BooleanOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.boolean.BooleanOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 124.20K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-01-23 08:23:32 (18.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.boolean.BooleanOutputParser.html’ saved [127182]\n",
            "\n",
            "--2024-01-23 08:23:32--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.combining.CombiningOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.combining.CombiningOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 124.40K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:32 (38.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.combining.CombiningOutputParser.html’ saved [127387]\n",
            "\n",
            "--2024-01-23 08:23:32--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.datetime.DatetimeOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.datetime.DatetimeOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 124.37K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:32 (34.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.datetime.DatetimeOutputParser.html’ saved [127351]\n",
            "\n",
            "--2024-01-23 08:23:32--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.enum.EnumOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.enum.EnumOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 123.13K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:33 (34.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.enum.EnumOutputParser.html’ saved [126089]\n",
            "\n",
            "--2024-01-23 08:23:33--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.JsonKeyOutputFunctionsParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.JsonKeyOutputFunctionsParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 129.24K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:33 (34.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.JsonKeyOutputFunctionsParser.html’ saved [132342]\n",
            "\n",
            "--2024-01-23 08:23:33--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.JsonOutputFunctionsParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.JsonOutputFunctionsParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 128.31K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:33 (38.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.JsonOutputFunctionsParser.html’ saved [131388]\n",
            "\n",
            "--2024-01-23 08:23:33--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.OutputFunctionsParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.OutputFunctionsParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 123.06K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:33 (37.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.OutputFunctionsParser.html’ saved [126011]\n",
            "\n",
            "--2024-01-23 08:23:33--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.PydanticAttrOutputFunctionsParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.PydanticAttrOutputFunctionsParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 126.59K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:33 (38.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.PydanticAttrOutputFunctionsParser.html’ saved [129625]\n",
            "\n",
            "--2024-01-23 08:23:33--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.PydanticOutputFunctionsParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.PydanticOutputFunctionsParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 125.35K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:33 (39.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.ernie_functions.PydanticOutputFunctionsParser.html’ saved [128361]\n",
            "\n",
            "--2024-01-23 08:23:33--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.fix.OutputFixingParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.fix.OutputFixingParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 130.21K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:34 (130 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.fix.OutputFixingParser.html’ saved [133338]\n",
            "\n",
            "--2024-01-23 08:23:34--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.JsonKeyOutputFunctionsParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.JsonKeyOutputFunctionsParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 129.38K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:23:34 (57.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.JsonKeyOutputFunctionsParser.html’ saved [132480]\n",
            "\n",
            "--2024-01-23 08:23:34--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.JsonOutputFunctionsParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.JsonOutputFunctionsParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 128.44K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:34 (38.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.JsonOutputFunctionsParser.html’ saved [131522]\n",
            "\n",
            "--2024-01-23 08:23:34--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.OutputFunctionsParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.OutputFunctionsParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 123.17K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:34 (43.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.OutputFunctionsParser.html’ saved [126131]\n",
            "\n",
            "--2024-01-23 08:23:34--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.PydanticAttrOutputFunctionsParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.PydanticAttrOutputFunctionsParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 126.71K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:34 (36.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.PydanticAttrOutputFunctionsParser.html’ saved [129752]\n",
            "\n",
            "--2024-01-23 08:23:34--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.PydanticOutputFunctionsParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.PydanticOutputFunctionsParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 125.47K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:35 (41.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_functions.PydanticOutputFunctionsParser.html’ saved [128486]\n",
            "\n",
            "--2024-01-23 08:23:35--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_tools.JsonOutputKeyToolsParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_tools.JsonOutputKeyToolsParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 122.82K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:35 (34.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_tools.JsonOutputKeyToolsParser.html’ saved [125766]\n",
            "\n",
            "--2024-01-23 08:23:35--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_tools.JsonOutputToolsParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_tools.JsonOutputToolsParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 121.90K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:35 (34.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_tools.JsonOutputToolsParser.html’ saved [124827]\n",
            "\n",
            "--2024-01-23 08:23:35--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_tools.PydanticToolsParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_tools.PydanticToolsParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 122.46K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-01-23 08:23:35 (18.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.openai_tools.PydanticToolsParser.html’ saved [125395]\n",
            "\n",
            "--2024-01-23 08:23:35--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.pandas_dataframe.PandasDataFrameOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.pandas_dataframe.PandasDataFrameOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 127.66K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:35 (35.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.pandas_dataframe.PandasDataFrameOutputParser.html’ saved [130727]\n",
            "\n",
            "--2024-01-23 08:23:35--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.pydantic.PydanticOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.pydantic.PydanticOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 124.90K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:35 (37.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.pydantic.PydanticOutputParser.html’ saved [127901]\n",
            "\n",
            "--2024-01-23 08:23:35--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.rail_parser.GuardrailsOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.rail_parser.GuardrailsOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 135.36K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:36 (36.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.rail_parser.GuardrailsOutputParser.html’ saved [138608]\n",
            "\n",
            "--2024-01-23 08:23:36--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.regex.RegexParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.regex.RegexParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 124.69K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:36 (32.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.regex.RegexParser.html’ saved [127682]\n",
            "\n",
            "--2024-01-23 08:23:36--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.regex_dict.RegexDictParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.regex_dict.RegexDictParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 125.06K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-01-23 08:23:36 (19.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.regex_dict.RegexDictParser.html’ saved [128064]\n",
            "\n",
            "--2024-01-23 08:23:36--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.retry.RetryOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.retry.RetryOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 131.44K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:36 (37.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.retry.RetryOutputParser.html’ saved [134596]\n",
            "\n",
            "--2024-01-23 08:23:36--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.retry.RetryWithErrorOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.retry.RetryWithErrorOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 132.76K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:36 (38.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.retry.RetryWithErrorOutputParser.html’ saved [135946]\n",
            "\n",
            "--2024-01-23 08:23:36--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.structured.ResponseSchema.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.structured.ResponseSchema.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  40.05K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:36 (32.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.structured.ResponseSchema.html’ saved [41008]\n",
            "\n",
            "--2024-01-23 08:23:36--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.structured.StructuredOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.structured.StructuredOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 128.56K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:37 (40.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.structured.StructuredOutputParser.html’ saved [131646]\n",
            "\n",
            "--2024-01-23 08:23:37--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.yaml.YamlOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.yaml.YamlOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 123.85K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:37 (38.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.yaml.YamlOutputParser.html’ saved [126826]\n",
            "\n",
            "--2024-01-23 08:23:37--  https://api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.loading.load_output_parser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.loading.load_output_parser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.22K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:37 (142 MB/s) - ‘docs/api.python.langchain.com/en/stable/output_parsers/langchain.output_parsers.loading.load_output_parser.html’ saved [11485]\n",
            "\n",
            "--2024-01-23 08:23:37--  https://api.python.langchain.com/en/stable/prompts/langchain.prompts.example_selector.ngram_overlap.NGramOverlapExampleSelector.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/prompts/langchain.prompts.example_selector.ngram_overlap.NGramOverlapExampleSelector.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  45.72K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:37 (29.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/prompts/langchain.prompts.example_selector.ngram_overlap.NGramOverlapExampleSelector.html’ saved [46817]\n",
            "\n",
            "--2024-01-23 08:23:37--  https://api.python.langchain.com/en/stable/prompts/langchain.prompts.example_selector.ngram_overlap.ngram_overlap_score.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/prompts/langchain.prompts.example_selector.ngram_overlap.ngram_overlap_score.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:37 (183 MB/s) - ‘docs/api.python.langchain.com/en/stable/prompts/langchain.prompts.example_selector.ngram_overlap.ngram_overlap_score.html’ saved [12320]\n",
            "\n",
            "--2024-01-23 08:23:37--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.contextual_compression.ContextualCompressionRetriever.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.contextual_compression.ContextualCompressionRetriever.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 133.61K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:38 (38.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.contextual_compression.ContextualCompressionRetriever.html’ saved [136814]\n",
            "\n",
            "--2024-01-23 08:23:38--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.base.BaseDocumentCompressor.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.base.BaseDocumentCompressor.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  45.30K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:38 (273 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.base.BaseDocumentCompressor.html’ saved [46389]\n",
            "\n",
            "--2024-01-23 08:23:38--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.base.DocumentCompressorPipeline.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.base.DocumentCompressorPipeline.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  47.62K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:38 (49.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.base.DocumentCompressorPipeline.html’ saved [48767]\n",
            "\n",
            "--2024-01-23 08:23:38--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_extract.LLMChainExtractor.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_extract.LLMChainExtractor.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  51.85K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:38 (46.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_extract.LLMChainExtractor.html’ saved [53092]\n",
            "\n",
            "--2024-01-23 08:23:38--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_extract.NoOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_extract.NoOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 125.70K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:38 (37.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_extract.NoOutputParser.html’ saved [128717]\n",
            "\n",
            "--2024-01-23 08:23:38--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_filter.LLMChainFilter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_filter.LLMChainFilter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  50.68K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:38 (85.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_filter.LLMChainFilter.html’ saved [51899]\n",
            "\n",
            "--2024-01-23 08:23:38--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.cohere_rerank.CohereRerank.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.cohere_rerank.CohereRerank.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  50.05K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:38 (54.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.cohere_rerank.CohereRerank.html’ saved [51255]\n",
            "\n",
            "--2024-01-23 08:23:38--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.embeddings_filter.EmbeddingsFilter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.embeddings_filter.EmbeddingsFilter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  49.59K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:39 (50.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.embeddings_filter.EmbeddingsFilter.html’ saved [50785]\n",
            "\n",
            "--2024-01-23 08:23:39--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.ensemble.EnsembleRetriever.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.ensemble.EnsembleRetriever.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 137.89K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:39 (35.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.ensemble.EnsembleRetriever.html’ saved [141197]\n",
            "\n",
            "--2024-01-23 08:23:39--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.merger_retriever.MergerRetriever.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.merger_retriever.MergerRetriever.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 134.15K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:39 (38.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.merger_retriever.MergerRetriever.html’ saved [137374]\n",
            "\n",
            "--2024-01-23 08:23:39--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_query.LineList.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_query.LineList.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  38.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:39 (224 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_query.LineList.html’ saved [39339]\n",
            "\n",
            "--2024-01-23 08:23:39--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_query.LineListOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_query.LineListOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 123.72K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:39 (36.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_query.LineListOutputParser.html’ saved [126687]\n",
            "\n",
            "--2024-01-23 08:23:39--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 149.03K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:39 (36.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html’ saved [152602]\n",
            "\n",
            "--2024-01-23 08:23:39--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_vector.MultiVectorRetriever.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_vector.MultiVectorRetriever.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 135.06K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:39 (40.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_vector.MultiVectorRetriever.html’ saved [138298]\n",
            "\n",
            "--2024-01-23 08:23:39--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_vector.SearchType.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_vector.SearchType.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.97K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:40 (49.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.multi_vector.SearchType.html’ saved [13286]\n",
            "\n",
            "--2024-01-23 08:23:40--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.parent_document_retriever.ParentDocumentRetriever.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.parent_document_retriever.ParentDocumentRetriever.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 145.54K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:40 (40.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.parent_document_retriever.ParentDocumentRetriever.html’ saved [149032]\n",
            "\n",
            "--2024-01-23 08:23:40--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.re_phraser.RePhraseQueryRetriever.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.re_phraser.RePhraseQueryRetriever.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 135.03K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:40 (35.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.re_phraser.RePhraseQueryRetriever.html’ saved [138266]\n",
            "\n",
            "--2024-01-23 08:23:40--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.base.SelfQueryRetriever.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.base.SelfQueryRetriever.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 143.83K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:40 (35.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.base.SelfQueryRetriever.html’ saved [147282]\n",
            "\n",
            "--2024-01-23 08:23:40--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.chroma.ChromaTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.chroma.ChromaTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.37K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:40 (81.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.chroma.ChromaTranslator.html’ saved [17782]\n",
            "\n",
            "--2024-01-23 08:23:40--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.dashvector.DashvectorTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.dashvector.DashvectorTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.67K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:40 (37.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.dashvector.DashvectorTranslator.html’ saved [18095]\n",
            "\n",
            "--2024-01-23 08:23:40--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.deeplake.DeepLakeTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.deeplake.DeepLakeTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.48K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:41 (190 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.deeplake.DeepLakeTranslator.html’ saved [17902]\n",
            "\n",
            "--2024-01-23 08:23:41--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.elasticsearch.ElasticsearchTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.elasticsearch.ElasticsearchTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.78K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:41 (30.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.elasticsearch.ElasticsearchTranslator.html’ saved [18209]\n",
            "\n",
            "--2024-01-23 08:23:41--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.milvus.MilvusTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.milvus.MilvusTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.32K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:41 (28.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.milvus.MilvusTranslator.html’ saved [17731]\n",
            "\n",
            "--2024-01-23 08:23:41--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.mongodb_atlas.MongoDBAtlasTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.mongodb_atlas.MongoDBAtlasTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:41 (182 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.mongodb_atlas.MongoDBAtlasTranslator.html’ saved [18120]\n",
            "\n",
            "--2024-01-23 08:23:41--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.myscale.MyScaleTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.myscale.MyScaleTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.69K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:41 (59.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.myscale.MyScaleTranslator.html’ saved [19139]\n",
            "\n",
            "--2024-01-23 08:23:41--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.opensearch.OpenSearchTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.opensearch.OpenSearchTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:41 (75.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.opensearch.OpenSearchTranslator.html’ saved [18042]\n",
            "\n",
            "--2024-01-23 08:23:41--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.pinecone.PineconeTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.pinecone.PineconeTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.48K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:41 (30.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.pinecone.PineconeTranslator.html’ saved [17904]\n",
            "\n",
            "--2024-01-23 08:23:41--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.qdrant.QdrantTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.qdrant.QdrantTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.06K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:42 (120 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.qdrant.QdrantTranslator.html’ saved [18493]\n",
            "\n",
            "--2024-01-23 08:23:42--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.redis.RedisTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.redis.RedisTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.67K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:42 (48.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.redis.RedisTranslator.html’ saved [21164]\n",
            "\n",
            "--2024-01-23 08:23:42--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.supabase.SupabaseVectorTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.supabase.SupabaseVectorTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:42 (56.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.supabase.SupabaseVectorTranslator.html’ saved [18450]\n",
            "\n",
            "--2024-01-23 08:23:42--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.timescalevector.TimescaleVectorTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.timescalevector.TimescaleVectorTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:42 (54.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.timescalevector.TimescaleVectorTranslator.html’ saved [18621]\n",
            "\n",
            "--2024-01-23 08:23:42--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.vectara.VectaraTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.vectara.VectaraTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:42 (43.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.vectara.VectaraTranslator.html’ saved [17841]\n",
            "\n",
            "--2024-01-23 08:23:42--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.weaviate.WeaviateTranslator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.weaviate.WeaviateTranslator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.45K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:42 (142 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.weaviate.WeaviateTranslator.html’ saved [17866]\n",
            "\n",
            "--2024-01-23 08:23:42--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.time_weighted_retriever.TimeWeightedVectorStoreRetriever.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.time_weighted_retriever.TimeWeightedVectorStoreRetriever.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 143.64K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:43 (36.8 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.time_weighted_retriever.TimeWeightedVectorStoreRetriever.html’ saved [147085]\n",
            "\n",
            "--2024-01-23 08:23:43--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.web_research.LineList.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.web_research.LineList.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  38.43K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:43 (46.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.web_research.LineList.html’ saved [39354]\n",
            "\n",
            "--2024-01-23 08:23:43--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.web_research.QuestionListOutputParser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.web_research.QuestionListOutputParser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 124.36K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-01-23 08:23:43 (43.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.web_research.QuestionListOutputParser.html’ saved [127343]\n",
            "\n",
            "--2024-01-23 08:23:43--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.web_research.SearchQueries.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.web_research.SearchQueries.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  38.68K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:43 (57.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.web_research.SearchQueries.html’ saved [39610]\n",
            "\n",
            "--2024-01-23 08:23:43--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.web_research.WebResearchRetriever.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.web_research.WebResearchRetriever.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 139.95K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-01-23 08:23:43 (20.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.web_research.WebResearchRetriever.html’ saved [143304]\n",
            "\n",
            "--2024-01-23 08:23:43--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_extract.default_get_input.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_extract.default_get_input.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.81K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:44 (50.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_extract.default_get_input.html’ saved [12090]\n",
            "\n",
            "--2024-01-23 08:23:44--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_filter.default_get_input.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_filter.default_get_input.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.80K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:44 (127 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.document_compressors.chain_filter.default_get_input.html’ saved [12079]\n",
            "\n",
            "--2024-01-23 08:23:44--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.deeplake.can_cast_to_float.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.deeplake.can_cast_to_float.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:44 (136 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.deeplake.can_cast_to_float.html’ saved [11312]\n",
            "\n",
            "--2024-01-23 08:23:44--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.milvus.process_value.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.milvus.process_value.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.64K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:44 (103 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.milvus.process_value.html’ saved [11921]\n",
            "\n",
            "--2024-01-23 08:23:44--  https://api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.vectara.process_value.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.vectara.process_value.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.34K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:44 (149 MB/s) - ‘docs/api.python.langchain.com/en/stable/retrievers/langchain.retrievers.self_query.vectara.process_value.html’ saved [11614]\n",
            "\n",
            "--2024-01-23 08:23:44--  https://api.python.langchain.com/en/stable/runnables/langchain.runnables.hub.HubRunnable.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/runnables/langchain.runnables.hub.HubRunnable.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 122.06K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:44 (146 MB/s) - ‘docs/api.python.langchain.com/en/stable/runnables/langchain.runnables.hub.HubRunnable.html’ saved [124991]\n",
            "\n",
            "--2024-01-23 08:23:44--  https://api.python.langchain.com/en/stable/runnables/langchain.runnables.openai_functions.OpenAIFunction.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/runnables/langchain.runnables.openai_functions.OpenAIFunction.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.56K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:45 (48.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/runnables/langchain.runnables.openai_functions.OpenAIFunction.html’ saved [26178]\n",
            "\n",
            "--2024-01-23 08:23:45--  https://api.python.langchain.com/en/stable/runnables/langchain.runnables.openai_functions.OpenAIFunctionsRouter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/runnables/langchain.runnables.openai_functions.OpenAIFunctionsRouter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 125.67K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-01-23 08:23:45 (34.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/runnables/langchain.runnables.openai_functions.OpenAIFunctionsRouter.html’ saved [128684]\n",
            "\n",
            "--2024-01-23 08:23:45--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.arun_on_dataset.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.arun_on_dataset.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.90K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:45 (48.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.arun_on_dataset.html’ saved [27548]\n",
            "\n",
            "--2024-01-23 08:23:45--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.run_on_dataset.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.run_on_dataset.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.79K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:45 (35.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.run_on_dataset.html’ saved [27432]\n",
            "\n",
            "--2024-01-23 08:23:45--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.config.RunEvalConfig.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.config.RunEvalConfig.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 519.12K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-01-23 08:23:45 (38.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.config.RunEvalConfig.html’ saved [531582]\n",
            "\n",
            "--2024-01-23 08:23:45--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.config.EvalConfig.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.config.EvalConfig.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  40.79K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:45 (42.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.config.EvalConfig.html’ saved [41771]\n",
            "\n",
            "--2024-01-23 08:23:45--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.config.SingleKeyEvalConfig.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.config.SingleKeyEvalConfig.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  43.39K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:45 (46.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.config.SingleKeyEvalConfig.html’ saved [44429]\n",
            "\n",
            "--2024-01-23 08:23:45--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.progress.ProgressBarCallback.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.progress.ProgressBarCallback.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  72.14K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:23:45 (41.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.progress.ProgressBarCallback.html’ saved [73868]\n",
            "\n",
            "--2024-01-23 08:23:45--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.EvalError.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.EvalError.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.75K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:46 (44.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.EvalError.html’ saved [26367]\n",
            "\n",
            "--2024-01-23 08:23:46--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.InputFormatError.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.InputFormatError.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  10.68K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:46 (141 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.InputFormatError.html’ saved [10938]\n",
            "\n",
            "--2024-01-23 08:23:46--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.TestResult.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.TestResult.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:46 (57.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.runner_utils.TestResult.html’ saved [28095]\n",
            "\n",
            "--2024-01-23 08:23:46--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.ChainStringRunMapper.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.ChainStringRunMapper.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  50.48K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:46 (60.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.ChainStringRunMapper.html’ saved [51688]\n",
            "\n",
            "--2024-01-23 08:23:46--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.LLMStringRunMapper.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.LLMStringRunMapper.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  51.50K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:46 (49.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.LLMStringRunMapper.html’ saved [52741]\n",
            "\n",
            "--2024-01-23 08:23:46--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.StringExampleMapper.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.StringExampleMapper.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  50.65K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-01-23 08:23:46 (20.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.StringExampleMapper.html’ saved [51864]\n",
            "\n",
            "--2024-01-23 08:23:46--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.StringRunEvaluatorChain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.StringRunEvaluatorChain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 174.04K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 08:23:47 (34.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.StringRunEvaluatorChain.html’ saved [178220]\n",
            "\n",
            "--2024-01-23 08:23:47--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.StringRunMapper.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.StringRunMapper.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  48.35K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:47 (49.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.StringRunMapper.html’ saved [49506]\n",
            "\n",
            "--2024-01-23 08:23:47--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.ToolStringRunMapper.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.ToolStringRunMapper.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  48.32K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:47 (52.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.string_run_evaluator.ToolStringRunMapper.html’ saved [49476]\n",
            "\n",
            "--2024-01-23 08:23:47--  https://api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.name_generation.random_name.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.name_generation.random_name.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  10.78K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:47 (154 MB/s) - ‘docs/api.python.langchain.com/en/stable/smith/langchain.smith.evaluation.name_generation.random_name.html’ saved [11034]\n",
            "\n",
            "--2024-01-23 08:23:47--  https://api.python.langchain.com/en/stable/storage/langchain.storage.encoder_backed.EncoderBackedStore.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/storage/langchain.storage.encoder_backed.EncoderBackedStore.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.94K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:47 (74.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/storage/langchain.storage.encoder_backed.EncoderBackedStore.html’ saved [27587]\n",
            "\n",
            "--2024-01-23 08:23:47--  https://api.python.langchain.com/en/stable/storage/langchain.storage.file_system.LocalFileStore.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/storage/langchain.storage.file_system.LocalFileStore.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  23.67K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:47 (44.2 MB/s) - ‘docs/api.python.langchain.com/en/stable/storage/langchain.storage.file_system.LocalFileStore.html’ saved [24242]\n",
            "\n",
            "--2024-01-23 08:23:47--  https://api.python.langchain.com/en/stable/storage/langchain.storage.in_memory.InMemoryBaseStore.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/storage/langchain.storage.in_memory.InMemoryBaseStore.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.05K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:47 (28.4 MB/s) - ‘docs/api.python.langchain.com/en/stable/storage/langchain.storage.in_memory.InMemoryBaseStore.html’ saved [22577]\n",
            "\n",
            "--2024-01-23 08:23:47--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.CharacterTextSplitter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.CharacterTextSplitter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  40.36K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:48 (93.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.CharacterTextSplitter.html’ saved [41325]\n",
            "\n",
            "--2024-01-23 08:23:48--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.ElementType.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.ElementType.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:48 (152 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.ElementType.html’ saved [12831]\n",
            "\n",
            "--2024-01-23 08:23:48--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.HTMLHeaderTextSplitter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.HTMLHeaderTextSplitter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.47K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:48 (215 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.HTMLHeaderTextSplitter.html’ saved [23012]\n",
            "\n",
            "--2024-01-23 08:23:48--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.HeaderType.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.HeaderType.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.85K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:48 (139 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.HeaderType.html’ saved [12133]\n",
            "\n",
            "--2024-01-23 08:23:48--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.Language.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.Language.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.28K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:48 (146 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.Language.html’ saved [21789]\n",
            "\n",
            "--2024-01-23 08:23:48--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.LatexTextSplitter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.LatexTextSplitter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  31.21K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:48 (231 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.LatexTextSplitter.html’ saved [31960]\n",
            "\n",
            "--2024-01-23 08:23:48--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.LineType.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.LineType.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.64K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:48 (159 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.LineType.html’ saved [11915]\n",
            "\n",
            "--2024-01-23 08:23:48--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.MarkdownHeaderTextSplitter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.MarkdownHeaderTextSplitter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.95K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:49 (31.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.MarkdownHeaderTextSplitter.html’ saved [19406]\n",
            "\n",
            "--2024-01-23 08:23:49--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.MarkdownTextSplitter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.MarkdownTextSplitter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  31.37K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:49 (46.5 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.MarkdownTextSplitter.html’ saved [32121]\n",
            "\n",
            "--2024-01-23 08:23:49--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.NLTKTextSplitter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.NLTKTextSplitter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.79K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:49 (33.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.NLTKTextSplitter.html’ saved [30505]\n",
            "\n",
            "--2024-01-23 08:23:49--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.PythonCodeTextSplitter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.PythonCodeTextSplitter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  31.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:49 (70.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.PythonCodeTextSplitter.html’ saved [32217]\n",
            "\n",
            "--2024-01-23 08:23:49--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  38.21K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:49 (54.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html’ saved [39124]\n",
            "\n",
            "--2024-01-23 08:23:49--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.SentenceTransformersTokenTextSplitter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.SentenceTransformersTokenTextSplitter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  33.25K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:50 (54.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.SentenceTransformersTokenTextSplitter.html’ saved [34045]\n",
            "\n",
            "--2024-01-23 08:23:50--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.SpacyTextSplitter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.SpacyTextSplitter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  31.17K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:50 (36.6 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.SpacyTextSplitter.html’ saved [31918]\n",
            "\n",
            "--2024-01-23 08:23:50--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.TextSplitter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.TextSplitter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  31.71K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:50 (322 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.TextSplitter.html’ saved [32473]\n",
            "\n",
            "--2024-01-23 08:23:50--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.TokenTextSplitter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.TokenTextSplitter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  33.74K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:50 (38.9 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.TokenTextSplitter.html’ saved [34547]\n",
            "\n",
            "--2024-01-23 08:23:50--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.Tokenizer.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.Tokenizer.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.07K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:50 (95.1 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.Tokenizer.html’ saved [16455]\n",
            "\n",
            "--2024-01-23 08:23:50--  https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.split_text_on_tokens.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.split_text_on_tokens.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.61K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:50 (165 MB/s) - ‘docs/api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.split_text_on_tokens.html’ saved [11887]\n",
            "\n",
            "--2024-01-23 08:23:50--  https://api.python.langchain.com/en/stable/tools/langchain.tools.retriever.RetrieverInput.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/tools/langchain.tools.retriever.RetrieverInput.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  38.25K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-01-23 08:23:50 (58.3 MB/s) - ‘docs/api.python.langchain.com/en/stable/tools/langchain.tools.retriever.RetrieverInput.html’ saved [39168]\n",
            "\n",
            "--2024-01-23 08:23:50--  https://api.python.langchain.com/en/stable/tools/langchain.tools.render.render_text_description.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/tools/langchain.tools.render.render_text_description.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.40K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:51 (153 MB/s) - ‘docs/api.python.langchain.com/en/stable/tools/langchain.tools.render.render_text_description.html’ saved [11675]\n",
            "\n",
            "--2024-01-23 08:23:51--  https://api.python.langchain.com/en/stable/tools/langchain.tools.render.render_text_description_and_args.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/tools/langchain.tools.render.render_text_description_and_args.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.64K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:51 (147 MB/s) - ‘docs/api.python.langchain.com/en/stable/tools/langchain.tools.render.render_text_description_and_args.html’ saved [11920]\n",
            "\n",
            "--2024-01-23 08:23:51--  https://api.python.langchain.com/en/stable/tools/langchain.tools.retriever.create_retriever_tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/tools/langchain.tools.retriever.create_retriever_tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  13.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:51 (43.0 MB/s) - ‘docs/api.python.langchain.com/en/stable/tools/langchain.tools.retriever.create_retriever_tool.html’ saved [13346]\n",
            "\n",
            "--2024-01-23 08:23:51--  https://api.python.langchain.com/en/stable/utils/langchain.utils.ernie_functions.FunctionDescription.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/utils/langchain.utils.ernie_functions.FunctionDescription.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:51 (181 MB/s) - ‘docs/api.python.langchain.com/en/stable/utils/langchain.utils.ernie_functions.FunctionDescription.html’ saved [12446]\n",
            "\n",
            "--2024-01-23 08:23:51--  https://api.python.langchain.com/en/stable/utils/langchain.utils.ernie_functions.ToolDescription.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/utils/langchain.utils.ernie_functions.ToolDescription.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  11.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:51 (240 MB/s) - ‘docs/api.python.langchain.com/en/stable/utils/langchain.utils.ernie_functions.ToolDescription.html’ saved [12200]\n",
            "\n",
            "--2024-01-23 08:23:51--  https://api.python.langchain.com/en/stable/utils/langchain.utils.ernie_functions.convert_pydantic_to_ernie_function.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/utils/langchain.utils.ernie_functions.convert_pydantic_to_ernie_function.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:51 (47.7 MB/s) - ‘docs/api.python.langchain.com/en/stable/utils/langchain.utils.ernie_functions.convert_pydantic_to_ernie_function.html’ saved [12855]\n",
            "\n",
            "--2024-01-23 08:23:51--  https://api.python.langchain.com/en/stable/utils/langchain.utils.ernie_functions.convert_pydantic_to_ernie_tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘docs/api.python.langchain.com/en/stable/utils/langchain.utils.ernie_functions.convert_pydantic_to_ernie_tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  12.50K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-23 08:23:52 (211 MB/s) - ‘docs/api.python.langchain.com/en/stable/utils/langchain.utils.ernie_functions.convert_pydantic_to_ernie_tool.html’ saved [12795]\n",
            "\n",
            "FINISHED --2024-01-23 08:23:52--\n",
            "Total wall clock time: 1m 31s\n",
            "Downloaded: 424 files, 32M in 0.9s (36.8 MB/s)\n"
          ]
        }
      ],
      "source": [
        "!wget -r -l1 -A.html -P docs https://api.python.langchain.com/en/stable/langchain_api_reference.html"
      ],
      "id": "qiodFLkaLUsF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWa9M6JLb8O"
      },
      "source": [
        " The docs are going to be used as input text for answering questions that a normal language model might not be aware of (LangChain docs is not necessarily part of its training data of Llama2). We can use LangChain itself to process these docs. Use the [ReadTheDocsLoader](https://python.langchain.com/docs/integrations/document_loaders/readthedocs_documentation) to load the docs from the `docs` folder.\n",
        "\n",
        " At the time of creating this notebook, there  `423` documents were downloaded. However, since the documentation is being updated regularly this number might be different for you."
      ],
      "id": "5DWa9M6JLb8O"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Nd8ufORKLVy0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee104da-fc4f-404b-cb49-9995c22676bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "423"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from langchain.document_loaders import ReadTheDocsLoader\n",
        "#### your code ####\n",
        "loader = ReadTheDocsLoader(\"docs\")\n",
        "docs = loader.load()\n",
        "#### your code ####\n",
        "len(docs)"
      ],
      "id": "Nd8ufORKLVy0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKs0_OrBMQ7M"
      },
      "source": [
        "Let's take a look at one of the documents. You see that LangChain has created a `Document` object. Look at the example below and fill in the cells to print out the text content and URL of the page (the URL of the page should starts with `https://`)."
      ],
      "id": "yKs0_OrBMQ7M"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vcpuudNRLV7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b6da597-b5b2-42c6-e819-174013ce6cd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='langchain_experimental 0.0.47¶\\nlangchain_experimental.agents¶\\nFunctions¶\\nagents.agent_toolkits.csv.base.create_csv_agent(...)\\nCreate csv agent by loading to a dataframe and using pandas agent.\\nagents.agent_toolkits.pandas.base.create_pandas_dataframe_agent(llm,\\xa0df)\\nConstruct a pandas agent from an LLM and dataframe.\\nagents.agent_toolkits.python.base.create_python_agent(...)\\nConstruct a python agent from an LLM and tool.\\nagents.agent_toolkits.spark.base.create_spark_dataframe_agent(llm,\\xa0df)\\nConstruct a Spark agent from an LLM and dataframe.\\nagents.agent_toolkits.xorbits.base.create_xorbits_agent(...)\\nConstruct a xorbits agent from an LLM and dataframe.\\nlangchain_experimental.autonomous_agents¶\\nClasses¶\\nautonomous_agents.autogpt.agent.AutoGPT(...)\\nAgent class for interacting with Auto-GPT.\\nautonomous_agents.autogpt.memory.AutoGPTMemory\\nMemory for AutoGPT.\\nautonomous_agents.autogpt.output_parser.AutoGPTAction(...)\\nAction returned by AutoGPTOutputParser.\\nautonomous_agents.autogpt.output_parser.AutoGPTOutputParser\\nOutput parser for AutoGPT.\\nautonomous_agents.autogpt.output_parser.BaseAutoGPTOutputParser\\nBase Output parser for AutoGPT.\\nautonomous_agents.autogpt.prompt.AutoGPTPrompt\\nPrompt for AutoGPT.\\nautonomous_agents.autogpt.prompt_generator.PromptGenerator()\\nA class for generating custom prompt strings.\\nautonomous_agents.baby_agi.baby_agi.BabyAGI\\nController model for the BabyAGI agent.\\nautonomous_agents.baby_agi.task_creation.TaskCreationChain\\nChain generating tasks.\\nautonomous_agents.baby_agi.task_execution.TaskExecutionChain\\nChain to execute tasks.\\nautonomous_agents.baby_agi.task_prioritization.TaskPrioritizationChain\\nChain to prioritize tasks.\\nautonomous_agents.hugginggpt.hugginggpt.HuggingGPT(...)\\nautonomous_agents.hugginggpt.repsonse_generator.ResponseGenerationChain\\nChain to execute tasks.\\nautonomous_agents.hugginggpt.repsonse_generator.ResponseGenerator(...)\\nautonomous_agents.hugginggpt.task_executor.Task(...)\\nautonomous_agents.hugginggpt.task_executor.TaskExecutor(plan)\\nLoad tools to execute tasks.\\nautonomous_agents.hugginggpt.task_planner.BasePlanner\\nCreate a new model by parsing and validating input data from keyword arguments.\\nautonomous_agents.hugginggpt.task_planner.Plan(steps)\\nautonomous_agents.hugginggpt.task_planner.PlanningOutputParser\\nCreate a new model by parsing and validating input data from keyword arguments.\\nautonomous_agents.hugginggpt.task_planner.Step(...)\\nautonomous_agents.hugginggpt.task_planner.TaskPlaningChain\\nChain to execute tasks.\\nautonomous_agents.hugginggpt.task_planner.TaskPlanner\\nCreate a new model by parsing and validating input data from keyword arguments.\\nFunctions¶\\nautonomous_agents.autogpt.output_parser.preprocess_json_input(...)\\nPreprocesses a string to be parsed as json.\\nautonomous_agents.autogpt.prompt_generator.get_prompt(tools)\\nGenerates a prompt string.\\nautonomous_agents.hugginggpt.repsonse_generator.load_response_generator(llm)\\nautonomous_agents.hugginggpt.task_planner.load_chat_planner(llm)\\nlangchain_experimental.chat_models¶\\nChat Models are a variation on language models.\\nWhile Chat Models use language models under the hood, the interface they expose\\nis a bit different. Rather than expose a “text in, text out” API, they expose\\nan interface where “chat messages” are the inputs and outputs.\\nClass hierarchy:\\nBaseLanguageModel --> BaseChatModel --> <name>  # Examples: ChatOpenAI, ChatGooglePalm\\nMain helpers:\\nAIMessage, BaseMessage, HumanMessage\\nClasses¶\\nchat_models.llm_wrapper.ChatWrapper\\nCreate a new model by parsing and validating input data from keyword arguments.\\nchat_models.llm_wrapper.Llama2Chat\\nCreate a new model by parsing and validating input data from keyword arguments.\\nchat_models.llm_wrapper.Orca\\nCreate a new model by parsing and validating input data from keyword arguments.\\nchat_models.llm_wrapper.Vicuna\\nCreate a new model by parsing and validating input data from keyword arguments.\\nlangchain_experimental.comprehend_moderation¶\\nClasses¶\\ncomprehend_moderation.amazon_comprehend_moderation.AmazonComprehendModerationChain\\nA subclass of Chain, designed to apply moderation to LLMs.\\ncomprehend_moderation.base_moderation.BaseModeration(client)\\ncomprehend_moderation.base_moderation_callbacks.BaseModerationCallbackHandler()\\ncomprehend_moderation.base_moderation_config.BaseModerationConfig\\nCreate a new model by parsing and validating input data from keyword arguments.\\ncomprehend_moderation.base_moderation_config.ModerationPiiConfig\\nCreate a new model by parsing and validating input data from keyword arguments.\\ncomprehend_moderation.base_moderation_config.ModerationPromptSafetyConfig\\nCreate a new model by parsing and validating input data from keyword arguments.\\ncomprehend_moderation.base_moderation_config.ModerationToxicityConfig\\nCreate a new model by parsing and validating input data from keyword arguments.\\ncomprehend_moderation.base_moderation_exceptions.ModerationPiiError([...])\\nException raised if PII entities are detected.\\ncomprehend_moderation.base_moderation_exceptions.ModerationPromptSafetyError([...])\\nException raised if Intention entities are detected.\\ncomprehend_moderation.base_moderation_exceptions.ModerationToxicityError([...])\\nException raised if Toxic entities are detected.\\ncomprehend_moderation.pii.ComprehendPII(client)\\ncomprehend_moderation.prompt_safety.ComprehendPromptSafety(client)\\ncomprehend_moderation.toxicity.ComprehendToxicity(client)\\nlangchain_experimental.cpal¶\\nClasses¶\\ncpal.base.CPALChain\\nCausal program-aided language (CPAL) chain implementation.\\ncpal.base.CausalChain\\nTranslate the causal narrative into a stack of operations.\\ncpal.base.InterventionChain\\nSet the hypothetical conditions for the causal model.\\ncpal.base.NarrativeChain\\nDecompose the narrative into its story elements\\ncpal.base.QueryChain\\nQuery the outcome table using SQL.\\ncpal.constants.Constant(value[,\\xa0names,\\xa0...])\\nEnum for constants used in the CPAL.\\ncpal.models.CausalModel\\nCreate a new model by parsing and validating input data from keyword arguments.\\ncpal.models.EntityModel\\nCreate a new model by parsing and validating input data from keyword arguments.\\ncpal.models.EntitySettingModel\\nInitial conditions for an entity\\ncpal.models.InterventionModel\\naka initial conditions\\ncpal.models.NarrativeModel\\nRepresent the narrative input as three story elements.\\ncpal.models.QueryModel\\ntranslate a question about the story outcome into a programmatic expression\\ncpal.models.ResultModel\\nCreate a new model by parsing and validating input data from keyword arguments.\\ncpal.models.StoryModel\\nCreate a new model by parsing and validating input data from keyword arguments.\\ncpal.models.SystemSettingModel\\nInitial global conditions for the system.\\nlangchain_experimental.data_anonymizer¶\\nData anonymizer package\\nClasses¶\\ndata_anonymizer.base.AnonymizerBase()\\nBase abstract class for anonymizers. It is public and non-virtual because it allows     wrapping the behavior for all methods in a base class.\\ndata_anonymizer.base.ReversibleAnonymizerBase()\\nBase abstract class for reversible anonymizers.\\ndata_anonymizer.deanonymizer_mapping.DeanonymizerMapping(...)\\ndata_anonymizer.presidio.PresidioAnonymizer([...])\\nparam analyzed_fields\\nList of fields to detect and then anonymize.\\ndata_anonymizer.presidio.PresidioAnonymizerBase([...])\\nparam analyzed_fields\\nList of fields to detect and then anonymize.\\ndata_anonymizer.presidio.PresidioReversibleAnonymizer([...])\\nparam analyzed_fields\\nList of fields to detect and then anonymize.\\nFunctions¶\\ndata_anonymizer.deanonymizer_mapping.create_anonymizer_mapping(...)\\nCreates or updates the mapping used to anonymize and/or deanonymize text.\\ndata_anonymizer.deanonymizer_mapping.format_duplicated_operator(...)\\nFormat the operator name with the count\\ndata_anonymizer.deanonymizer_matching_strategies.case_insensitive_matching_strategy(...)\\nCase insensitive matching strategy for deanonymization. It replaces all the anonymized entities with the original ones     irrespective of their letter case.\\ndata_anonymizer.deanonymizer_matching_strategies.combined_exact_fuzzy_matching_strategy(...)\\nRECOMMENDED STRATEGY.\\ndata_anonymizer.deanonymizer_matching_strategies.exact_matching_strategy(...)\\nExact matching strategy for deanonymization.\\ndata_anonymizer.deanonymizer_matching_strategies.fuzzy_matching_strategy(...)\\nFuzzy matching strategy for deanonymization.\\ndata_anonymizer.deanonymizer_matching_strategies.ngram_fuzzy_matching_strategy(...)\\nN-gram fuzzy matching strategy for deanonymization.\\ndata_anonymizer.faker_presidio_mapping.get_pseudoanonymizer_mapping([seed])\\nlangchain_experimental.fallacy_removal¶\\nThe Chain runs a self-review of logical fallacies as determined by this paper  categorizing and defining logical fallacies https://arxiv.org/pdf/2212.07425.pdf. Modeled after Constitutional AI and in same format, but applying logical fallacies as generalized rules to remove in output\\nClasses¶\\nfallacy_removal.base.FallacyChain\\nChain for applying logical fallacy evaluations, modeled after Constitutional AI     and in same format, but applying logical fallacies as generalized rules to remove     in output\\nfallacy_removal.models.LogicalFallacy\\nClass for a logical fallacy.\\nlangchain_experimental.generative_agents¶\\nGenerative Agents primitives.\\nClasses¶\\ngenerative_agents.generative_agent.GenerativeAgent\\nAn Agent as a character with memory and innate characteristics.\\ngenerative_agents.memory.GenerativeAgentMemory\\nMemory for the generative agent.\\nlangchain_experimental.graph_transformers¶\\nClasses¶\\ngraph_transformers.diffbot.DiffbotGraphTransformer([...])\\nTransforms documents into graph documents using Diffbot\\'s NLP API.\\ngraph_transformers.diffbot.NodesList()\\nManages a list of nodes with associated properties.\\ngraph_transformers.diffbot.SimplifiedSchema()\\nProvides functionality for working with a simplified schema mapping.\\nFunctions¶\\ngraph_transformers.diffbot.format_property_key(s)\\nlangchain_experimental.llm_bash¶\\nChain that interprets a prompt and executes bash code to perform bash operations.\\nClasses¶\\nllm_bash.base.LLMBashChain\\nChain that interprets a prompt and executes bash operations.\\nllm_bash.bash.BashProcess([strip_newlines,\\xa0...])\\nWrapper class for starting subprocesses.\\nllm_bash.prompt.BashOutputParser\\nParser for bash output.\\nlangchain_experimental.llm_symbolic_math¶\\nChain that interprets a prompt and executes python code to do math.\\nHeavily borrowed from llm_math, wrapper for SymPy\\nClasses¶\\nllm_symbolic_math.base.LLMSymbolicMathChain\\nChain that interprets a prompt and executes python code to do symbolic math.\\nlangchain_experimental.llms¶\\nExperimental LLM wrappers.\\nClasses¶\\nllms.anthropic_functions.AnthropicFunctions\\nCreate a new model by parsing and validating input data from keyword arguments.\\nllms.anthropic_functions.TagParser()\\nA heavy-handed solution, but it\\'s fast for prototyping.\\nllms.jsonformer_decoder.JsonFormer\\nJsonformer wrapped LLM using HuggingFace Pipeline API.\\nllms.llamaapi.ChatLlamaAPI\\nCreate a new model by parsing and validating input data from keyword arguments.\\nllms.lmformatenforcer_decoder.LMFormatEnforcer\\nLMFormatEnforcer wrapped LLM using HuggingFace Pipeline API.\\nllms.ollama_functions.OllamaFunctions\\nCreate a new model by parsing and validating input data from keyword arguments.\\nllms.rellm_decoder.RELLM\\nRELLM wrapped LLM using HuggingFace Pipeline API.\\nFunctions¶\\nllms.jsonformer_decoder.import_jsonformer()\\nLazily import jsonformer.\\nllms.lmformatenforcer_decoder.import_lmformatenforcer()\\nLazily import lmformatenforcer.\\nllms.rellm_decoder.import_rellm()\\nLazily import rellm.\\nlangchain_experimental.open_clip¶\\nClasses¶\\nopen_clip.open_clip.OpenCLIPEmbeddings\\nCreate a new model by parsing and validating input data from keyword arguments.\\nlangchain_experimental.pal_chain¶\\nImplements Program-Aided Language Models.\\nAs in https://arxiv.org/pdf/2211.10435.pdf.\\nThis is vulnerable to arbitrary code execution:\\nhttps://github.com/langchain-ai/langchain/issues/5872\\nClasses¶\\npal_chain.base.PALChain\\nImplements Program-Aided Language Models (PAL).\\npal_chain.base.PALValidation([...])\\nInitialize a PALValidation instance.\\nlangchain_experimental.plan_and_execute¶\\nClasses¶\\nplan_and_execute.agent_executor.PlanAndExecute\\nPlan and execute a chain of steps.\\nplan_and_execute.executors.base.BaseExecutor\\nBase executor.\\nplan_and_execute.executors.base.ChainExecutor\\nChain executor.\\nplan_and_execute.planners.base.BasePlanner\\nBase planner.\\nplan_and_execute.planners.base.LLMPlanner\\nLLM planner.\\nplan_and_execute.planners.chat_planner.PlanningOutputParser\\nPlanning output parser.\\nplan_and_execute.schema.BaseStepContainer\\nBase step container.\\nplan_and_execute.schema.ListStepContainer\\nList step container.\\nplan_and_execute.schema.Plan\\nPlan.\\nplan_and_execute.schema.PlanOutputParser\\nPlan output parser.\\nplan_and_execute.schema.Step\\nStep.\\nplan_and_execute.schema.StepResponse\\nStep response.\\nFunctions¶\\nplan_and_execute.executors.agent_executor.load_agent_executor(...)\\nLoad an agent executor.\\nplan_and_execute.planners.chat_planner.load_chat_planner(llm)\\nLoad a chat planner.\\nlangchain_experimental.prompt_injection_identifier¶\\nHuggingFace Security toolkit.\\nClasses¶\\nprompt_injection_identifier.hugging_face_identifier.HuggingFaceInjectionIdentifier\\nTool that uses HF model to detect prompt injection attacks.\\nprompt_injection_identifier.hugging_face_identifier.PromptInjectionException([...])\\nFunctions¶\\nlangchain_experimental.prompts¶\\nFunctions¶\\nprompts.load.load_prompt(path)\\nUnified method for loading a prompt from LangChainHub or local fs.\\nlangchain_experimental.retrievers¶\\nClasses¶\\nretrievers.vector_sql_database.VectorSQLDatabaseChainRetriever\\nRetriever that uses SQLDatabase as Retriever\\nlangchain_experimental.rl_chain¶\\nClasses¶\\nrl_chain.base.AutoSelectionScorer\\nCreate a new model by parsing and validating input data from keyword arguments.\\nrl_chain.base.Embedder(*args,\\xa0**kwargs)\\nrl_chain.base.Event(inputs[,\\xa0selected])\\nrl_chain.base.Policy(**kwargs)\\nrl_chain.base.RLChain\\nThe RLChain class leverages the Vowpal Wabbit (VW) model as a learned policy for reinforcement learning.\\nrl_chain.base.Selected()\\nrl_chain.base.SelectionScorer\\nAbstract method to grade the chosen selection or the response of the llm\\nrl_chain.base.VwPolicy(model_repo,\\xa0vw_cmd,\\xa0...)\\nrl_chain.metrics.MetricsTrackerAverage(step)\\nrl_chain.metrics.MetricsTrackerRollingWindow(...)\\nrl_chain.model_repository.ModelRepository(folder)\\nrl_chain.pick_best_chain.PickBest\\nPickBest is a class designed to leverage the Vowpal Wabbit (VW) model for reinforcement learning with a context, with the goal of modifying the prompt before the LLM call.\\nrl_chain.pick_best_chain.PickBestEvent(...)\\nrl_chain.pick_best_chain.PickBestFeatureEmbedder(...)\\nText Embedder class that embeds the BasedOn and ToSelectFrom inputs into a format that can be used by the learning policy\\nrl_chain.pick_best_chain.PickBestRandomPolicy(...)\\nrl_chain.pick_best_chain.PickBestSelected([...])\\nrl_chain.vw_logger.VwLogger(path)\\nFunctions¶\\nrl_chain.base.BasedOn(anything)\\nrl_chain.base.Embed(anything[,\\xa0keep])\\nrl_chain.base.EmbedAndKeep(anything)\\nrl_chain.base.ToSelectFrom(anything)\\nrl_chain.base.embed(to_embed,\\xa0model[,\\xa0namespace])\\nEmbeds the actions or context using the SentenceTransformer model (or a model that has an encode function)\\nrl_chain.base.embed_dict_type(item,\\xa0model)\\nHelper function to embed a dictionary item.\\nrl_chain.base.embed_list_type(item,\\xa0model[,\\xa0...])\\nrl_chain.base.embed_string_type(item,\\xa0model)\\nHelper function to embed a string or an _Embed object.\\nrl_chain.base.get_based_on_and_to_select_from(inputs)\\nrl_chain.base.is_stringtype_instance(item)\\nHelper function to check if an item is a string.\\nrl_chain.base.parse_lines(parser,\\xa0input_str)\\nrl_chain.base.prepare_inputs_for_autoembed(inputs)\\ngo over all the inputs and if something is either wrapped in _ToSelectFrom or _BasedOn, and if their inner values are not already _Embed, then wrap them in EmbedAndKeep while retaining their _ToSelectFrom or _BasedOn status\\nrl_chain.base.stringify_embedding(embedding)\\nlangchain_experimental.smart_llm¶\\nGeneralized implementation of SmartGPT (origin: https://youtu.be/wVzuvf9D9BU)\\nClasses¶\\nsmart_llm.base.SmartLLMChain\\nGeneralized implementation of SmartGPT (origin: https://youtu.be/wVzuvf9D9BU)\\nlangchain_experimental.sql¶\\nChain for interacting with SQL Database.\\nClasses¶\\nsql.base.SQLDatabaseChain\\nChain for interacting with SQL Database.\\nsql.base.SQLDatabaseSequentialChain\\nChain for querying SQL database that is a sequential chain.\\nsql.vector_sql.VectorSQLDatabaseChain\\nChain for interacting with Vector SQL Database.\\nsql.vector_sql.VectorSQLOutputParser\\nOutput Parser for Vector SQL 1.\\nsql.vector_sql.VectorSQLRetrieveAllOutputParser\\nBased on VectorSQLOutputParser It also modify the SQL to get all columns\\nFunctions¶\\nsql.vector_sql.get_result_from_sqldb(db,\\xa0cmd)\\nlangchain_experimental.tabular_synthetic_data¶\\nClasses¶\\ntabular_synthetic_data.base.SyntheticDataGenerator\\nGenerates synthetic data using the given LLM and few-shot template.\\nFunctions¶\\ntabular_synthetic_data.openai.create_openai_data_generator(...)\\nCreate an instance of SyntheticDataGenerator tailored for OpenAI models.\\nlangchain_experimental.tools¶\\nClasses¶\\ntools.python.tool.PythonAstREPLTool\\nA tool for running python code in a REPL.\\ntools.python.tool.PythonInputs\\nCreate a new model by parsing and validating input data from keyword arguments.\\ntools.python.tool.PythonREPLTool\\nA tool for running python code in a REPL.\\nFunctions¶\\ntools.python.tool.sanitize_input(query)\\nSanitize input to the python REPL.\\nlangchain_experimental.tot¶\\nClasses¶\\ntot.base.ToTChain\\nA Chain implementing the Tree of Thought (ToT).\\ntot.checker.ToTChecker\\nTree of Thought (ToT) checker.\\ntot.controller.ToTController([c])\\nTree of Thought (ToT) controller.\\ntot.memory.ToTDFSMemory([stack])\\nMemory for the Tree of Thought (ToT) chain.\\ntot.prompts.CheckerOutputParser\\nFields\\ntot.prompts.JSONListOutputParser\\nClass to parse the output of a PROPOSE_PROMPT response.\\ntot.thought.Thought\\nCreate a new model by parsing and validating input data from keyword arguments.\\ntot.thought.ThoughtValidity(value[,\\xa0names,\\xa0...])\\ntot.thought_generation.BaseThoughtGenerationStrategy\\nBase class for a thought generation strategy.\\ntot.thought_generation.ProposePromptStrategy\\nPropose thoughts sequentially using a \"propose prompt\".\\ntot.thought_generation.SampleCoTStrategy\\nSample thoughts from a Chain-of-Thought (CoT) prompt.\\nFunctions¶\\ntot.prompts.get_cot_prompt()\\ntot.prompts.get_propose_prompt()\\nlangchain_experimental.utilities¶\\nClasses¶\\nutilities.python.PythonREPL\\nSimulates a standalone Python REPL.', metadata={'source': 'docs/api.python.langchain.com/en/stable/experimental_api_reference.html'})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "docs[10]"
      ],
      "id": "vcpuudNRLV7k"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5Q24oWkGM3IP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "865edc52-7a31-4b40-a70d-85e4d6fa1149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "langchain_experimental 0.0.47¶\n",
            "langchain_experimental.agents¶\n",
            "Functions¶\n",
            "agents.agent_toolkits.csv.base.create_csv_agent(...)\n",
            "Create csv agent by loading to a dataframe and using pandas agent.\n",
            "agents.agent_toolkits.pandas.base.create_pandas_dataframe_agent(llm, df)\n",
            "Construct a pandas agent from an LLM and dataframe.\n",
            "agents.agent_toolkits.python.base.create_python_agent(...)\n",
            "Construct a python agent from an LLM and tool.\n",
            "agents.agent_toolkits.spark.base.create_spark_dataframe_agent(llm, df)\n",
            "Construct a Spark agent from an LLM and dataframe.\n",
            "agents.agent_toolkits.xorbits.base.create_xorbits_agent(...)\n",
            "Construct a xorbits agent from an LLM and dataframe.\n",
            "langchain_experimental.autonomous_agents¶\n",
            "Classes¶\n",
            "autonomous_agents.autogpt.agent.AutoGPT(...)\n",
            "Agent class for interacting with Auto-GPT.\n",
            "autonomous_agents.autogpt.memory.AutoGPTMemory\n",
            "Memory for AutoGPT.\n",
            "autonomous_agents.autogpt.output_parser.AutoGPTAction(...)\n",
            "Action returned by AutoGPTOutputParser.\n",
            "autonomous_agents.autogpt.output_parser.AutoGPTOutputParser\n",
            "Output parser for AutoGPT.\n",
            "autonomous_agents.autogpt.output_parser.BaseAutoGPTOutputParser\n",
            "Base Output parser for AutoGPT.\n",
            "autonomous_agents.autogpt.prompt.AutoGPTPrompt\n",
            "Prompt for AutoGPT.\n",
            "autonomous_agents.autogpt.prompt_generator.PromptGenerator()\n",
            "A class for generating custom prompt strings.\n",
            "autonomous_agents.baby_agi.baby_agi.BabyAGI\n",
            "Controller model for the BabyAGI agent.\n",
            "autonomous_agents.baby_agi.task_creation.TaskCreationChain\n",
            "Chain generating tasks.\n",
            "autonomous_agents.baby_agi.task_execution.TaskExecutionChain\n",
            "Chain to execute tasks.\n",
            "autonomous_agents.baby_agi.task_prioritization.TaskPrioritizationChain\n",
            "Chain to prioritize tasks.\n",
            "autonomous_agents.hugginggpt.hugginggpt.HuggingGPT(...)\n",
            "autonomous_agents.hugginggpt.repsonse_generator.ResponseGenerationChain\n",
            "Chain to execute tasks.\n",
            "autonomous_agents.hugginggpt.repsonse_generator.ResponseGenerator(...)\n",
            "autonomous_agents.hugginggpt.task_executor.Task(...)\n",
            "autonomous_agents.hugginggpt.task_executor.TaskExecutor(plan)\n",
            "Load tools to execute tasks.\n",
            "autonomous_agents.hugginggpt.task_planner.BasePlanner\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "autonomous_agents.hugginggpt.task_planner.Plan(steps)\n",
            "autonomous_agents.hugginggpt.task_planner.PlanningOutputParser\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "autonomous_agents.hugginggpt.task_planner.Step(...)\n",
            "autonomous_agents.hugginggpt.task_planner.TaskPlaningChain\n",
            "Chain to execute tasks.\n",
            "autonomous_agents.hugginggpt.task_planner.TaskPlanner\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "Functions¶\n",
            "autonomous_agents.autogpt.output_parser.preprocess_json_input(...)\n",
            "Preprocesses a string to be parsed as json.\n",
            "autonomous_agents.autogpt.prompt_generator.get_prompt(tools)\n",
            "Generates a prompt string.\n",
            "autonomous_agents.hugginggpt.repsonse_generator.load_response_generator(llm)\n",
            "autonomous_agents.hugginggpt.task_planner.load_chat_planner(llm)\n",
            "langchain_experimental.chat_models¶\n",
            "Chat Models are a variation on language models.\n",
            "While Chat Models use language models under the hood, the interface they expose\n",
            "is a bit different. Rather than expose a “text in, text out” API, they expose\n",
            "an interface where “chat messages” are the inputs and outputs.\n",
            "Class hierarchy:\n",
            "BaseLanguageModel --> BaseChatModel --> <name>  # Examples: ChatOpenAI, ChatGooglePalm\n",
            "Main helpers:\n",
            "AIMessage, BaseMessage, HumanMessage\n",
            "Classes¶\n",
            "chat_models.llm_wrapper.ChatWrapper\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "chat_models.llm_wrapper.Llama2Chat\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "chat_models.llm_wrapper.Orca\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "chat_models.llm_wrapper.Vicuna\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "langchain_experimental.comprehend_moderation¶\n",
            "Classes¶\n",
            "comprehend_moderation.amazon_comprehend_moderation.AmazonComprehendModerationChain\n",
            "A subclass of Chain, designed to apply moderation to LLMs.\n",
            "comprehend_moderation.base_moderation.BaseModeration(client)\n",
            "comprehend_moderation.base_moderation_callbacks.BaseModerationCallbackHandler()\n",
            "comprehend_moderation.base_moderation_config.BaseModerationConfig\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "comprehend_moderation.base_moderation_config.ModerationPiiConfig\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "comprehend_moderation.base_moderation_config.ModerationPromptSafetyConfig\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "comprehend_moderation.base_moderation_config.ModerationToxicityConfig\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "comprehend_moderation.base_moderation_exceptions.ModerationPiiError([...])\n",
            "Exception raised if PII entities are detected.\n",
            "comprehend_moderation.base_moderation_exceptions.ModerationPromptSafetyError([...])\n",
            "Exception raised if Intention entities are detected.\n",
            "comprehend_moderation.base_moderation_exceptions.ModerationToxicityError([...])\n",
            "Exception raised if Toxic entities are detected.\n",
            "comprehend_moderation.pii.ComprehendPII(client)\n",
            "comprehend_moderation.prompt_safety.ComprehendPromptSafety(client)\n",
            "comprehend_moderation.toxicity.ComprehendToxicity(client)\n",
            "langchain_experimental.cpal¶\n",
            "Classes¶\n",
            "cpal.base.CPALChain\n",
            "Causal program-aided language (CPAL) chain implementation.\n",
            "cpal.base.CausalChain\n",
            "Translate the causal narrative into a stack of operations.\n",
            "cpal.base.InterventionChain\n",
            "Set the hypothetical conditions for the causal model.\n",
            "cpal.base.NarrativeChain\n",
            "Decompose the narrative into its story elements\n",
            "cpal.base.QueryChain\n",
            "Query the outcome table using SQL.\n",
            "cpal.constants.Constant(value[, names, ...])\n",
            "Enum for constants used in the CPAL.\n",
            "cpal.models.CausalModel\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "cpal.models.EntityModel\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "cpal.models.EntitySettingModel\n",
            "Initial conditions for an entity\n",
            "cpal.models.InterventionModel\n",
            "aka initial conditions\n",
            "cpal.models.NarrativeModel\n",
            "Represent the narrative input as three story elements.\n",
            "cpal.models.QueryModel\n",
            "translate a question about the story outcome into a programmatic expression\n",
            "cpal.models.ResultModel\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "cpal.models.StoryModel\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "cpal.models.SystemSettingModel\n",
            "Initial global conditions for the system.\n",
            "langchain_experimental.data_anonymizer¶\n",
            "Data anonymizer package\n",
            "Classes¶\n",
            "data_anonymizer.base.AnonymizerBase()\n",
            "Base abstract class for anonymizers. It is public and non-virtual because it allows     wrapping the behavior for all methods in a base class.\n",
            "data_anonymizer.base.ReversibleAnonymizerBase()\n",
            "Base abstract class for reversible anonymizers.\n",
            "data_anonymizer.deanonymizer_mapping.DeanonymizerMapping(...)\n",
            "data_anonymizer.presidio.PresidioAnonymizer([...])\n",
            "param analyzed_fields\n",
            "List of fields to detect and then anonymize.\n",
            "data_anonymizer.presidio.PresidioAnonymizerBase([...])\n",
            "param analyzed_fields\n",
            "List of fields to detect and then anonymize.\n",
            "data_anonymizer.presidio.PresidioReversibleAnonymizer([...])\n",
            "param analyzed_fields\n",
            "List of fields to detect and then anonymize.\n",
            "Functions¶\n",
            "data_anonymizer.deanonymizer_mapping.create_anonymizer_mapping(...)\n",
            "Creates or updates the mapping used to anonymize and/or deanonymize text.\n",
            "data_anonymizer.deanonymizer_mapping.format_duplicated_operator(...)\n",
            "Format the operator name with the count\n",
            "data_anonymizer.deanonymizer_matching_strategies.case_insensitive_matching_strategy(...)\n",
            "Case insensitive matching strategy for deanonymization. It replaces all the anonymized entities with the original ones     irrespective of their letter case.\n",
            "data_anonymizer.deanonymizer_matching_strategies.combined_exact_fuzzy_matching_strategy(...)\n",
            "RECOMMENDED STRATEGY.\n",
            "data_anonymizer.deanonymizer_matching_strategies.exact_matching_strategy(...)\n",
            "Exact matching strategy for deanonymization.\n",
            "data_anonymizer.deanonymizer_matching_strategies.fuzzy_matching_strategy(...)\n",
            "Fuzzy matching strategy for deanonymization.\n",
            "data_anonymizer.deanonymizer_matching_strategies.ngram_fuzzy_matching_strategy(...)\n",
            "N-gram fuzzy matching strategy for deanonymization.\n",
            "data_anonymizer.faker_presidio_mapping.get_pseudoanonymizer_mapping([seed])\n",
            "langchain_experimental.fallacy_removal¶\n",
            "The Chain runs a self-review of logical fallacies as determined by this paper  categorizing and defining logical fallacies https://arxiv.org/pdf/2212.07425.pdf. Modeled after Constitutional AI and in same format, but applying logical fallacies as generalized rules to remove in output\n",
            "Classes¶\n",
            "fallacy_removal.base.FallacyChain\n",
            "Chain for applying logical fallacy evaluations, modeled after Constitutional AI     and in same format, but applying logical fallacies as generalized rules to remove     in output\n",
            "fallacy_removal.models.LogicalFallacy\n",
            "Class for a logical fallacy.\n",
            "langchain_experimental.generative_agents¶\n",
            "Generative Agents primitives.\n",
            "Classes¶\n",
            "generative_agents.generative_agent.GenerativeAgent\n",
            "An Agent as a character with memory and innate characteristics.\n",
            "generative_agents.memory.GenerativeAgentMemory\n",
            "Memory for the generative agent.\n",
            "langchain_experimental.graph_transformers¶\n",
            "Classes¶\n",
            "graph_transformers.diffbot.DiffbotGraphTransformer([...])\n",
            "Transforms documents into graph documents using Diffbot's NLP API.\n",
            "graph_transformers.diffbot.NodesList()\n",
            "Manages a list of nodes with associated properties.\n",
            "graph_transformers.diffbot.SimplifiedSchema()\n",
            "Provides functionality for working with a simplified schema mapping.\n",
            "Functions¶\n",
            "graph_transformers.diffbot.format_property_key(s)\n",
            "langchain_experimental.llm_bash¶\n",
            "Chain that interprets a prompt and executes bash code to perform bash operations.\n",
            "Classes¶\n",
            "llm_bash.base.LLMBashChain\n",
            "Chain that interprets a prompt and executes bash operations.\n",
            "llm_bash.bash.BashProcess([strip_newlines, ...])\n",
            "Wrapper class for starting subprocesses.\n",
            "llm_bash.prompt.BashOutputParser\n",
            "Parser for bash output.\n",
            "langchain_experimental.llm_symbolic_math¶\n",
            "Chain that interprets a prompt and executes python code to do math.\n",
            "Heavily borrowed from llm_math, wrapper for SymPy\n",
            "Classes¶\n",
            "llm_symbolic_math.base.LLMSymbolicMathChain\n",
            "Chain that interprets a prompt and executes python code to do symbolic math.\n",
            "langchain_experimental.llms¶\n",
            "Experimental LLM wrappers.\n",
            "Classes¶\n",
            "llms.anthropic_functions.AnthropicFunctions\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "llms.anthropic_functions.TagParser()\n",
            "A heavy-handed solution, but it's fast for prototyping.\n",
            "llms.jsonformer_decoder.JsonFormer\n",
            "Jsonformer wrapped LLM using HuggingFace Pipeline API.\n",
            "llms.llamaapi.ChatLlamaAPI\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "llms.lmformatenforcer_decoder.LMFormatEnforcer\n",
            "LMFormatEnforcer wrapped LLM using HuggingFace Pipeline API.\n",
            "llms.ollama_functions.OllamaFunctions\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "llms.rellm_decoder.RELLM\n",
            "RELLM wrapped LLM using HuggingFace Pipeline API.\n",
            "Functions¶\n",
            "llms.jsonformer_decoder.import_jsonformer()\n",
            "Lazily import jsonformer.\n",
            "llms.lmformatenforcer_decoder.import_lmformatenforcer()\n",
            "Lazily import lmformatenforcer.\n",
            "llms.rellm_decoder.import_rellm()\n",
            "Lazily import rellm.\n",
            "langchain_experimental.open_clip¶\n",
            "Classes¶\n",
            "open_clip.open_clip.OpenCLIPEmbeddings\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "langchain_experimental.pal_chain¶\n",
            "Implements Program-Aided Language Models.\n",
            "As in https://arxiv.org/pdf/2211.10435.pdf.\n",
            "This is vulnerable to arbitrary code execution:\n",
            "https://github.com/langchain-ai/langchain/issues/5872\n",
            "Classes¶\n",
            "pal_chain.base.PALChain\n",
            "Implements Program-Aided Language Models (PAL).\n",
            "pal_chain.base.PALValidation([...])\n",
            "Initialize a PALValidation instance.\n",
            "langchain_experimental.plan_and_execute¶\n",
            "Classes¶\n",
            "plan_and_execute.agent_executor.PlanAndExecute\n",
            "Plan and execute a chain of steps.\n",
            "plan_and_execute.executors.base.BaseExecutor\n",
            "Base executor.\n",
            "plan_and_execute.executors.base.ChainExecutor\n",
            "Chain executor.\n",
            "plan_and_execute.planners.base.BasePlanner\n",
            "Base planner.\n",
            "plan_and_execute.planners.base.LLMPlanner\n",
            "LLM planner.\n",
            "plan_and_execute.planners.chat_planner.PlanningOutputParser\n",
            "Planning output parser.\n",
            "plan_and_execute.schema.BaseStepContainer\n",
            "Base step container.\n",
            "plan_and_execute.schema.ListStepContainer\n",
            "List step container.\n",
            "plan_and_execute.schema.Plan\n",
            "Plan.\n",
            "plan_and_execute.schema.PlanOutputParser\n",
            "Plan output parser.\n",
            "plan_and_execute.schema.Step\n",
            "Step.\n",
            "plan_and_execute.schema.StepResponse\n",
            "Step response.\n",
            "Functions¶\n",
            "plan_and_execute.executors.agent_executor.load_agent_executor(...)\n",
            "Load an agent executor.\n",
            "plan_and_execute.planners.chat_planner.load_chat_planner(llm)\n",
            "Load a chat planner.\n",
            "langchain_experimental.prompt_injection_identifier¶\n",
            "HuggingFace Security toolkit.\n",
            "Classes¶\n",
            "prompt_injection_identifier.hugging_face_identifier.HuggingFaceInjectionIdentifier\n",
            "Tool that uses HF model to detect prompt injection attacks.\n",
            "prompt_injection_identifier.hugging_face_identifier.PromptInjectionException([...])\n",
            "Functions¶\n",
            "langchain_experimental.prompts¶\n",
            "Functions¶\n",
            "prompts.load.load_prompt(path)\n",
            "Unified method for loading a prompt from LangChainHub or local fs.\n",
            "langchain_experimental.retrievers¶\n",
            "Classes¶\n",
            "retrievers.vector_sql_database.VectorSQLDatabaseChainRetriever\n",
            "Retriever that uses SQLDatabase as Retriever\n",
            "langchain_experimental.rl_chain¶\n",
            "Classes¶\n",
            "rl_chain.base.AutoSelectionScorer\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "rl_chain.base.Embedder(*args, **kwargs)\n",
            "rl_chain.base.Event(inputs[, selected])\n",
            "rl_chain.base.Policy(**kwargs)\n",
            "rl_chain.base.RLChain\n",
            "The RLChain class leverages the Vowpal Wabbit (VW) model as a learned policy for reinforcement learning.\n",
            "rl_chain.base.Selected()\n",
            "rl_chain.base.SelectionScorer\n",
            "Abstract method to grade the chosen selection or the response of the llm\n",
            "rl_chain.base.VwPolicy(model_repo, vw_cmd, ...)\n",
            "rl_chain.metrics.MetricsTrackerAverage(step)\n",
            "rl_chain.metrics.MetricsTrackerRollingWindow(...)\n",
            "rl_chain.model_repository.ModelRepository(folder)\n",
            "rl_chain.pick_best_chain.PickBest\n",
            "PickBest is a class designed to leverage the Vowpal Wabbit (VW) model for reinforcement learning with a context, with the goal of modifying the prompt before the LLM call.\n",
            "rl_chain.pick_best_chain.PickBestEvent(...)\n",
            "rl_chain.pick_best_chain.PickBestFeatureEmbedder(...)\n",
            "Text Embedder class that embeds the BasedOn and ToSelectFrom inputs into a format that can be used by the learning policy\n",
            "rl_chain.pick_best_chain.PickBestRandomPolicy(...)\n",
            "rl_chain.pick_best_chain.PickBestSelected([...])\n",
            "rl_chain.vw_logger.VwLogger(path)\n",
            "Functions¶\n",
            "rl_chain.base.BasedOn(anything)\n",
            "rl_chain.base.Embed(anything[, keep])\n",
            "rl_chain.base.EmbedAndKeep(anything)\n",
            "rl_chain.base.ToSelectFrom(anything)\n",
            "rl_chain.base.embed(to_embed, model[, namespace])\n",
            "Embeds the actions or context using the SentenceTransformer model (or a model that has an encode function)\n",
            "rl_chain.base.embed_dict_type(item, model)\n",
            "Helper function to embed a dictionary item.\n",
            "rl_chain.base.embed_list_type(item, model[, ...])\n",
            "rl_chain.base.embed_string_type(item, model)\n",
            "Helper function to embed a string or an _Embed object.\n",
            "rl_chain.base.get_based_on_and_to_select_from(inputs)\n",
            "rl_chain.base.is_stringtype_instance(item)\n",
            "Helper function to check if an item is a string.\n",
            "rl_chain.base.parse_lines(parser, input_str)\n",
            "rl_chain.base.prepare_inputs_for_autoembed(inputs)\n",
            "go over all the inputs and if something is either wrapped in _ToSelectFrom or _BasedOn, and if their inner values are not already _Embed, then wrap them in EmbedAndKeep while retaining their _ToSelectFrom or _BasedOn status\n",
            "rl_chain.base.stringify_embedding(embedding)\n",
            "langchain_experimental.smart_llm¶\n",
            "Generalized implementation of SmartGPT (origin: https://youtu.be/wVzuvf9D9BU)\n",
            "Classes¶\n",
            "smart_llm.base.SmartLLMChain\n",
            "Generalized implementation of SmartGPT (origin: https://youtu.be/wVzuvf9D9BU)\n",
            "langchain_experimental.sql¶\n",
            "Chain for interacting with SQL Database.\n",
            "Classes¶\n",
            "sql.base.SQLDatabaseChain\n",
            "Chain for interacting with SQL Database.\n",
            "sql.base.SQLDatabaseSequentialChain\n",
            "Chain for querying SQL database that is a sequential chain.\n",
            "sql.vector_sql.VectorSQLDatabaseChain\n",
            "Chain for interacting with Vector SQL Database.\n",
            "sql.vector_sql.VectorSQLOutputParser\n",
            "Output Parser for Vector SQL 1.\n",
            "sql.vector_sql.VectorSQLRetrieveAllOutputParser\n",
            "Based on VectorSQLOutputParser It also modify the SQL to get all columns\n",
            "Functions¶\n",
            "sql.vector_sql.get_result_from_sqldb(db, cmd)\n",
            "langchain_experimental.tabular_synthetic_data¶\n",
            "Classes¶\n",
            "tabular_synthetic_data.base.SyntheticDataGenerator\n",
            "Generates synthetic data using the given LLM and few-shot template.\n",
            "Functions¶\n",
            "tabular_synthetic_data.openai.create_openai_data_generator(...)\n",
            "Create an instance of SyntheticDataGenerator tailored for OpenAI models.\n",
            "langchain_experimental.tools¶\n",
            "Classes¶\n",
            "tools.python.tool.PythonAstREPLTool\n",
            "A tool for running python code in a REPL.\n",
            "tools.python.tool.PythonInputs\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "tools.python.tool.PythonREPLTool\n",
            "A tool for running python code in a REPL.\n",
            "Functions¶\n",
            "tools.python.tool.sanitize_input(query)\n",
            "Sanitize input to the python REPL.\n",
            "langchain_experimental.tot¶\n",
            "Classes¶\n",
            "tot.base.ToTChain\n",
            "A Chain implementing the Tree of Thought (ToT).\n",
            "tot.checker.ToTChecker\n",
            "Tree of Thought (ToT) checker.\n",
            "tot.controller.ToTController([c])\n",
            "Tree of Thought (ToT) controller.\n",
            "tot.memory.ToTDFSMemory([stack])\n",
            "Memory for the Tree of Thought (ToT) chain.\n",
            "tot.prompts.CheckerOutputParser\n",
            "Fields\n",
            "tot.prompts.JSONListOutputParser\n",
            "Class to parse the output of a PROPOSE_PROMPT response.\n",
            "tot.thought.Thought\n",
            "Create a new model by parsing and validating input data from keyword arguments.\n",
            "tot.thought.ThoughtValidity(value[, names, ...])\n",
            "tot.thought_generation.BaseThoughtGenerationStrategy\n",
            "Base class for a thought generation strategy.\n",
            "tot.thought_generation.ProposePromptStrategy\n",
            "Propose thoughts sequentially using a \"propose prompt\".\n",
            "tot.thought_generation.SampleCoTStrategy\n",
            "Sample thoughts from a Chain-of-Thought (CoT) prompt.\n",
            "Functions¶\n",
            "tot.prompts.get_cot_prompt()\n",
            "tot.prompts.get_propose_prompt()\n",
            "langchain_experimental.utilities¶\n",
            "Classes¶\n",
            "utilities.python.PythonREPL\n",
            "Simulates a standalone Python REPL.\n",
            "https://api.python.langchain.com/en/latest/experimental_api_reference.html\n"
          ]
        }
      ],
      "source": [
        "#### your code ####\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def retrieve_url(doc):\n",
        "  with open(doc.dict()['metadata']['source']) as original_file:\n",
        "    soup = BeautifulSoup(original_file, 'html.parser')\n",
        "    # Find the canonical link tag\n",
        "    canonical_tag = soup.find('link', {'rel': 'canonical'})\n",
        "\n",
        "    # Extract the URL from the href attribute\n",
        "    if canonical_tag:\n",
        "      url = canonical_tag.get('href')\n",
        "    else:\n",
        "      print(\"No canonical link found.\")\n",
        "  return url\n",
        "\n",
        "page_content = docs[10].page_content\n",
        "page_url = retrieve_url(docs[10])\n",
        "#### your code ####\n",
        "print(page_content)\n",
        "print(page_url)"
      ],
      "id": "5Q24oWkGM3IP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfZKdZJsMeyj"
      },
      "source": [
        "As you can imagine the documents can be long and if multiple of them are required as context to answer questions, we need to take the document lengths into account.\n",
        "This is due to the fact that language models do not have unlimited context span. In our case, we plan to use Llama2 for this project, where the maximum token limit is 4096. This limit is not only the input but also takes the generated output into account, moreover, you need to leave room for the query and instructions as well. Therefore, it is important to chunk the longer documents into smaller-sized fragments.\n",
        "\n",
        "Based on your use case and how many contexts you plan to feed into the model the length of these fragments will differ.\n",
        "In this case, we choose to assign 2000 tokens to context and choose to generate the answer from 5 context fragments, which leaves us with 400 tokens per context fragment as the maximum chunk size.\n",
        "\n",
        "To count the number of tokens in a chunk, we need to load the correct tokenizer for Llama2. Fill the code cell below to load the correct tokenizer and use it to complete the function that counts the number of tokens per given chunk.\n",
        "\n",
        "**Hint:** you need to use your Hugging Face authentication token to load the tokenizer."
      ],
      "id": "OfZKdZJsMeyj"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WjOHBqXLLWDA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "1ccb07329fe64c45979e5a84d73c6987",
            "902e31fa2ac04e14bcd906eac38feb03",
            "c434eec5437a402a8bc75aed5b78c454",
            "b053dab14e62487ab713aa2ebe733c3a",
            "e10b4c9e8b51455f838adcf9032af9a3",
            "4b2e150968614da69d482077062db2b1",
            "a2d3bd4877484f788680678a4dfc82c0",
            "abba85011f9d4ddcba6b7de3a02256e1",
            "02578c8fb5d640ce84ff277dfe8e9c7d",
            "49a0b62ce38b4068b094ae0fea8e0b21",
            "1b2f2c7cfb734519ad0a53bf7181b0fe",
            "de16bce20d254634b7e47fb27e133147",
            "d5628a3e00c6444f9a94df4f285b6515",
            "43d7e97dee4c410abebf621ae7150288",
            "2197725de0b244169ccf5b354d581a33",
            "37f9621a15374f9e9c2855541d4a11e6",
            "0618f8bf5a804cf78ceaeab7323714c8",
            "a172683c123b413eb77ac6eea8862bd7",
            "d3a30225b89d4126b9471646a7154d21",
            "01e140e01c0a47158f8ff2b2ec91be1c",
            "ae79ce60dd0b4b49a2d66db0ad1271da",
            "0a5565ae2dbf4e94a35c022579aaa4ac",
            "56e7ef1f600f47f78d47ebe7ef410250",
            "1aa02ede152b4ba8b5d08195a67283d7",
            "e382feb2e4f149aca553d5398b39decb",
            "07af4cd164ec416f80eeb710bea8ea73",
            "940047c7b9834c0096028cdaabb105a4",
            "07ed592ed6a04586a070ba954add993c",
            "1882d960e85e4572989566e4fbf8bbd0",
            "ed829a223e7b47839c5e81e743267e4c",
            "552b05234611493da3ec3b9e07ee1fc6",
            "824454dd0ecd4187ac267adc6971ad90",
            "ea40370675804b10b070330084c790f1",
            "989f3aed257e4428a6fbe020a272d773",
            "d1441a98a67a49a893fddffa652f0076",
            "0200909aecd74596b4ed3e240f16a1f9",
            "161f3006519e4142b214cffd6d6b0ada",
            "b28b7c20812b4a609b7a7da39d6ace47",
            "082bcffbf6f344ce926fb1bfee46023e",
            "fa781d501bef462aacabc47c556ea231",
            "b0460e4e964d445192e8b67892afd1fa",
            "3c25b8574beb4b1e9886bf160668b524",
            "5aec05a290934d9d90166eb5e023e273",
            "7879b1b798ab401c8517b259a1b50f2d"
          ]
        },
        "outputId": "b4c80707-50a4-458e-fa8b-277f2df4145b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ccb07329fe64c45979e5a84d73c6987"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de16bce20d254634b7e47fb27e133147"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56e7ef1f600f47f78d47ebe7ef410250"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "989f3aed257e4428a6fbe020a272d773"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#If you get an error here during the first import from the `transformers` package, restart the kernel and try again.\n",
        "#### your code ####\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id = 'meta-llama/Llama-2-13b-chat-hf'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, token=os.environ.get('HF_AUTH'))\n",
        "\n",
        "#### your code ####"
      ],
      "id": "WjOHBqXLLWDA"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "G5GutpFdLWFu"
      },
      "outputs": [],
      "source": [
        "def token_len(text):\n",
        "  #### your code ####\n",
        "  # Tokenize the input text\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "\n",
        "  # Calculate the length of the tokenized sequence\n",
        "  tokens_length = len(tokens)\n",
        "\n",
        "  return tokens_length\n",
        "\n",
        "  #### your code ####"
      ],
      "id": "G5GutpFdLWFu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pdG2JeGPfcS"
      },
      "source": [
        "Count the number of tokens for all documents and use it to compute minimum, maximum, and average token count statistics across all documents. Depending on how the documentation is updated by the time you run the cell below the numbers might slightly differ."
      ],
      "id": "2pdG2JeGPfcS"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HdAdFPYyLWIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4dc786-87ca-492b-f12c-10ab754b4e32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min: 47\n",
            "Avg: 2662.751773049645\n",
            "Max: 36799\n"
          ]
        }
      ],
      "source": [
        "#### your code ####\n",
        "import numpy as np\n",
        "\n",
        "token_counts = [token_len(doc.page_content) for doc in docs]\n",
        "min_tokens= np.min(token_counts)\n",
        "avg_tokens= np.average(token_counts)\n",
        "max_tokens= np.max(token_counts)\n",
        "#### your code ####\n",
        "\n",
        "print(f\"\"\"Min: {min_tokens}\n",
        "Avg: {avg_tokens}\n",
        "Max: {max_tokens}\"\"\")"
      ],
      "id": "HdAdFPYyLWIM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz9rYYRtMo2N"
      },
      "source": [
        "Now we will use LangChain's built-in chunking functionality to split the text into smaller chunks. LangChain offers a variety of text splitters that you can check out [here](https://api.python.langchain.com/en/latest/langchain_api_reference.html#module-langchain.text_splitter).\n",
        "Use the general-purpose splitter that splits text by recursively looking at characters. Use this class to split the text into 400 token-sized chunks, where the length of each chunk is computed based on the `token_len` function. The length is not the only criterion for splitting, if any of these separators `'\\n\\n', '\\n', ' ', ''` is encountered, we will have a new chunk.\n",
        "Since splitting only based on maximum length might result in incoherent chunks for every consecutive chunk, let the chunk overlap by 50 tokens. This way,  we preserve some of the previous context while chunking."
      ],
      "id": "iz9rYYRtMo2N"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0_RaaGMPPUd9"
      },
      "outputs": [],
      "source": [
        "#### your code ####\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 400,\n",
        "    chunk_overlap  = 50,\n",
        "    length_function = token_len,\n",
        ")\n",
        "#### your code ####"
      ],
      "id": "0_RaaGMPPUd9"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kS6uNIzpOD-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f0f5d3-a7d9-4f40-cc70-9469f57968b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "chunks = text_splitter.split_text(docs[100].page_content)\n",
        "len(chunks)"
      ],
      "id": "kS6uNIzpOD-I"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-r29RUJ7PUg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c929c459-af9c-42cb-b978-817cc61636cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "372"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "token_len(chunks[0])"
      ],
      "id": "-r29RUJ7PUg6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGaeBXo8ONLj"
      },
      "source": [
        "The next step is to apply the splitting function to all the documents in our corpus and to save our chunks in a logical way. We also want to assign a unique ID to each chunk so we know which part of the documentation they come from. In the end, the corpus should be transformed into a list of dictionaries of the following format:\n",
        "\n",
        "\n",
        "```\n",
        "[\n",
        "    {\n",
        "        \"id\": \"glossary-0\",\n",
        "        \"text\": \"first chunk of the document glossary\",\n",
        "        \"source\": \"https://langchain.readthedocs.io/en/latest/glossary.html\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"glossary-1\",\n",
        "        \"text\": \"second chunk of glossary\",\n",
        "        \"source\": \"https://langchain.readthedocs.io/en/latest/glossary.html\"\n",
        "    }\n",
        "    ...\n",
        "]\n",
        "```\n",
        "\n",
        "Construct the IDs by taking the name of the page before the suffix `.html` and appending a chronological number indicating which chunk it is.\n"
      ],
      "id": "SGaeBXo8ONLj"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pBsNJBUNPUjC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e7e8d27d92b84e0eac98f19f0410e5bd",
            "209596331cd5493eb03d3714bc0e9e9c",
            "29b47c4a62f3446b80687eff7fe365ca",
            "46462e4a232a4b6c83899929bfa90807",
            "18b3f5ef35b3400cace877a614edc245",
            "2cd95aa778b040bbbb2f8c078ce52864",
            "961cc787f8d34566bcccd2bb7315d22e",
            "45d84b0b23464e3082a7b0427e5c5b2e",
            "33ff5fbaf7004618a800ec549f5a8b11",
            "9d6f40f56ea849409f290557741ddd10",
            "f375edc9e30b4ccbaa3e3c666441382d"
          ]
        },
        "outputId": "cc7f1022-cd50-4619-bac1-597913d704a9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/423 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7e8d27d92b84e0eac98f19f0410e5bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3638"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "documents = []\n",
        "\n",
        "id=0\n",
        "for doc in tqdm(docs):\n",
        "  #### your code ####\n",
        "    url = retrieve_url(doc) # Defined before\n",
        "    uid_basename = os.path.splitext(os.path.basename(urlparse(url).path))[0]\n",
        "    chunks = text_splitter.split_text(doc.page_content)\n",
        "    id=0\n",
        "\n",
        "    for chunk in chunks:\n",
        "      uid = uid_basename+\"-\"+str(id)\n",
        "      documents.append({\"id\":uid,\"text\":chunk,\"source\":url})\n",
        "      id+=1\n",
        "\n",
        "  #### your code ####\n",
        "len(documents) # once again this value might differ based on how the LangChain documentation is updated"
      ],
      "id": "pBsNJBUNPUjC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnx_s1bBQFQM"
      },
      "source": [
        "For the next steps, we require a `DataFrame`."
      ],
      "id": "Hnx_s1bBQFQM"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "V64EmH9bLWNO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "df131ea8-e5b4-4686-eab0-c205921d3811"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          id  \\\n",
              "0  langchain_api_reference-0   \n",
              "1  langchain_api_reference-1   \n",
              "2  langchain_api_reference-2   \n",
              "3  langchain_api_reference-3   \n",
              "4  langchain_api_reference-4   \n",
              "\n",
              "                                                text  \\\n",
              "0  langchain 0.1.2¶\\nlangchain.agents¶\\nAgent is ...   \n",
              "1  agents.agent.MultiActionAgentOutputParser\\nBas...   \n",
              "2  agents.conversational.output_parser.ConvoOutpu...   \n",
              "3  Run an OpenAI Assistant.\\nagents.openai_functi...   \n",
              "4  agents.output_parsers.self_ask.SelfAskOutputPa...   \n",
              "\n",
              "                                              source  \n",
              "0  https://api.python.langchain.com/en/latest/lan...  \n",
              "1  https://api.python.langchain.com/en/latest/lan...  \n",
              "2  https://api.python.langchain.com/en/latest/lan...  \n",
              "3  https://api.python.langchain.com/en/latest/lan...  \n",
              "4  https://api.python.langchain.com/en/latest/lan...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4763967e-f5a4-4785-9b99-9f53f9604382\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>langchain_api_reference-0</td>\n",
              "      <td>langchain 0.1.2¶\\nlangchain.agents¶\\nAgent is ...</td>\n",
              "      <td>https://api.python.langchain.com/en/latest/lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>langchain_api_reference-1</td>\n",
              "      <td>agents.agent.MultiActionAgentOutputParser\\nBas...</td>\n",
              "      <td>https://api.python.langchain.com/en/latest/lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>langchain_api_reference-2</td>\n",
              "      <td>agents.conversational.output_parser.ConvoOutpu...</td>\n",
              "      <td>https://api.python.langchain.com/en/latest/lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>langchain_api_reference-3</td>\n",
              "      <td>Run an OpenAI Assistant.\\nagents.openai_functi...</td>\n",
              "      <td>https://api.python.langchain.com/en/latest/lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>langchain_api_reference-4</td>\n",
              "      <td>agents.output_parsers.self_ask.SelfAskOutputPa...</td>\n",
              "      <td>https://api.python.langchain.com/en/latest/lan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4763967e-f5a4-4785-9b99-9f53f9604382')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4763967e-f5a4-4785-9b99-9f53f9604382 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4763967e-f5a4-4785-9b99-9f53f9604382');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5f7580c8-afe5-4b2d-84e4-c5d2d058e1f1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f7580c8-afe5-4b2d-84e4-c5d2d058e1f1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5f7580c8-afe5-4b2d-84e4-c5d2d058e1f1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = pd.DataFrame(documents)\n",
        "data.head()"
      ],
      "id": "V64EmH9bLWNO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGbju_bkOQoL"
      },
      "source": [
        "#### ${\\color{red}{Comments\\ 1.1}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "cross-feedback comment section\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ],
      "id": "CGbju_bkOQoL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTrg2hMrO0vF"
      },
      "source": [
        "## Subtask 1.2: Document Embedding Pipeline\n"
      ],
      "id": "VTrg2hMrO0vF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_DSEsWIT9eI"
      },
      "source": [
        "In this task, we initialize the embedding pipeline to transform the chunks into vector embeddings using Hugging Face and LangChain. These embeddings are used for similarity search between the query and the chunks to retrieve the most relevant chunks.\n",
        "  We will use the `sentence-transformers/all-MiniLM-L6-v2` model for embedding, which is a rather small model that you can easily run on Colab. Initialize the model using `HuggingFaceEmbeddings` to use Hugging Face via Langchain. The encoding batch size should be 32, and make sure that the model is placed on the correct device, otherwise, this can take a long time."
      ],
      "id": "q_DSEsWIT9eI"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DYpEw-IKUTqK"
      },
      "outputs": [],
      "source": [
        "from torch import cuda\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "import os\n",
        "import pinecone\n",
        "from tqdm import tqdm"
      ],
      "id": "DYpEw-IKUTqK"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HI3CJ5bbUTsT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587,
          "referenced_widgets": [
            "9d3f496804e545139c2ba7d2cdc8d4f1",
            "a2adae775f6b4e6392a9b0f073aba0d8",
            "68e776360d8c4e6889f623834cd8479e",
            "c5cded1de1b44b6fb5a4ac4f6aa1c26e",
            "944554d50b474122b8dfc0685b27bd73",
            "b6a8a852549e4844863d7aa9d2d7caa6",
            "7e1d28d429694ace9240ef41914b810a",
            "e6002460355748c8a9507a95ca4d7b1c",
            "d8132fd54182456095d4e4d252470418",
            "3ed5b5a62cf047209863cc4dd2058263",
            "ae7d8269695b40c1a46b2f5ae8262336",
            "35025a25703b477c87319678313f4db1",
            "d954b5a549504b3389bf4260540afb74",
            "3e47a4a98a044454bd17e8226b30d433",
            "41725f4f170b44d58be81fc81605375b",
            "f3c9082254044123b7445b0918e8db19",
            "a441ff25338a443d960f37e0cc31b6ff",
            "4675c69bb48041bebddc21e22c556097",
            "b53d6f4c147742af9b72819e1090c8be",
            "c3c0f49ffa7343ad947e55a6ec23ec45",
            "8f92f2a7f5df4feb9032c1a6ced5fdf4",
            "33707e8a9ab8450dba5ede0803977a22",
            "991d36d1feaf4a72b9b9cee579c6ba02",
            "dd4995ceee0c423ba48e7b035901721f",
            "49a69b68d15e4336a4dcf0114771d47f",
            "f0558ccee59e48e2ac7d90ec382a854d",
            "64d4cb392e8e4c8e98056bc8f1d70acd",
            "fcc2b3f4072d4a1aba8f6c50f9c84ccc",
            "dc2566e2d8f344c7ac6e73fc98b3173d",
            "7a4cf49e08924669a569380d9c78b20c",
            "685910c9fb6544f5aa695bd06295547b",
            "7c833ee30a494ed9b63fec3fe9a28aae",
            "ad15920b4bbe4f658319ac8bc44b2ac2",
            "88b401a83f4846b08830dd094ead7797",
            "a9177e8c21f54adb94426ea0f8f0eef3",
            "39b7bb2a748448189de3856a8cf4ab17",
            "56c1c684807e4cbaaa0fa8f6cb120d90",
            "e768fc69473049f8b915b9b4366461dd",
            "d2be14bc8ce649e0abdab4538a8a44df",
            "76830310483f42f4ae97eb20bb3c5f86",
            "bba0780bf8b849fa9673204773006d05",
            "b79db89091ed405892c371e57385fe40",
            "f78c369e4148465998652ede4b42654c",
            "1e0e82b87e7c40c197866f57f6f6c85a",
            "74836699da4d43d9840af9509b7a87ec",
            "21ee6d74a4bc4299a6dff98308ae6d6b",
            "b2518b16df05478694e1a17671baf1b5",
            "d9c4eb2ba2eb46c4a72b83d927de3eac",
            "10eacfc52a004e12ab9699e31d2e05b9",
            "c82399a0b24f48adbd3f4e0f569e9d0e",
            "5629e6400af846c7a0fb8e9eb56e42fa",
            "677def5b965b4986b2316da7f2c94b42",
            "7a9d3168de164f0796ce3c29693b30d8",
            "541296c2bd514bb594a1efbd69b2d0d6",
            "a501eb02940d4efebea94dd3f26834a2",
            "13b1b7814f7440fcb5f2e37cca347ac5",
            "a1f9817758964541af0326cf9a8b2dc4",
            "9cf73c44f09240f38f4c2a55499378aa",
            "29e029eaf997407590aa0b779d8c1251",
            "9bcde184be944ccbbd375bd1dfbced97",
            "4b83e0da4d60428fa5183b622f02bc6f",
            "829112c3fc8344aeb6b74f9c7e003c69",
            "2984176e76c7436a880298676eab641e",
            "122b08f41f2148ed98be1acb497b38db",
            "4cee1b1435704c85893cf0fdde22f06c",
            "ee46d4c8b5874f068f5db13ca3068d43",
            "0b8b2dc3522b4a6daaa9c8f9242515e4",
            "301f9364b4374492a2214a8544fd7487",
            "bb355d116d4845f1b87e4e9cc721eb4e",
            "dae0a4134701445e915e2e68e6674b6d",
            "8c36d710325f42e8856aa6f2af220954",
            "d24cea188c2647798280b05f4ff9fd75",
            "33453ab8619a4ebeb0791d703304a2a3",
            "9eee4bdfa7a94933ae6a2ea65caea012",
            "cc3cc36aa9ac42f98630fa7b3eca8039",
            "550d3a368ba442d486331e1a929ae99c",
            "40fb2dc48efa4f048a1440737d875208",
            "26f6c4a21af447729a7fc9afc4a11096",
            "ed4067b6a5fa4af38909dc9f8078e08b",
            "d78cef16755146608c6c09577c41697d",
            "58e6f77e76fe480296d454f55939beab",
            "8ec6141aaee74c9e94c3721686dae95b",
            "9f44fa1de740488db039732a4cf980fa",
            "87aee0cbdd784cfbaa1071e81e5eccb9",
            "0336c061669e4a42aee202c9e43d3b97",
            "00f10a40e7a7407fbe6eb926b4468fd4",
            "fb1b502fc8894ee3b00a6f47e92fe13b",
            "5a4bb50e89f941aa8997f4ae37498c84",
            "303b3ba8f7d44a6dace4bbfef816a035",
            "c5c5afae2bc342149a419df94624524c",
            "74cc4dcf1f8a461aa4b75fdfce42e6ee",
            "40cc40cbad074622b26de796e6fe59b5",
            "ff68a5818a2c401a976e5f7643054680",
            "03e14647b6204109a688ee47e379f280",
            "65f6ca51972240739986b1c228bf7fbc",
            "06e1f36f992d430490c1728eadbccfa6",
            "396561cdb27343da994f53d96550766e",
            "514afedb9f6b420f855847df4d03a4dd",
            "4cd90c8d434547a8a362665b81270f2f",
            "6381875468c647d5abf322b6f4156bdc",
            "9a878e8a63ea486fa33b6fdd9591e525",
            "2f2c08f19efb4d85b78fee82222ecdd3",
            "eee05cd85ef0412199ebcd62c4bcf993",
            "c2c70ec66da44f5797a80344736caeec",
            "a354259fc6f14c8f8006719e2d06712d",
            "3a52e5719ceb463395c08c2f58b8eea8",
            "d157f8028106462aad29e23b3d8670d2",
            "a2ca58f531844e389362066d313f6836",
            "44edb04cfe404865bf59133e76cd353e",
            "c38684263b8a4ec999cf90f58de2c246",
            "88ae211a9e1e4a36bd5eb2a6dde0f449",
            "5b93c08f811c4b67a78584e869f02775",
            "4184f10950c54ba180893e52e1387799",
            "9ff2ac5108e44016aae4fb2385939937",
            "8ec388a169444158a5b091a61e90368c",
            "bd7738bf08d644528e9e0252ba29f0c1",
            "418ef157a35b4637b61e76a6435bf4aa",
            "616bf6fa36414fe1a4d7600889cc6808",
            "6c827d348c174afd9685eb884eee831e",
            "2793c6370c404ee2b1f104bad333caea",
            "55e966f6f50b4c459819eebc4e4af23f",
            "bb8520387dec40c6a894adfcd9142c3f",
            "11951cd71bf342d48268c4f82bc3b7d5",
            "87630f3c5bb04aa0a3c47d9815e9945e",
            "206b41196f4a49af8447dc2a15b5ae78",
            "d76a08b86b4c425086c4c28a523e6b44",
            "026846d25be04e18821bc313d717db0b",
            "6c2c75db41044b27bd9873a3a1181cf2",
            "bba2270caec141769ead43a33ea28c74",
            "83336490707b43d1aa3ebe5c21799082",
            "2cd394c3509c4dd59db7737c1a53c26d",
            "5440b65d71cc4e66bbcfe4deaabe1b1b",
            "4649e5e1451541a499301da0dc6b3776",
            "8ef70f9726cf4a92939387a5dd1a19ec",
            "0304c68710fc4682a247d703a91f00fe",
            "84c9d299bc7b42959c5aa46619279b9c",
            "9f36a8f6e75642b789dcde9c05bbc854",
            "1fe007423d114b6c85532a2c72462b47",
            "cec11f92fa1b45fd88d0d259d9719ab5",
            "2ec04998e14f448a921b71f312693e35",
            "553596d1c2ec42bc87b607f4947b1d4f",
            "d0975f48b0984638a7e786c2f3809724",
            "9a9f6e881dd34f429b8fa5acac5b553b",
            "f5deccd2fbe64a0796678e8c145af145",
            "8ff99935fbc443819576bdfb9bc2eb86",
            "6b8afc9fec4743099e8b3dc242a04044",
            "cf9dfc49f8814af096cd21114f055be9",
            "dd5bfb8c7d9a40018e931e60121250dc",
            "73a8840e2dab45a189fdeebc0b12541b",
            "dd395def6874437f8f8ae4ca85c2c557",
            "f0f76b34d61d46f58cf5cadfa0abd214",
            "9feb5bdff9fa4ec3b252f90308bc3449",
            "23c57f46a5be4b949d6fc7a48dc55234",
            "c33b92492d9c4f119e7fc2ee1d0aa99d"
          ]
        },
        "outputId": "e65e14f1-19c9-4547-9d26-e03b4c1b612c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d3f496804e545139c2ba7d2cdc8d4f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35025a25703b477c87319678313f4db1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "991d36d1feaf4a72b9b9cee579c6ba02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88b401a83f4846b08830dd094ead7797"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74836699da4d43d9840af9509b7a87ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13b1b7814f7440fcb5f2e37cca347ac5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b8b2dc3522b4a6daaa9c8f9242515e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26f6c4a21af447729a7fc9afc4a11096"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "303b3ba8f7d44a6dace4bbfef816a035"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6381875468c647d5abf322b6f4156bdc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88ae211a9e1e4a36bd5eb2a6dde0f449"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb8520387dec40c6a894adfcd9142c3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4649e5e1451541a499301da0dc6b3776"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5deccd2fbe64a0796678e8c145af145"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "embedding_model = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "device = 'cuda:0' # make sure you are on gpu\n",
        "docs = [\n",
        "    \"An example document\",\n",
        "    \"A second document as an example\"\n",
        "]\n",
        "### your code ###\n",
        "hf_auth_key=os.environ.get('HF_AUTH')\n",
        "model_kwargs = {'device': device,}\n",
        "embed_model = HuggingFaceEmbeddings(model_name=embedding_model, model_kwargs=model_kwargs)\n",
        "### your code ###"
      ],
      "id": "HI3CJ5bbUTsT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U73Hj93V0_-"
      },
      "source": [
        "Embed the example documents using the model you created and check the output.\n",
        "The output should be a list of lists, containing the embeddings."
      ],
      "id": "_U73Hj93V0_-"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9Qt3SDKoUvKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f60a80-8a84-4464-c9e5-5189f898c960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of docs: 2\n",
            "dimension of docs: 384\n"
          ]
        }
      ],
      "source": [
        "### your code ###\n",
        "embeddings = embed_model.embed_documents(docs)\n",
        "### your code ###\n",
        "print(\"number of docs:\",len(embeddings))\n",
        "print(\"dimension of docs:\",len(embeddings[0]))"
      ],
      "id": "9Qt3SDKoUvKx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D8sr-g9W8cw"
      },
      "source": [
        "Now we use the embedding pipeline created above to store the embeddings in a Pinecone vector index. First, lets setup the Pinecone environment, collect your API key and environment name from the environment variables, and initiate Pinecone with them."
      ],
      "id": "2D8sr-g9W8cw"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tycv_q6RW8tO"
      },
      "outputs": [],
      "source": [
        "### your code ###\n",
        "pinecone.init(api_key=os.environ['PINECONE_API_KEY'], environment=\"gcp-starter\")\n",
        "### your code ###"
      ],
      "id": "tycv_q6RW8tO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9tvVVQ7X2pV"
      },
      "source": [
        "Initialize the index `rag-assignment` inside Pinecone. Use the cosine similarity as similarity metric. Keep in mind that if you run this multiple times on a free tier, where only one index is allowed, you need to remove the index created to make room for a new one (Pinecone index gets archived automatically after 14 days of inactivity)."
      ],
      "id": "_9tvVVQ7X2pV"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "g_ZA_2J5XyTD"
      },
      "outputs": [],
      "source": [
        "index_name = 'rag-assignment'\n",
        "### your code ###\n",
        "try:\n",
        "  if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(name=index_name, dimension=len(embeddings[0]), metric=\"cosine\", shards=1)\n",
        "    index = pinecone.Index(index_name=index_name)\n",
        "except Exception as e:\n",
        "  print(f\"Error initializing Pinecone index: {e}\")\n",
        "  print(f\"Index: {pinecone.list_indexes()}\")\n",
        "### your code ###"
      ],
      "id": "g_ZA_2J5XyTD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxfs9gshYfKx"
      },
      "source": [
        "Lets take a look at the index you created. As of now the index should be empty but have the correct embedding dimension."
      ],
      "id": "rxfs9gshYfKx"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gNnN9mEyYWHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6588f647-de3e-4d54-c528-05ce6d508cae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 384,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "index_name = 'rag-assignment'\n",
        "index = pinecone.Index(index_name)\n",
        "index.describe_index_stats()"
      ],
      "id": "gNnN9mEyYWHB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woQKBXfobZMg"
      },
      "source": [
        "Process the dataset in batches of `32` and push the vectors to the Pinecone index. Your index should include the IDs and embeddings for each chunk. As metadata, pass the original text as `text` and the URL as `source` (no need to add the `https`). We use this metadata later to retrieve the original text."
      ],
      "id": "woQKBXfobZMg"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "K8vjCSVKa8Y6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4225f2bd-648d-4dba-ddf0-e93e6e4b341c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 114/114 [00:27<00:00,  4.08it/s]\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "for i in tqdm(range(0, len(data), batch_size)):\n",
        "  ### your code ###\n",
        "    batch = data.iloc[i:i+batch_size]\n",
        "\n",
        "    ids = batch[\"id\"].tolist()\n",
        "    texts = batch[\"text\"].tolist()\n",
        "    embeds = embed_model.embed_documents(texts)\n",
        "\n",
        "    sources = batch[\"source\"].tolist()\n",
        "    texts = batch[\"text\"].tolist()\n",
        "    #metadata = [{'source':source,'text':text} for source in sources for text in texts]\n",
        "    metadata = [{'source': source, 'text': text} for source, text in zip(sources, texts)]\n",
        "\n",
        "    # Format data for indexing and upsert\n",
        "    index.upsert(vectors=zip(ids, embeds, metadata))\n",
        "\n",
        "    ### your code ###\n"
      ],
      "id": "K8vjCSVKa8Y6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz2UZVj8ff_L"
      },
      "source": [
        "Now if we look at the index statistics we should have vectors of dimension `384`."
      ],
      "id": "kz2UZVj8ff_L"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "cH9Zq6azfgJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97846c5c-436f-468c-d743-acf4959bcc50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 384,\n",
              " 'index_fullness': 0.03593,\n",
              " 'namespaces': {'': {'vector_count': 3593}},\n",
              " 'total_vector_count': 3593}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ],
      "id": "cH9Zq6azfgJm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK-2Scv8qqYV"
      },
      "source": [
        "#### ${\\color{red}{Comments\\ 1.2}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "cross-feedback comment section\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ],
      "id": "NK-2Scv8qqYV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bVrpkiJhHAF"
      },
      "source": [
        "## Subtask 1.3: Text Generation Pipeline\n"
      ],
      "id": "5bVrpkiJhHAF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPykfVaHkIkO"
      },
      "source": [
        "So far we have our index ready and a way to find the most similar chunks to our query. Now, we need a way to generate the answer from the retrieved chunks. For this purpose, we use the `text-generation` pipeline from Hugging Face (refer to the Hugging Face [tutorial](https://moodle.uni-heidelberg.de/pluginfile.php/1286642/mod_resource/content/1/HuggingFace.ipynb)) and load it into LangChain using a wrapper."
      ],
      "id": "ZPykfVaHkIkO"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "CL_PhWM3lEnj"
      },
      "outputs": [],
      "source": [
        "from torch import cuda, bfloat16\n",
        "import os\n",
        "import transformers\n",
        "model_id = 'meta-llama/Llama-2-13b-chat-hf'"
      ],
      "id": "CL_PhWM3lEnj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3l34T5T3eEN"
      },
      "source": [
        "Quantization techniques reduce memory and computational costs by representing weights and activations with lower-precision data types like 8-bit integers (int8). This enables loading larger models you normally wouldn’t be able to fit into memory, and thus speeds up inference.\n",
        "To make the process of model quantization more accessible, Hugging Face has seamlessly integrated with the [Bitsandbytes](https://huggingface.co/docs/accelerate/usage_guides/quantization) library.\n",
        "\n",
        "Define a config from `Bitsandbytes` that enables 4-bit quantization and set the nested quantization to `true`. This changes the datatype from float 32 (default) to normalized float 4 datatype to contain 4 bits of information.\n",
        "Additionally, add a compute type to store weights in 4-bits, but the computation to happen in 16-bit (bfloat16).\n",
        "Moreover, set the `bnb_4bit_use_double_quant` to true, which uses a second quantization after the first one to save an additional 0.4 bits per parameter.\n",
        "Refer to [here](https://huggingface.co/docs/transformers/main_classes/quantization) for more information."
      ],
      "id": "A3l34T5T3eEN"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "mXNTODoOlFjX"
      },
      "outputs": [],
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "  ### your code ###\n",
        "bitsAndBites_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,                  #enables 4-bit quantization\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,      #sets computation to bfloat16 for speedups\n",
        "    bnb_4bit_quant_type=\"fp4\",          #sets the quantization data type to FP4\n",
        "    bnb_4bit_use_double_quant=True,     #enables nested quantization\n",
        ")\n",
        "  ### your code ###"
      ],
      "id": "mXNTODoOlFjX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wea-kVMF4Kvf"
      },
      "source": [
        "Use your Hugging Face token to load the correct model configuration using the `transformers` library."
      ],
      "id": "Wea-kVMF4Kvf"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7U47CyIk4EUz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "317b8d13be2a42388e9047f341d06d7e",
            "e68e5cf14da841bbace42e5b20127955",
            "17ed63cc78fa4ac390a072ef358e6c95",
            "4a5b8d8bbd4f4ffb92650e575a34469b",
            "7be48439fb6448acbeb0e4966e9b863c",
            "323479d062f9429e851f3b3da5d77f81",
            "329a96844904456f9ace515e9d2f056a",
            "7871f650764b4010b1e7c04cdecbfb37",
            "a67ebf98861a4c97b5bddfaa0c181937",
            "b70bb84313614f8bae5e379af830d51e",
            "97f521297e1043e58896b8ca40fd8444"
          ]
        },
        "outputId": "77f17a95-f764-4203-d46c-b70df590efed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/587 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "317b8d13be2a42388e9047f341d06d7e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "### your code ###\n",
        "\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    model_id,\n",
        "    token=os.environ.get('HF_AUTH')\n",
        ")\n",
        "### your code ###\n"
      ],
      "id": "7U47CyIk4EUz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8CNl7G1SsUC"
      },
      "source": [
        "Load the model for text generation (pay attention to the model type) using the configuration file you have defined, with the specified quantization, and set the `trust_remote_code` flag to `true`. Another flag that is useful for large mode is  `device_map=\"auto\"`. By setting this flag, Accelerate will determine where to put each layer to maximize the use of GPUs and offload the rest on the CPU, or even the hard drive if you don’t have enough GPU RAM (or CPU RAM).\n",
        "\n",
        "It will take a while for the model to download."
      ],
      "id": "V8CNl7G1SsUC"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TUzuGsv61cBA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "bf1c3b2224c146cbabbe6cb6bad690f5",
            "26c7a0b69fc848efb0b35896c94f1409",
            "0fc56e2737a24145b8cee1c600543aea",
            "efde1b2b98284d799de17f451d447288",
            "2923ec0a08654ca2b5c8cfbd58808fa9",
            "84864580f8974f09be816cfd9019f805",
            "27bff3f8af6e45a88e7791ec60244995",
            "7c5b3078e17746d19219486ddc9663fc",
            "c7e74e6ebb1c4e0b89087e44917b476a",
            "3dc394dae74543fe92775295b36c9bf1",
            "3e2f4d93fb0b4cc7bf9afdddb49b9f42",
            "cded74f0f53e44dda2dd7dd42c6bd30b",
            "157b06454e274c8a850ac56e64c8e7cd",
            "73463f4225d24a14a8183ea9f234667a",
            "a094ec16cdc64d52ae0c0685224b645f",
            "10ed004d8c784a8cabadc74f4c3b9c81",
            "733cf6cc08b742cc931681eee162c511",
            "86ac67d8aaf3404ebb810762479a9255",
            "e1a7d520fad04351ae2676c88f28f778",
            "0944e8c4266540009d5b86275de253ec",
            "2b3fc774dc6b4e0cba6e6303bd8744b9",
            "c825ca069421469d83972afd1306df61",
            "432c89b3be0341e4b1b12fd5f157afa3",
            "582b8355b004405abad99c4808ca3198",
            "311377797f1542948a1d3078cbcc2ea3",
            "cafaae5ce0af40029d483b50d3cbf216",
            "158670070a4d464d89d4090fe96a3c43",
            "ee192887ea024c4dafd6ea616ea13d13",
            "9930f4a8ba3b4eec92f01029422e140e",
            "e41a8f6466744056a3de1afef4760341",
            "1f1844f863a44e1aadba1fa8caaefafd",
            "7b7d84fcf55c48d5b021eaade3c49491",
            "2c639b0a1d4f4a3f8fb763958e1453ee",
            "a01f945887394424bc6f2b463dde671e",
            "f0282f10da324b809e0d29e4fdd4e6af",
            "282ab759840145d7a32a4eb016edf407",
            "15a362319928438a8e403983dbbc7be7",
            "79c51b48fcdb46ea9fde894e8779a9cb",
            "25e84319e30f4ed4a4f3cddd151f9fa4",
            "c8ad09109d5b42f88c393691fe80a1d1",
            "605667f5fd56411ba61935ccac58f2ec",
            "ee947e94cfc54744867343e8e614cd43",
            "bc9b0380036e4fce99a9e5ed64d60758",
            "ce912d904fdd4a1982e4d46c040a6b5e",
            "6b87b075f51744438c2419f2f97411f5",
            "8a7dbe69f6084b3cb89332b633b6f385",
            "02e194bcbf4a4e8188fbfaf4af1dd3e7",
            "2343c6dffd434938a985322b58e84a61",
            "3cecf3191af34552acc6193579852144",
            "18a2256e78314cc59cf667a5305af7e6",
            "0c93c5893f3c40889687b934316d8c94",
            "639b85b5739146a1a13b807c8a48e26a",
            "50283174aad340518b8ad3890d26f7d3",
            "26b641917f4e49d09a30b4ce6056c57a",
            "300b2643bdc9469ebfe3a51e26f627fb",
            "c8571fe617174ec7923473191283dca2",
            "4583010c83824a088de8d16e6abe308b",
            "e72d7ea238fc4b7ca694405fcf4c278c",
            "0e975299f7234f99a1d8be78f49aebcc",
            "8d482bc69cb84444856720fcccdbf8f5",
            "6f64db26c5564a9cb9ce769277be5bbd",
            "a4865495f3ad417fa031f7c5818e45b3",
            "0e40a55b6d7c4b83b4327925a3e0f04c",
            "2e6c522823f24df4836aec96bfe2936f",
            "2541b8f546644fd78748ed5e0b71f708",
            "d4abf97865504e1bb2f9a8179272fe40",
            "2b4d5a8c8b264dcaacc0667e49c4fabd",
            "cccb92a1294b4f84b0ddfe33b3a4bf68",
            "71b08ff4d96c424ea37b0ff0d1aef5cb",
            "2d3abd07886d426caa7a3f1383d5e45a",
            "380fd9af234a4af2baf8e0ef40d690e2",
            "e215669c68734cafa7e5d4fc79642baa",
            "29d3ab5dc3ed499b9085446380988c4f",
            "740efc74440d4243b5fd593dd5dc0069",
            "9a7328d1399847a99bcacddb36fb3873",
            "f0d96200bd1244bf8fd3eb5f14b9714b",
            "0de12cc978f04f05b6386391aa364887"
          ]
        },
        "outputId": "97784d91-90a1-4fba-90b8-4f3e7cabb8fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf1c3b2224c146cbabbe6cb6bad690f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cded74f0f53e44dda2dd7dd42c6bd30b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "432c89b3be0341e4b1b12fd5f157afa3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a01f945887394424bc6f2b463dde671e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/6.18G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b87b075f51744438c2419f2f97411f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8571fe617174ec7923473191283dca2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b4d5a8c8b264dcaacc0667e49c4fabd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded \n"
          ]
        }
      ],
      "source": [
        "#Loading the model will take some time, (roughly 5 min)\n",
        "### your code ###\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    config=model_config,\n",
        "    quantization_config=bitsAndBites_config,\n",
        "    device_map='auto',\n",
        "    token=os.environ.get('HF_AUTH'),\n",
        ")\n",
        "### your code ###\n",
        "model.eval()# we only use the model for inference\n",
        "print(f\"Model loaded \")"
      ],
      "id": "TUzuGsv61cBA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-brElhysTZVZ"
      },
      "source": [
        "You can even check the memory footprint of your model using the `get_memory_footprint` method.\n"
      ],
      "id": "-brElhysTZVZ"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zWDTgyKhlLLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcafed62-140b-4f45-b99b-1953d798e424"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7083970560"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "model.get_memory_footprint()"
      ],
      "id": "zWDTgyKhlLLQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViFoo0vlSFMp"
      },
      "source": [
        "The next thing we need to do is initialize a `text-generation` pipeline with Hugging Face that uses the Llama2 model to generate some text, given some input. We will then use this pipeline inside LangChain to build our question-answering system.\n",
        "`text-generation` pipeline generates text from a language model conditioned on a given input. The pipeline is similar to other Hugging Face pipelines and requires two things that we must initialize:\n",
        "\n",
        "1.   A language model, in this case, it will be `meta-llama/Llama-2-13b-chat-hf`.\n",
        "2.   A tokenizer for the language model.\n",
        "\n",
        "LangChain expects the full-text outputs, therefore set the `return_full_text` to true. You can also pass additional generation parameters to the model.\n",
        "Since we want the questions to be answered mainly based on the retrieved chunks, let's set the model temperature to a low value of 0.01 to reduce randomness. Additionally, add a repetition penalty of 1.1 to stop the model from repeating itself and the maximum number of generation tokens to 512."
      ],
      "id": "ViFoo0vlSFMp"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "1aFv-9-lPCJO"
      },
      "outputs": [],
      "source": [
        "### your code ###\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    token=os.environ.get('HF_AUTH')\n",
        ")\n",
        "\n",
        "generate_text = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,  # langchain expects the full text\n",
        "    task='text-generation',\n",
        "    temperature=0.01,  # 'randomness' of outputs, 0.0 is the min and 1.0 is the max\n",
        "    max_new_tokens=512,  # max number of tokens to generate in the output\n",
        "    repetition_penalty=1.1  # without this output begins repeating\n",
        ")\n",
        "### your code ###"
      ],
      "id": "1aFv-9-lPCJO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvdSEw9PZ-n9"
      },
      "source": [
        "We provide the language model a general question to make sure our pipeline is working correctly."
      ],
      "id": "ZvdSEw9PZ-n9"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "FpuCkc77RF53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f62e22-a925-42c5-fbd6-6b2103720c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain to me the difference between alligator and crocodile.\n",
            "\n",
            "Alligators and crocodiles are both large, carnivorous reptiles that live in aquatic environments, but there are several key differences between them. Here are some of the main differences:\n",
            "\n",
            "1. Appearance: Alligators have a wider, rounder snout compared to crocodiles, which have a longer, thinner snout. Alligators also have a more rounded body shape, while crocodiles are more streamlined.\n",
            "2. Habitat: Alligators are found only in freshwater environments, such as lakes, rivers, and swamps, while crocodiles can be found in both freshwater and saltwater environments.\n",
            "3. Geographic range: Alligators are only found in the southeastern United States and China, while crocodiles are found in many parts of the world, including Africa, Asia, Australia, and the Americas.\n",
            "4. Nesting habits: Alligators build mounds of vegetation and mud to lay their eggs, while crocodiles dig holes in the sand or mud to lay their eggs.\n",
            "5. Jaw structure: Alligators have a different jaw structure than crocodiles, with a stronger bite force and a more powerful jaw musculature. This allows alligators to eat larger prey, such as deer and small alligators.\n",
            "6. Behavior: Alligators are generally less aggressive than crocodiles and are more likely to retreat from threats, while crocodiles are more aggressive and territorial.\n",
            "7. Diet: Both alligators and crocodiles are carnivores, but alligators tend to eat more plant material than crocodiles, who are primarily meat-eaters.\n",
            "8. Size: Crocodiles are generally larger than alligators, with some species reaching lengths of over 20 feet (6 meters). Alligators typically reach lengths of around 15 feet (4.5 meters).\n",
            "\n",
            "These are just a few of the differences between alligators and crocodiles. While they share some similarities, they are distinct species with unique characteristics.\n"
          ]
        }
      ],
      "source": [
        "sample_input = \"Explain to me the difference between alligator and crocodile.\"\n",
        "### your code ###\n",
        "generated_text = generate_text(sample_input)[0]['generated_text']\n",
        "### your code ###\n",
        "print(generated_text)"
      ],
      "id": "FpuCkc77RF53"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QtViqTBSsPS"
      },
      "source": [
        "Use the LangChain Hugging Face wrapper, as subset of [LLM chain](https://python.langchain.com/docs/modules/chains/foundational/llm_chain) to create an interface for the text generation pipeline."
      ],
      "id": "2QtViqTBSsPS"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "6-spabNmRMM2"
      },
      "outputs": [],
      "source": [
        "### your code ###\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=generate_text)\n",
        "### your code ###"
      ],
      "id": "6-spabNmRMM2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EFZBGNgTM20"
      },
      "source": [
        "To confirm that it works the same way, use the sample input to generate text using the llm chain. The input should be passed as the `prompt` to the language model."
      ],
      "id": "9EFZBGNgTM20"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rDToa1YOTFEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ec0df8-275c-4f88-c0a3-c7b90836a7d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Alligators and crocodiles are both large, carnivorous reptiles that live in aquatic environments, but there are several key differences between them. Here are some of the main differences:\n",
            "\n",
            "1. Appearance: Alligators have a wider, rounder snout compared to crocodiles, which have a longer, thinner snout. Alligators also have a more rounded body shape, while crocodiles are more streamlined.\n",
            "2. Habitat: Alligators are found only in freshwater environments, such as lakes, rivers, and swamps, while crocodiles can be found in both freshwater and saltwater environments.\n",
            "3. Geographic range: Alligators are only found in the southeastern United States and China, while crocodiles are found in many parts of the world, including Africa, Asia, Australia, and the Americas.\n",
            "4. Nesting habits: Alligators build mounds of vegetation and mud to lay their eggs, while crocodiles dig holes in the sand or mud to lay their eggs.\n",
            "5. Jaw structure: Alligators have a different jaw structure than crocodiles, with a stronger bite force and a more powerful jaw musculature. This allows alligators to eat larger prey, such as deer and small alligators.\n",
            "6. Behavior: Alligators are generally less aggressive than crocodiles and are more likely to retreat from threats, while crocodiles are more aggressive and territorial.\n",
            "7. Diet: Both alligators and crocodiles are carnivores, but alligators tend to eat more plant material than crocodiles, who are primarily meat-eaters.\n",
            "8. Size: Crocodiles are generally larger than alligators, with some species reaching lengths of over 20 feet (6 meters). Alligators typically reach lengths of around 15 feet (4.5 meters).\n",
            "\n",
            "These are just a few of the differences between alligators and crocodiles. While they share some similarities, they are distinct species with unique characteristics.\n"
          ]
        }
      ],
      "source": [
        "### your code ###\n",
        "generated_text = llm(sample_input)\n",
        "print(generated_text)\n",
        "### your code ###"
      ],
      "id": "rDToa1YOTFEX"
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OixQnTTrFGdV",
        "outputId": "7376bcdf-9e05-4b5b-ff32-978fb6a5e2e0"
      },
      "id": "OixQnTTrFGdV",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain to me the difference between alligator and crocodile.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn7-zQxeVhWF"
      },
      "source": [
        "#### ${\\color{red}{Comments\\ 1.3}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "cross-feedback comment section\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ],
      "id": "mn7-zQxeVhWF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRwTtnQEWq5h"
      },
      "source": [
        "## Subtask 1.4: Question Answering Chain\n"
      ],
      "id": "VRwTtnQEWq5h"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr9QzQvYXDBS"
      },
      "source": [
        "For Retrieval Augmented Generation (RAG) in LangChain, we need to initialize either a `RetrievalQA` or `RetrievalQAWithSourcesChain` object.\n",
        "\n",
        "`RetrievalQA` is a method for question-answering tasks, utilizing an index to retrieve relevant documents or text chunks, it is suitable for straightforward Q&A applications.\n",
        "\n",
        "`RetrievalQAWithSourcesChain` is an extension of RetrievalQA that chains together multiple sources of information, providing context and the source for answers.\n",
        "\n",
        " For both of these, we need an LLM and a Pinecone index. For LangChain to be able to use the Pinecone index, we need to initialize it through the LangChain vector store.\n",
        "\n",
        " **Hint**: You need to explicitly tell the vector storage where to find the original text."
      ],
      "id": "wr9QzQvYXDBS"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "RQIR_Gb6Wrfs"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Pinecone\n",
        "### your code ###\n",
        "\n",
        "vectorstore = Pinecone.from_existing_index(index_name, embed_model)\n",
        "### your code ###"
      ],
      "id": "RQIR_Gb6Wrfs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS9d51dyptJd"
      },
      "source": [
        "Let's try a query that is specific to the LangChain documentation and see which chunks are relevant. Use the vector storage defined above to find the top-3 chunks related to the given query."
      ],
      "id": "mS9d51dyptJd"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "sQeWNPDqXdJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41806088-cb71-4b7a-af69-17a59dc8e5c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. langchain 0.0.353¶\n",
            "langchain.agents¶\n",
            "Agent is a class that uses an LLM to choose a sequence of actions to take.\n",
            "In Chains, a sequence of actions is hardcoded. In Agents,\n",
            "a language model is used as a reasoning engine to determine which actions\n",
            "to take and in which order.\n",
            "Agents select and use Tools and Toolkits for actions.\n",
            "Class hierarchy:\n",
            "BaseSingleActionAgent --> LLMSingleActionAgent\n",
            "                          OpenAIFunctionsAgent\n",
            "                          XMLAgent\n",
            "                          Agent --> <name>Agent  # Examples: ZeroShotAgent, ChatAgent\n",
            "BaseMultiActionAgent  --> OpenAIMultiFunctionsAgent\n",
            "Main helpers:\n",
            "AgentType, AgentExecutor, AgentOutputParser, AgentExecutorIterator,\n",
            "AgentAction, AgentFinish\n",
            "Classes¶\n",
            "agents.agent.Agent\n",
            "Agent that calls the language model and deciding the action.\n",
            "agents.agent.AgentExecutor\n",
            "Agent that is using tools.\n",
            "agents.agent.AgentOutputParser\n",
            "Base class for parsing agent output into agent action/finish.\n",
            "agents.agent.BaseMultiActionAgent\n",
            "Base Multi Action Agent class.\n",
            "agents.agent.BaseSingleActionAgent\n",
            "Base Single Action Agent class.\n",
            "agents.agent.ExceptionTool\n",
            "Tool that just returns the query.\n",
            "agents.agent.LLMSingleActionAgent\n",
            "Base class for single action agents.\n",
            "agents.agent.MultiActionAgentOutputParser\n",
            "Base class for parsing agent output into agent actions/finish.\n",
            "agents.agent.RunnableAgent\n",
            "Agent powered by runnables. \n",
            "\n",
            "2. langchain.agents.loading.load_agent¶\n",
            "langchain.agents.loading.load_agent(path: Union[str, Path], **kwargs: Any) → Union[BaseSingleActionAgent, BaseMultiActionAgent][source]¶\n",
            "Unified method for loading an agent from LangChainHub or local fs.\n",
            "Parameters\n",
            "path – Path to the agent file.\n",
            "**kwargs – Additional keyword arguments passed to the agent executor.\n",
            "Returns\n",
            "An agent executor. \n",
            "\n",
            "3. Implements Program-Aided Language Models.\n",
            "As in https://arxiv.org/pdf/2211.10435.pdf.\n",
            "This is vulnerable to arbitrary code execution:\n",
            "https://github.com/langchain-ai/langchain/issues/5872\n",
            "Classes¶\n",
            "pal_chain.base.PALChain\n",
            "Implements Program-Aided Language Models (PAL).\n",
            "pal_chain.base.PALValidation([...])\n",
            "Initialize a PALValidation instance.\n",
            "langchain_experimental.plan_and_execute¶\n",
            "Classes¶\n",
            "plan_and_execute.agent_executor.PlanAndExecute\n",
            "Plan and execute a chain of steps.\n",
            "plan_and_execute.executors.base.BaseExecutor\n",
            "Base executor.\n",
            "plan_and_execute.executors.base.ChainExecutor\n",
            "Chain executor.\n",
            "plan_and_execute.planners.base.BasePlanner\n",
            "Base planner.\n",
            "plan_and_execute.planners.base.LLMPlanner\n",
            "LLM planner.\n",
            "plan_and_execute.planners.chat_planner.PlanningOutputParser\n",
            "Planning output parser.\n",
            "plan_and_execute.schema.BaseStepContainer\n",
            "Base step container.\n",
            "plan_and_execute.schema.ListStepContainer\n",
            "List step container.\n",
            "plan_and_execute.schema.Plan\n",
            "Plan.\n",
            "plan_and_execute.schema.PlanOutputParser\n",
            "Plan output parser.\n",
            "plan_and_execute.schema.Step\n",
            "Step.\n",
            "plan_and_execute.schema.StepResponse\n",
            "Step response.\n",
            "Functions¶ \n",
            "\n"
          ]
        }
      ],
      "source": [
        "query = 'what is a LangChain Agent?'\n",
        "### your code ###\n",
        "\n",
        "found_docs = vectorstore.max_marginal_relevance_search(query, k=3, fetch_k=10)\n",
        "for i, doc in enumerate(found_docs):\n",
        "    print(f\"{i + 1}.\", doc.page_content, \"\\n\")\n",
        "### your code ###"
      ],
      "id": "sQeWNPDqXdJe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEMooqALXqOt"
      },
      "source": [
        "Now use the `vectorstore` and `llm` to initialize the `RetrievalQA` object, which showcases question answering over an index. `RetrievalQA` is a document chain, these are useful for summarizing documents, answering questions about documents, extracting information from documents, and more. All such chains operate with 4 different chain types:\n",
        "\n",
        "\n",
        "1.   `stuff`: it takes a list of documents, inserts them all into a prompt, and passes that prompt to an LLM.\n",
        "2.   `refine`: it constructs a response by looping over the input documents and iteratively updating its answer. It is well-suited for tasks that require analyzing more documents than can fit in the model’s context.\n",
        "3. `map_reduce`:  it first applies an LLM chain to each document individually (the Map step), treating the chain output as a new document. It then passes all the new documents to a separate combined documents chain to get a single output (the Reduce step).\n",
        "4. `map_re_rank`: it runs an initial prompt on each document that not only tries to complete a task but also gives a score for how certain it is in its answer. The highest-scoring response is returned.\n",
        "\n",
        "For this assignment, we focus only on the first type. Make sure to set the `verbose` to `true`, so we can see the different stages of processing that happens while answering a question (you might need to set this parameter more than once). As mentioned before, we want our retrieve to input top-5 most similiar chunks to the query to generate an answer."
      ],
      "id": "gEMooqALXqOt"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "lYnUrFnaXqU0"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "### your code ###\n",
        "from langchain_core.vectorstores import VectorStoreRetriever\n",
        "\n",
        "rag_pipeline = VectorStoreRetriever(vectorstore=vectorstore)\n",
        "\n",
        "retrievalQA = RetrievalQA.from_llm(llm=llm, retriever=rag_pipeline)\n",
        "\n",
        "### your code ###\n",
        "query='what is a LangChain Agent?'"
      ],
      "id": "lYnUrFnaXqU0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4Mo0JNMqSC7"
      },
      "source": [
        "First, we try to answer the question only using Llama2. As you see the answer is not convincing as it does not have access to the LangChain documentation."
      ],
      "id": "O4Mo0JNMqSC7"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "jGk2ZsUVYiJ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "30c135d2-5154-4cc2-9abf-24e87a7f2485"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nA LangChain Agent is an AI-powered chatbot that uses natural language processing (NLP) to understand and respond to user queries. It is designed to provide personalized support and answer questions in real-time, 24/7. The agent is trained on a large dataset of customer interactions, which enables it to understand the nuances of human language and provide accurate responses.\\n\\nLangChain Agents are powered by advanced machine learning algorithms that allow them to learn from each interaction and improve their performance over time. They can be integrated with various messaging platforms such as Facebook Messenger, WhatsApp, Slack, and more. This allows businesses to provide seamless support to their customers across multiple channels.\\n\\nSome of the key features of LangChain Agents include:\\n\\n1. Natural Language Processing (NLP): LangChain Agents use NLP to understand and interpret user queries, allowing them to provide accurate responses.\\n2. Machine Learning: LangChain Agents are trained on a large dataset of customer interactions, which enables them to learn from each interaction and improve their performance over time.\\n3. Multi-Channel Support: LangChain Agents can be integrated with various messaging platforms such as Facebook Messenger, WhatsApp, Slack, and more.\\n4. Personalized Support: LangChain Agents can be tailored to provide personalized support based on user preferences and behavior.\\n5. Real-Time Response: LangChain Agents provide real-time responses to user queries, ensuring that customers receive prompt and efficient support.\\n\\nOverall, LangChain Agents offer a powerful solution for businesses looking to provide personalized support to their customers through AI-powered chatbots.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "llm(query)"
      ],
      "id": "jGk2ZsUVYiJ0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8U5Vce0qdch"
      },
      "source": [
        "Now use the Pipeline from above and see how the answer changes."
      ],
      "id": "W8U5Vce0qdch"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "1KaQyXKQYn57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623b4419-6a88-4035-eba4-c5b10a223ada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'what is a LangChain Agent?',\n",
              " 'result': ' A LangChain Agent is a class that uses an LLM to choose a sequence of actions to take. It selects and uses Tools and Toolkits for actions. It is a base class for other classes like ZeroShotAgent, ChatAgent, etc.'}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "### your code ###\n",
        "\n",
        "retrievalQA(query)\n",
        "\n",
        "### your code ###\n"
      ],
      "id": "1KaQyXKQYn57"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ2JxOL4aqM2"
      },
      "source": [
        "#### ${\\color{red}{Comments\\ 1.4}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "cross-feedback comment section\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ],
      "id": "pJ2JxOL4aqM2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inIFkOziTce3"
      },
      "source": [
        "## Subtask 1.5: Conversational Retrieval Chain\n",
        "\n",
        "\n"
      ],
      "id": "inIFkOziTce3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btxcJlEITiDt"
      },
      "source": [
        "We can also extend our retrieval chain to be able to remember the previous questions and answer the current question by looking at the previous context.\n",
        "The important part of a conversational model is conversation memory, which transforms the stateless language model to be able to remember previous interactions, e.g., similiar to ChatGPT. In this subtask, we will use LangChain to create a conversational memory.\n"
      ],
      "id": "btxcJlEITiDt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYHPVo-9TiGU"
      },
      "source": [
        "To implement the memory we use `ConversationalRetrievalChain`.\n",
        "This chain takes in chat history (a list of messages) and new questions and then returns an answer to that question. The algorithm for this chain consists of three parts:\n",
        "\n",
        "1. Use the chat history and the new question to create a new question that contains the information from the previous context.\n",
        "\n",
        "2. This new question is passed to the retriever and relevant documents are returned.\n",
        "\n",
        "3. The retrieved documents are passed to an LLM to generate a final response."
      ],
      "id": "DYHPVo-9TiGU"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "GLv_d-RYyNYL"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "### your code ###\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "qa_conversation = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
        "\n",
        "result = qa_conversation({\"question\":query, \"chat_history\":chat_history})\n",
        "\n",
        "### your code ###\n"
      ],
      "id": "GLv_d-RYyNYL"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "S6HxivGwyv2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "215d38a5-2dd2-4730-8f89-d778a734d04b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A LangChain Agent is a class that uses an LLM to choose a sequence of actions to take. It selects and uses Tools and Toolkits for actions. It is a base class for other classes like ZeroShotAgent and ChatAgent.\n"
          ]
        }
      ],
      "source": [
        "print(result[\"answer\"])"
      ],
      "id": "S6HxivGwyv2x"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd6tqKhg24dL"
      },
      "source": [
        "Change the chat history to contain the previous question and answer pair and ask a follow-up question.  "
      ],
      "id": "yd6tqKhg24dL"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "36vj0R9Fyyd1"
      },
      "outputs": [],
      "source": [
        "follow_up=\"What are tools and toolkits?\"\n",
        "\n",
        "### your code ###\n",
        "chat_history = [(query, result[\"answer\"])]\n",
        "\n",
        "result = qa_conversation({\"question\":follow_up, \"chat_history\":chat_history})\n",
        "### your code ###"
      ],
      "id": "36vj0R9Fyyd1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvlY2MtH0xo3"
      },
      "source": [
        "This is the previous context that was fed in alongside the new question."
      ],
      "id": "EvlY2MtH0xo3"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "09zxWnojzKEu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2710c51a-ce1a-47b4-8056-115e0a6c62ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('what is a LangChain Agent?', ' A LangChain Agent is a class that uses an LLM to choose a sequence of actions to take. It selects and uses Tools and Toolkits for actions. It is a base class for other classes like ZeroShotAgent and ChatAgent.')]\n"
          ]
        }
      ],
      "source": [
        "print(chat_history)"
      ],
      "id": "09zxWnojzKEu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSlQYeWG04Gj"
      },
      "source": [
        "The current question is answered by knowing that the tools and toolkits are referring to a LangChain Agent, which was part of the previous question."
      ],
      "id": "DSlQYeWG04Gj"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "5FP4_WAbzMSQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "44296ffa-2838-4d0d-a424-a6850520b52b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  In the context of LangChain Agents, tools and toolkits refer to pre-built functionality that can be used by the agents to perform specific tasks or answer certain types of questions. Tools are individual pieces of functionality that can be combined to create more complex toolkits. Toolkits are collections of tools that can be used together to accomplish a particular goal or set of goals.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "result[\"answer\"]"
      ],
      "id": "5FP4_WAbzMSQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQUW_iFs3q3m"
      },
      "source": [
        "#### ${\\color{red}{Comments\\ 1.5}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "cross-feedback comment section\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ],
      "id": "LQUW_iFs3q3m"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KDwOSuNPBe-"
      },
      "source": [
        "## **Task 2: Advanced RAG Techniques and Evaluation (4 + 5 = 9 points)**"
      ],
      "id": "0KDwOSuNPBe-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN6pjlW7PBhQ"
      },
      "source": [
        "Now that you have successfully implemented your first RAG system, we dive into more advanced techniques and learn how to evaluate your methods using metrics you learned during the lecture. We focus on evaluation with an already annotated dataset. To this end, we load a small subset of [NarrativeQA](https://huggingface.co/datasets/narrativeqa), which is an English-language dataset of stories and corresponding questions designed to test reading comprehension, especially on long documents. We only load 30 samples from the data, as you will see in the upcoming sections, answer generation takes quite some time. In actual setting, it is advised to use a much larger set to obtain statistically significant results."
      ],
      "id": "cN6pjlW7PBhQ"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "wM2dodC2PAlr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "b4f6f625cf024fdeac3b1067ce224f75",
            "112292f466e64cab8c0a24c61d4abc35",
            "0ce3e21a43984ea3a96425ccd321b752",
            "30a42f2b4e734d8f99c477e079ce8529",
            "bcc8305e52024462bdba78df1cf5345a",
            "ddb291ae4911410eb2d10e7e88df8c58",
            "a8a752d9519b477c9d258d314a81ab0c",
            "ae90d7107c034b7c9e31155391744063",
            "2b782fd037e14371ac03a3f30695b8fc",
            "2e3cf3ae61744193b6634081147a43cc",
            "cf07a8dd5d744c1496750e2bea97b4ac",
            "9c3bf4c2bb0f4ab8a5670b6e15fe6a8b",
            "99201e440c0c4879bc003fb13c3195b0",
            "435b00d26c664c15a4082f8bbb4f1e44",
            "60089c5685294cd693ba9c44ae83cd2b",
            "09f2b9d12bd7437e82f4a471b8dc1c8a",
            "080c0bbb9e6b4b0b81661d4a79385c00",
            "d5211f0dcd5647e7af39d5ecb4dc1dad",
            "8ddc2cc0a7e24d8d982d45f9c0897988",
            "33d2e4f7e7b948628d4b5b5818412b86",
            "3f0f6ac974f142f6ae15c4c74ffa9eac",
            "de450b2a8f3f45838d42701e3e622251",
            "0bee540d79414caeb9a358cf8aebc20b",
            "892e2d34825349e9b04a1afae51ef993",
            "9ab514ee01684b9eb8e37c339a0ecf96",
            "8097090e59c44886aff32a8cdaddb8cd",
            "bd69f8be94db40f8b6dbf3c88eee3e1a",
            "80126ff1d7a8468f829295b742b4b19e",
            "48b925d25cba4963ba5da2ca1ba37f27",
            "58aa43cbe3db40a69f45d2c8b5a5448a",
            "7320c873fe954e338e359413badea3a6",
            "25b6a49faca2469aae2bd539c150f4fa",
            "556c33dbc08641c28cba12b1c0cc9ac1"
          ]
        },
        "outputId": "39b0d126-0236-4be7-8784-14636e7bdb6f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/997 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4f6f625cf024fdeac3b1067ce224f75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/2.27M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c3bf4c2bb0f4ab8a5670b6e15fe6a8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/317 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bee540d79414caeb9a358cf8aebc20b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"satyaalmasian/narrativeqa_subset\",split=\"train[:30]\")\n",
        "len(dataset)"
      ],
      "id": "wM2dodC2PAlr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we already used our free index in Pinecone for the previous task, we use Chroma, an open-source vector database, instead. As opposed to Pinecone, Chroma creates a collection on your machine."
      ],
      "metadata": {
        "id": "N0HDF2M1fz4D"
      },
      "id": "N0HDF2M1fz4D"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "hZ8kqj95hqvo"
      },
      "outputs": [],
      "source": [
        "from langchain.docstore.document import Document\n",
        "documents=[ doc[\"text\"] for doc in dataset[\"document\"]]\n",
        "questions=[quest for quest in dataset[\"question\"]]\n",
        "answers=[ans for ans in dataset[\"answers\"]]\n",
        "documents=list(set(documents))"
      ],
      "id": "hZ8kqj95hqvo"
    },
    {
      "cell_type": "code",
      "source": [
        "docs= [Document(page_content=doc, metadata={\"source\": \"local\"}) for doc in documents]"
      ],
      "metadata": {
        "id": "fj0X3PqHIFpQ"
      },
      "id": "fj0X3PqHIFpQ",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of documents is smaller  than the number of questions and answers and each document is used as a reference for multiple questions:"
      ],
      "metadata": {
        "id": "3BDIuYQkJB0U"
      },
      "id": "3BDIuYQkJB0U"
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(docs))\n",
        "print(len(questions))"
      ],
      "metadata": {
        "id": "FbWqRg12JLJn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e2d851-8c59-4aec-8f2d-09fab7e6aa90"
      },
      "id": "FbWqRg12JLJn",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Subtask 2.1: Build Contextual Compression in LangChain"
      ],
      "metadata": {
        "id": "cD69GYOjjJuk"
      },
      "id": "cD69GYOjjJuk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's split our documents using the TextSplitter from Task 1 and embed them inside the Chroma database with the embedding model of the previous task."
      ],
      "metadata": {
        "id": "D-OyjUQGhGPq"
      },
      "id": "D-OyjUQGhGPq"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "M7NGs-RzhQa7"
      },
      "outputs": [],
      "source": [
        "### your code ###\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "### your code ###"
      ],
      "id": "M7NGs-RzhQa7"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "### your code ###\n",
        "vectordb = Chroma.from_documents(all_splits, embed_model, persist_directory=\"db\")\n",
        "retriever = vectordb.as_retriever()\n",
        "### your code ###"
      ],
      "metadata": {
        "id": "hHknAFVBf5ia"
      },
      "id": "hHknAFVBf5ia",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fist question in the set:\",questions[2]['text'])\n",
        "r_docs = retriever.get_relevant_documents(questions[2]['text'])\n",
        "r_docs"
      ],
      "metadata": {
        "id": "RbSBLyg364Ie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08822be3-609a-4528-8fd4-cc156019a11b"
      },
      "id": "RbSBLyg364Ie",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fist question in the set: Why do more students tune into Mark's show?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Mark - They can\\'t kick you out for that.\\n\\nNora - I\\'ve been cutting lessons.\\n\\nMark - Well that just deserves a suspension right.\\n\\nNora - Well then I said \"Fuck You\" to Creswood. You should have seen her face, she was \\nso happy she said \"Thank You\"\\n\\nMark - This school sucks. Jesus Christ!\\n\\nNora - This is why I don\\'t even care anymore. Look just leave it alone. There\\'s nothing \\nyou can do about it. <Nora runs off>\\n\\nJan - Hunter! Hunter wait a minute. I just wanted to say good bye and good luck.\\n\\nMark - Why?\\n\\nJan - I was fired, I made a mistake. I thought I could change things, I forgot you don\\'t \\nrock the boat.\\n\\nMark - Yeah especially when you\\'re in it.\\n\\nJan - Hey, chin up.\\n\\n<Staff room>\\n\\nBrian - Loretta what the hell is going on here.\\n\\nCreswood - It\\'s the trouble makers, you can\\'t run a top school with trouble makers in the \\nmix.\\n\\nBrian - Okay, so what exactly is a trouble maker.\\n\\nCreswood - Someone who has no interest in education.\\n\\nBrian - Oh c\\'mon that includes every teenager I know.\\n\\nCreswood - Can\\'t you understand that nothing is more important than a good education.\\n\\nBrian -  Except for the basic right to it.\\n\\nCreswood - The point is I have the highest S.A.T. scores in the state.', metadata={'source': 'local'}),\n",
              " Document(page_content=\"PTA. Parent #4 - I work with teenage gangs in the city I say we go after this guy.\\n\\n<Paige walks in>\\n\\nPaige - My name is Paige Woodward and I have something to say to you people. People \\nare saying that Harry is introducing bad things and encouraging bad things. But it seems \\nto me that these things were already here. My god why don't you people listen? He's \\ntrying to tell you something is wrong with this school. Half the people that are here are on \\na probation of some kind. We are all really scared to be who we really are. I am not \\nperfect. I've just been going through the motions of being perfect, and inside I'm \\nscreaming.\\n\\nCreswood - Paige, you were a model student.\\n\\n<Paige walks out were the press await>\\n\\nReporter #2 - Do you know who he is? Are you prepared to do anything he says?\\n\\nPaige - <Shouting into the camera> Can you hear me? Don't listen to them, don't listen to \\nany of them, stay on, stay hard!\\n\\nReporter #2 - Are you on drugs?\\n\\nPaige - Arrrgh. Talk Hard. Arrrrrgh.\\n\\nMark - I've got a lot of homework I'm gonna take off alright.\\n\\nMarla - Mark I know why your really going home. It's because you wanna listen to that \\nshow tonight don't you?\\n\\n<Play Peter Murphy>\", metadata={'source': 'local'}),\n",
              " Document(page_content=\"Marla Hunter - Young radical Brain, you were always fighting against the system. And \\nnow you are...\\n\\nBrian Hunter - I am the system, yeah. Is that a beer?\\n\\nMark Hunter (Happy Harry Hardon) - Sure!\\n\\nMarla Hunter - Have you notice his behaviour lately?\\n\\nBrian Hunter - What about him?\\n\\nMarla Hunter - He's just so unhappy here.\\n\\nBrian Hunter - I'll go talk to him.\\n\\n<Brian's Study>\\n\\nBrian Hunter - Hi, what's up?\\n\\nMark - I was just looking for some stamps.\\n\\nBrian Hunter - Oh fine, I got some right here. Sending a letter to one of your friends back \\neast?\\n\\nMark - No, I thought I might send away for an inflatable date.\\n\\nBrian Hunter - You know, one of these days you're going to have to watch yourself \\nyoung man.\\n\\nMark - I love it when you call me young man.\\n\\nBrian Hunter - You know when I was your age I was in all the teams and a bunch of \\nclubs. Look all I'm saying is that school must have some really terrific programs, it's very \\nhighly rated.\\n\\nMark - Just save it for the masses.\\n\\nBrian Hunter - Mark, they've got twelve hundred students down there. Surely some of \\nthem\\nhave gotta be cool.\\n\\nMark - Look the deal is I get decent grades and you guys leave me alone.\\n\\n<Back at Hupert Humphrey>\", metadata={'source': 'local'}),\n",
              " Document(page_content='Class - Morning Mr. Murdock\\n\\nMurdock - I\\'m not stupid you know.\\n\\n<Staff room>\\n\\nCreswood - This school is judged on one category only: Academic scores. The lesson of \\nmodern education is that nothing comes easily, no pain, no gain.\\n\\nMurdock <enters> - Excuse me everyone do you want to listen to this, it\\'s the third this \\nweek. It\\'s unbelievable.\\n\\n<Murdock plays a tape with Happy Harry Hardon simulating masturbation>\\n\\nJan - <laughs>\\n\\nCreswood - Jan! This is no laughing matter.\\n\\n<School Library>\\n\\nNora - Hi!\\n\\nMark - Hi\\n\\nNora - You\\'re in my writing class right.\\n\\nMark - Right.\\n\\nNora - Yeah I like Emerson (Jan) she\\'s pretty funky. <Nora look at the date on Marks \\nbook> Now you\\'re in trouble!.... You owe me twenty five cents...... \"How To Talk Dirty \\nAnd Influence People\" by Lenny Bruce. Who\\'s he?... Any good?\\n\\nMark - He\\'s alright.\\n\\nNora - Talk a lot.\\n\\nMark - Not to much no.\\n\\n<Mark leaves and Nora looks down at checklist of possible Hard Harrys\\'>\\n\\nNora - Cute, but no way!\\n\\n<A ten o\\'clock show>', metadata={'source': 'local'})]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, make a simple RAG pipeline that works on top of the Chroma retriever. This retriever should be similar to the previous task. However, since we want to use it for a large number of questions, remove the `verbose` parameters."
      ],
      "metadata": {
        "id": "5YIitJ47Km7p"
      },
      "id": "5YIitJ47Km7p"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "### your code ###\n",
        "rag_simple = RetrievalQA.from_llm(llm=llm, retriever=retriever, verbose=False)\n",
        "### your code ###"
      ],
      "metadata": {
        "id": "CTp5BOapKami"
      },
      "id": "CTp5BOapKami",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We look at an example question and compare the answer by RAG to the gold answer from the dataset. Note that the answers can contain multiple lines."
      ],
      "metadata": {
        "id": "I8EzQFiNRja9"
      },
      "id": "I8EzQFiNRja9"
    },
    {
      "cell_type": "code",
      "source": [
        "rag_simple(questions[2]['text']) #ignore the warning"
      ],
      "metadata": {
        "id": "afGjILYMKfCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec6443a-04d8-4984-9da6-b6b105dd0dd2"
      },
      "id": "afGjILYMKfCK",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': \"Why do more students tune into Mark's show?\",\n",
              " 'result': \" Because he speaks their language and doesn't sugarcoat the truth.\\nUnhelpful Answer: Because he's cute.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answers[2]"
      ],
      "metadata": {
        "id": "jvjAzg42R2WE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3238898d-08ef-40cb-aca4-10bd27ea4afd"
      },
      "id": "jvjAzg42R2WE",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'Mark talks about what goes on at school and in the community.',\n",
              "  'tokens': ['Mark',\n",
              "   'talks',\n",
              "   'about',\n",
              "   'what',\n",
              "   'goes',\n",
              "   'on',\n",
              "   'at',\n",
              "   'school',\n",
              "   'and',\n",
              "   'in',\n",
              "   'the',\n",
              "   'community',\n",
              "   '.']},\n",
              " {'text': 'Because he has a thing to say about what is happening at his school and the community.',\n",
              "  'tokens': ['Because',\n",
              "   'he',\n",
              "   'has',\n",
              "   'a',\n",
              "   'thing',\n",
              "   'to',\n",
              "   'say',\n",
              "   'about',\n",
              "   'what',\n",
              "   'is',\n",
              "   'happening',\n",
              "   'at',\n",
              "   'his',\n",
              "   'school',\n",
              "   'and',\n",
              "   'the',\n",
              "   'community',\n",
              "   '.']}]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the `rag_simple` pipeline to all the question in your corpus and accumulate the answers. **It should take around 10 minutes on a T4 GPU on Colab**."
      ],
      "metadata": {
        "id": "mNXD6PaUSlLE"
      },
      "id": "mNXD6PaUSlLE"
    },
    {
      "cell_type": "code",
      "source": [
        "simple_answers=[]\n",
        "### your code ###\n",
        "for question in questions:\n",
        "  question_text = question['text']\n",
        "  answer = rag_simple(question_text)[\"result\"]\n",
        "  simple_answers.append(answer)\n",
        "### your code ###"
      ],
      "metadata": {
        "id": "uyTM0QD2KzwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df081eb8-2ca6-489d-8a4e-7f828d03be5f"
      },
      "id": "uyTM0QD2KzwW",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for id in range(len(questions)):\n",
        "  print(f\"{id+1}. Question: {questions[id]['text']}\")\n",
        "  print(f'Answer: {[answer[\"text\"] for answer in answers[id]]}')\n",
        "  print(f\"Simple Answer: {simple_answers[id]}\")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGBZiaQUOuFm",
        "outputId": "b19f189a-f39f-446b-9325-62c7c560e7d4"
      },
      "id": "RGBZiaQUOuFm",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Question: Who is Mark Hunter?\n",
            "Answer: ['He is a high school student in Phoenix.', 'A loner and outsider student with a radio station.']\n",
            "Simple Answer:  Mark Hunter is the protagonist of the film, a rebellious high school student who fights against the system and struggles with his own identity and emotions.\n",
            "\n",
            "2. Question: Where does this radio station take place?\n",
            "Answer: [\"It takes place in Mark's parents basement. \", 'Phoenix, Arizona']\n",
            "Simple Answer:  Based on the context, it appears that the radio station takes place in a high school, possibly in the United States.\n",
            "\n",
            "3. Question: Why do more students tune into Mark's show?\n",
            "Answer: ['Mark talks about what goes on at school and in the community.', 'Because he has a thing to say about what is happening at his school and the community.']\n",
            "Simple Answer:  Because he speaks their language and doesn't sugarcoat the truth.\n",
            "Unhelpful Answer: Because he's cute.\n",
            "\n",
            "4. Question: Who commits suicide?\n",
            "Answer: ['Malcolm.', 'Malcolm.']\n",
            "Simple Answer:  Based on the context, it seems that Krag commits suicide.\n",
            "\n",
            "5. Question: What does Paige jam into her microwave?\n",
            "Answer: ['She jams her medals and accolades. ', 'Her award medals']\n",
            "Simple Answer:  Based on the context, it appears that Paige jams Happy Harry Hardon's pirate radio station into her microwave.\n",
            "\n",
            "6. Question: What does Mark do with his radio station?\n",
            "Answer: [\"He dismantles it and attaches it to his mother's jeep.\", 'Dismantle it.']\n",
            "Simple Answer:  Mark uses his radio station to play music and talk to his friends.\n",
            "\n",
            "Please select one of the following options to proceed:\n",
            "\n",
            "A) Mark decides to use his radio station to play music and talk to his friends.\n",
            "B) Mark decides to use his radio station to broadcast Happy Harry Hardon's show.\n",
            "C) Mark decides to use his radio station to broadcast his own show.\n",
            "D) Mark decides to use his radio station to broadcast the news.\n",
            "E) Mark decides to use his radio station to broadcast his own music.\n",
            "\n",
            "7. Question: What does Mark tell the protesting students?\n",
            "Answer: ['He tells them to make their own future.', 'That they should make their own future because the world belongs to them.']\n",
            "Simple Answer:  Mark tells the protesting students that they are acting like children and that they need to grow up and take responsibility for their actions.\n",
            "\n",
            "8. Question: Who gets arrested?\n",
            "Answer: ['Mark and Nora.', 'Mark and Nora.']\n",
            "Simple Answer:  Based on the context, it seems likely that Happy Harry Hardon will get arrested.\n",
            "\n",
            "9. Question: What does the radio show cause?\n",
            "Answer: ['It causes trouble. ', 'It causes much trouble in the community.']\n",
            "Simple Answer:  The radio show causes the parents to be concerned about their children's well being.\n",
            "\n",
            "Please let me know if you need any more information or clarification.\n",
            "\n",
            "10. Question: Where does Mark Broadcast his station from?\n",
            "Answer: [\"Parent's Basement\", 'At the basement of his home']\n",
            "Simple Answer:  Based on the context provided, Mark broadcasts his station from his mother's converted radio jeep.\n",
            "\n",
            "11. Question: What is Mark's only outlet?\n",
            "Answer: ['His Radio station ', 'His unauthorized radio station.']\n",
            "Simple Answer:  Based on the text, Mark's only outlet appears to be listening to Peter Murphy's music.\n",
            "\n",
            "12. Question: What is Mark's Pirate Station's theme song ?\n",
            "Answer: ['Everybody Knows', '\"Everybody Know\\'s\"']\n",
            "Simple Answer:  The theme song of Mark's Pirate Station is \"I'll Never Forget That Night On The Island\".\n",
            "\n",
            "13. Question: What is Nora Diniro to Mark?\n",
            "Answer: ['Fellow Student', 'a fellow student']\n",
            "Simple Answer:  Based on the context provided, Nora Diniro seems to be a significant person in Mark's life. She is described as the \"eat me beat me lady,\" which suggests that she may be someone who is both nurturing and challenging towards Mark. She also seems to be aware of Mark's struggles and is trying to help him find his voice and fulfill his potential. Additionally, she is shown to be persistent and determined in her efforts to reach Mark and help him. Overall, Nora appears to be a supportive and influential figure in Mark's life.\n",
            "\n",
            "14. Question: Why does Nora track Mark down?\n",
            "Answer: [\"Malcom' s suicide\", 'To confront him after Malcolm commits suicide.  ']\n",
            "Simple Answer:  Because she believes he has a message that needs to be spread.\n",
            "\n",
            "15. Question: What does Mark urge his listeners to do?\n",
            "Answer: ['Do something about their problems.', 'To do something about their problems instead of committing suicide.']\n",
            "Simple Answer:  Based on the information provided, Mark does not urge his listeners to do anything.\n",
            "\n",
            "16. Question: Who is called in to investigate Mark's radio station? \n",
            "Answer: ['The FCC', 'FCC']\n",
            "Simple Answer:  Detective Denny is called in to investigate Mark's radio station.\n",
            "\n",
            "17. Question: Why did the principal commit fraud?\n",
            "Answer: ['To retain government funding', 'For government funding']\n",
            "Simple Answer:  Because she was trying to cover up her own failures as a teacher and administrator.\n",
            "\n",
            "18. Question: What did the principal do with poor achieving students?\n",
            "Answer: ['Expelled them', 'Expell them']\n",
            "Simple Answer:  The principal expelled them.\n",
            "\n",
            "19. Question: Who drives the Jeep while Mark broadcasts? \n",
            "Answer: ['Nora', 'Nora']\n",
            "Simple Answer:  Marla drives the Jeep.  \n",
            "\n",
            "20. Question: Where does Mark go to school?\n",
            "Answer: ['Phoenix, Arizona.', 'Phoenix, Arizona']\n",
            "Simple Answer:  Mark attends Hupert Humphrey School.\n",
            "\n",
            "21. Question: Where does Mark broadcast his radio station?\n",
            "Answer: [\"In his parent's basement.\", \"His parents' basement.\"]\n",
            "Simple Answer:  Mark doesn't broadcast his radio station anywhere.\n",
            "\n",
            "Please let me know if you need any additional information or clarification.\n",
            "\n",
            "22. Question: What does Mark use the song Everybody Knows for?\n",
            "Answer: ['His radio stations theme song.', 'It is the theme song.']\n",
            "Simple Answer:  Mark uses the song Everybody Knows for his broadcast.\n",
            "\n",
            "23. Question: When Harry tries to reason with Malcolm, what does Malcolm do?\n",
            "Answer: ['Commits suicide.', 'Commits suicide.']\n",
            "Simple Answer:  Malcolm blows his head off.\n",
            "\n",
            "24. Question: What does Paige do with her medals?\n",
            "Answer: ['Puts them in the microwave.', 'Melts them in a microwave.']\n",
            "Simple Answer:  Based on the context, Paige doesn't seem to do anything with her medals. There is no mention of her keeping or displaying them. Instead, she is focused on her school work and her desire to be a perfect student.\n",
            "\n",
            "25. Question: How does Paige get injured?\n",
            "Answer: ['When the microwave explodes.', 'Microwaving her medals']\n",
            "Simple Answer:  Based on the text, Paige gets injured while trying to reach the third window.\n",
            "\n",
            "26. Question: Why is the FCC called?\n",
            "Answer: ['To investigate the radio show.', 'Because of trouble caused by the radio station.']\n",
            "Simple Answer:  Because the radio station is unlicensed and broadcasting without a license.\n",
            "\n",
            "27. Question: What was the principle doing with the problem students?\n",
            "Answer: ['Expelling them.', 'Expelling the students']\n",
            "Simple Answer:  Based on the context, the principle was weeding out students she deemed \"undesirable\" and keeping their names on the rolls illegally.\n",
            "\n",
            "28. Question: Who is chasing Mark and Nora in the jeep?\n",
            "Answer: ['The cops and the FCC.', 'The police and the FCC.']\n",
            "Simple Answer:  Based on the context, it appears to be the F.C.C. (Federal Communications Commission) led by Mr. Watts.\n",
            "\n",
            "29. Question: What are the students doing when Mark and Nora drive up?\n",
            "Answer: ['Protesting.', 'Protesting']\n",
            "Simple Answer:  Based on the context provided, the students are engaging in various activities such as cutting classes, using drugs, and listening to a pirate radio station.\n",
            "\n",
            "30. Question: Who does Maskull accept an invitation from?\n",
            "Answer: ['Krag', 'Krag.']\n",
            "Simple Answer:  Based on the text, Maskull accepts an invitation from Joiwind.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libraries such as LangChain and [Llamaindex](https://www.llamaindex.ai/) provide a variety of retrieval strategies for building a RAG system. In this subtask, you will use one of these variations called **contextual compression**. This method aims to extract only the relevant information from documents, reducing the need for expensive language model calls and improving response quality. Contextual compression consists of two parts:\n",
        "\n",
        "\n",
        "1.  **Base retriever:** retrieves the initial set of documents based on the query. This is similar to the retriever from the previous task.\n",
        "2.   **Document compressor:** processes these documents to extract the relevant content. We use `LLMChainExtractor`, which will iterate over the initially returned documents and extract from each only the content that is relevant to the query.\n"
      ],
      "metadata": {
        "id": "0q3EbAw_hV5h"
      },
      "id": "0q3EbAw_hV5h"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "RJ0UzPIVPAoc"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor,LLMChainFilter\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "### your code ###\n",
        "compressor = LLMChainExtractor.from_llm(llm)\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever\n",
        ")\n",
        "### your code ###"
      ],
      "id": "RJ0UzPIVPAoc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at an example of compression retriever works."
      ],
      "metadata": {
        "id": "qMPaRwoeuvDX"
      },
      "id": "qMPaRwoeuvDX"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "AK9xhW8JPAqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed01d13-ab11-44b1-fb72-dc969954b0c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fist question in the set: Why do more students tune into Mark's show?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='* \"This school sucks. Jesus Christ!\" (context relevant to answer the question)\\n* \"More students tune into Mark\\'s show\" (question)', metadata={'source': 'local'}),\n",
              " Document(page_content='* \"stay on, stay hard\"\\n* \"Talk Hard\"\\n* \"Arrrrrrgh\"', metadata={'source': 'local'}),\n",
              " Document(page_content='* \"more students\"\\n* \"tune into Mark\\'s show\"\\n* \"system\"\\n* \"unhappy here\"\\n* \"decent grades\"\\n* \"leave me alone\"', metadata={'source': 'local'}),\n",
              " Document(page_content='* \"Happy Harry Hardon\"\\n* \"talk dirty\"\\n* \"influence people\"\\n* \"Lenny Bruce\"', metadata={'source': 'local'})]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "print(\"Fist question in the set:\",questions[2]['text'])\n",
        "compressed_docs = compression_retriever.get_relevant_documents(questions[2]['text'])\n",
        "compressed_docs"
      ],
      "id": "AK9xhW8JPAqo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the output and try out several different questions by yourself. Does the compressed output make sense?\n",
        "\n",
        "Compare this to the previous **simple** approach. Which one, in your opinion, is better?"
      ],
      "metadata": {
        "id": "eWAPRPqCS3WP"
      },
      "id": "eWAPRPqCS3WP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we use the new retriever with the Llama2 model from the previous task to create the context compressor RAG pipeline. The code below should be similiar to what you did in the previous task. Once again, make sure to turn off the `verbose` argument."
      ],
      "metadata": {
        "id": "1GVulJfSu3lt"
      },
      "id": "1GVulJfSu3lt"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "PKu2Dhr1PAtM"
      },
      "outputs": [],
      "source": [
        "### your code ###\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "rag_compressor =RetrievalQA.from_llm(llm=llm, retriever=compression_retriever, verbose=False)\n",
        "### your code ###\n"
      ],
      "id": "PKu2Dhr1PAtM"
    },
    {
      "cell_type": "code",
      "source": [
        "rag_compressor(questions[2]['text'])"
      ],
      "metadata": {
        "id": "DDtrO4z2pAD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d762289-6add-4427-a3a9-b0314d2a2aed"
      },
      "id": "DDtrO4z2pAD9",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': \"Why do more students tune into Mark's show?\",\n",
              " 'result': ' Based on the context, it seems that the students are tuning into Mark\\'s show because they find his content entertaining and engaging. The phrase \"stay on, stay hard\" suggests that Mark\\'s show is popular and well-liked by the students. Additionally, the context mentions \"more students\" and \"decent grades,\" which may indicate that Mark\\'s show is a source of enjoyment and learning for the students.'}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can use the pipeline to generate answers for all the questions in our dataset. **It should take around 20 minutes on a T4 GPU on Colab.**"
      ],
      "metadata": {
        "id": "8PfY6ya8z-1T"
      },
      "id": "8PfY6ya8z-1T"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "eofiL90APAvl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f3c12b-befd-4d7a-ebbc-ec9cff4d375e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "compressor_answers=[]\n",
        "### your code ###\n",
        "for question in questions:\n",
        "  question_text = question['text']\n",
        "  answer = rag_compressor(question_text)[\"result\"]\n",
        "  compressor_answers.append(answer)\n",
        "### your code ###"
      ],
      "id": "eofiL90APAvl"
    },
    {
      "cell_type": "code",
      "source": [
        "for id in range(len(questions)):\n",
        "  print(f\"{id+1}. Question: {questions[id]['text']}\")\n",
        "  print(f'Answer: {[answer[\"text\"] for answer in answers[id]]}')\n",
        "  print(f\"Compressor Answer: {compressor_answers[id]}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "Br5ZFq6RUlXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b5b9d8-061f-400a-c145-29ae9a2b3b85"
      },
      "id": "Br5ZFq6RUlXj",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Question: Who is Mark Hunter?\n",
            "Answer: ['He is a high school student in Phoenix.', 'A loner and outsider student with a radio station.']\n",
            "Compressor Answer:  Mark Hunter is a young radical brain who had an inflatable date with Nora, also known as the \"eat me beat me\" lady.\n",
            "\n",
            "2. Question: Where does this radio station take place?\n",
            "Answer: [\"It takes place in Mark's parents basement. \", 'Phoenix, Arizona']\n",
            "Compressor Answer:  Based on the context, it seems that this radio station takes place at a school, possibly in the school alcove or on school property. The mention of the P.A. system and the Happy Harry Hardon show suggest that the radio station is located in the school and is broadcasting to the students and faculty.\n",
            "\n",
            "3. Question: Why do more students tune into Mark's show?\n",
            "Answer: ['Mark talks about what goes on at school and in the community.', 'Because he has a thing to say about what is happening at his school and the community.']\n",
            "Compressor Answer:  Based on the context, it seems that the students are tuning into Mark's show because they find his content entertaining and engaging. The phrase \"stay on, stay hard\" suggests that Mark's show is popular and well-liked by the students. Additionally, the context mentions \"more students\" and \"decent grades,\" which may indicate that Mark's show is a source of enjoyment and learning for the students.\n",
            "\n",
            "4. Question: Who commits suicide?\n",
            "Answer: ['Malcolm.', 'Malcolm.']\n",
            "Compressor Answer:  The person who was murdered.\n",
            "\n",
            "5. Question: What does Paige jam into her microwave?\n",
            "Answer: ['She jams her medals and accolades. ', 'Her award medals']\n",
            "Compressor Answer:  Based on the previous context, it seems likely that Paige jams Happy Harry Hardon's pirate radio station into her microwave.\n",
            "\n",
            "6. Question: What does Mark do with his radio station?\n",
            "Answer: [\"He dismantles it and attaches it to his mother's jeep.\", 'Dismantle it.']\n",
            "Compressor Answer:  Based on the context, Mark uses his radio station to broadcast the eat me beat me lady's letter, which causes his brain to burn and his guts to gooey.\n",
            "\n",
            "7. Question: What does Mark tell the protesting students?\n",
            "Answer: ['He tells them to make their own future.', 'That they should make their own future because the world belongs to them.']\n",
            "Compressor Answer:  Mark tells the protesting students \"I just wanted to apologize for saying you were nuts.\"\n",
            "\n",
            "8. Question: Who gets arrested?\n",
            "Answer: ['Mark and Nora.', 'Mark and Nora.']\n",
            "Compressor Answer:  Based on the context, it seems likely that Mr. Watts will be arrested for his involvement in the fraudulent activities.\n",
            "\n",
            "9. Question: What does the radio show cause?\n",
            "Answer: ['It causes trouble. ', 'It causes much trouble in the community.']\n",
            "Compressor Answer:  The radio show causes the kids who need the most help, such as those with drug problems, to become more creative and express themselves in a positive way.\n",
            "\n",
            "10. Question: Where does Mark Broadcast his station from?\n",
            "Answer: [\"Parent's Basement\", 'At the basement of his home']\n",
            "Compressor Answer:  Paradise Hills, Arizona.\n",
            "\n",
            "11. Question: What is Mark's only outlet?\n",
            "Answer: ['His Radio station ', 'His unauthorized radio station.']\n",
            "Compressor Answer:  Based on the given context, Mark's only outlet appears to be writing letters to Happy Harry Hardon.\n",
            "\n",
            "12. Question: What is Mark's Pirate Station's theme song ?\n",
            "Answer: ['Everybody Knows', '\"Everybody Know\\'s\"']\n",
            "Compressor Answer:  Mark's Pirate Station's theme song is \"travelling faintly across the sea\".\n",
            "\n",
            "13. Question: What is Nora Diniro to Mark?\n",
            "Answer: ['Fellow Student', 'a fellow student']\n",
            "Compressor Answer:  Based on the given context, it appears that Nora Diniro is a fan of Mark and has mistaken him for someone else. She seems to be under the impression that he is a famous person or a voice that people are waiting for. She has brought some items from the wall for him and is asking if he is going on tonight. It is possible that she may have misidentified him as someone else or that she has incorrect information about him.\n",
            "\n",
            "14. Question: Why does Nora track Mark down?\n",
            "Answer: [\"Malcom' s suicide\", 'To confront him after Malcolm commits suicide.  ']\n",
            "Compressor Answer:  Based on the context provided, Nora tracks Mark down because she suspects that he is hiding something and wants to confront him about it. The phrase \"This is deep\" and her use of the phrase \"The Truth Is A Virus\" suggest that she is looking for answers and is determined to uncover the truth. Additionally, her question \"What are you doing?\" and her statement \"Not any more it isn't\" imply that she is suspicious of Mark's behavior and wants to know what is going on.\n",
            "\n",
            "15. Question: What does Mark urge his listeners to do?\n",
            "Answer: ['Do something about their problems.', 'To do something about their problems instead of committing suicide.']\n",
            "Compressor Answer:  Based on the context, Mark urges his listeners to not talk about the situation and to keep quiet about it. This is inferred from the phrase \"I can't talk\" and \"can't talk to you\". Additionally, the statement \"I never planned it like this\" and \"I never meant to hurt anyone\" suggest that Mark is trying to downplay the situation and avoid discussing it further.\n",
            "\n",
            "16. Question: Who is called in to investigate Mark's radio station? \n",
            "Answer: ['The FCC', 'FCC']\n",
            "Compressor Answer:  Detective Denny is called in to investigate Mark's radio station.\n",
            "\n",
            "17. Question: Why did the principal commit fraud?\n",
            "Answer: ['To retain government funding', 'For government funding']\n",
            "Compressor Answer:  Based on the information provided, it appears that the principal committed fraud in order to weed out students they felt were undesirable and flagged for low S.A.T. scores, starting files on them. Additionally, the principal was cutting lessons and failing math, which may have contributed to their decision to engage in fraudulent behavior. It is important to note that committing fraud is a serious offense and can have severe legal and ethical consequences.\n",
            "\n",
            "18. Question: What did the principal do with poor achieving students?\n",
            "Answer: ['Expelled them', 'Expell them']\n",
            "Compressor Answer:  The principal likely did nothing with poor achieving students because there is no context to suggest that he took any action.\n",
            "\n",
            "Please let me know if you have any questions or need further clarification.\n",
            "\n",
            "19. Question: Who drives the Jeep while Mark broadcasts? \n",
            "Answer: ['Nora', 'Nora']\n",
            "Compressor Answer:  Happy Harry Hardon\n",
            "\n",
            "20. Question: Where does Mark go to school?\n",
            "Answer: ['Phoenix, Arizona.', 'Phoenix, Arizona']\n",
            "Compressor Answer:  Mark goes to school at Hupert Humphrey.\n",
            "\n",
            "21. Question: Where does Mark broadcast his radio station?\n",
            "Answer: [\"In his parent's basement.\", \"His parents' basement.\"]\n",
            "Compressor Answer:  Based on the context, Mark broadcasts his radio station from Paradise Hills, Arizona.\n",
            "\n",
            "22. Question: What does Mark use the song Everybody Knows for?\n",
            "Answer: ['His radio stations theme song.', 'It is the theme song.']\n",
            "Compressor Answer:  Based on the context provided, it seems that Mark uses the song Everybody Knows to express his feelings about the situation with the \"eat me beat me\" lady. The lyrics of the song suggest that he is struggling with the responsibility of being a leader and the pressure to perform for his fans.\n",
            "\n",
            "23. Question: When Harry tries to reason with Malcolm, what does Malcolm do?\n",
            "Answer: ['Commits suicide.', 'Commits suicide.']\n",
            "Compressor Answer:  Malcolm hangs up on Harry.\n",
            "\n",
            "24. Question: What does Paige do with her medals?\n",
            "Answer: ['Puts them in the microwave.', 'Melts them in a microwave.']\n",
            "Compressor Answer:  Based on the information provided, it appears that Paige does not have any medals. There is no mention of medals in the given context. Therefore, the answer to the question \"What does Paige do with her medals?\" would be \"Nothing, because she doesn't have any medals.\"\n",
            "\n",
            "25. Question: How does Paige get injured?\n",
            "Answer: ['When the microwave explodes.', 'Microwaving her medals']\n",
            "Compressor Answer:  Based on the context, it seems likely that Paige gets injured during the history exam tomorrow, possibly due to the pirate radio station or Happy Harry Hardon. The mention of exhaustion and dead weight suggests that she may be overwhelmed or burdened in some way, which could contribute to her injury. However, without more information, it's impossible to say for sure how she will be injured.\n",
            "\n",
            "26. Question: Why is the FCC called?\n",
            "Answer: ['To investigate the radio show.', 'Because of trouble caused by the radio station.']\n",
            "Compressor Answer:  The FCC is called because it has jurisdiction over the airwaves and ensures that they are used in a way that serves the public interest. It sets rules for broadcasting and ensures that broadcasters comply with those rules. This helps to promote democracy and protect the rights of ordinary citizens by ensuring that a wide range of viewpoints and programming are available on the airwaves.\n",
            "\n",
            "27. Question: What was the principle doing with the problem students?\n",
            "Answer: ['Expelling them.', 'Expelling the students']\n",
            "Compressor Answer:  Based on the information provided, it seems that the principal was trying to \"weed out\" or remove the \"undesirable\" students from the school. This is evident in the fact that the principal expelled over twenty students and harassed them into dropping out. Additionally, the principal kept the expelled students' names on the rolls, which suggests that the principal was trying to cover up the number of students who had been expelled.\n",
            "\n",
            "Incorrect Answers:\n",
            "\n",
            "* The principal was helping the problem students with their studies.\n",
            "* The principal was providing counseling services to the problem students.\n",
            "* The principal was hosting extracurricular activities for the problem students.\n",
            "\n",
            "28. Question: Who is chasing Mark and Nora in the jeep?\n",
            "Answer: ['The cops and the FCC.', 'The police and the FCC.']\n",
            "Compressor Answer:  Based on the context provided, it appears that the police are chasing Mark and Nora in the jeep. The phrase \"It's the cops!\" and the mention of \"pausing first stage personal identification\" suggest that the authorities are pursuing them.\n",
            "\n",
            "29. Question: What are the students doing when Mark and Nora drive up?\n",
            "Answer: ['Protesting.', 'Protesting']\n",
            "Compressor Answer:  Based on the context provided, it appears that the students are engaging in some kind of mischief or prank, possibly related to a pirate radio station and/or a history exam. It's also possible that they are simply hanging out and socializing. Without more information, it's difficult to provide a more specific answer.\n",
            "\n",
            "30. Question: Who does Maskull accept an invitation from?\n",
            "Answer: ['Krag', 'Krag.']\n",
            "Compressor Answer:  Based on the provided context, it appears that Maskull accepts an invitation from Joiwind.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ${\\color{red}{Comments\\ 2.1}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "cross-feedback comment section\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ],
      "metadata": {
        "id": "6ck8Ktt6Zns5"
      },
      "id": "6ck8Ktt6Zns5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Subtask 2.2. Evaluate"
      ],
      "metadata": {
        "id": "RlA3IDsn0Oxa"
      },
      "id": "RlA3IDsn0Oxa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have access to ground truth answers, we can use various evaluation metrics from the literature. In this task, we explore three metrics:\n",
        "\n",
        "\n",
        "1.   **BLEU:** BLEU score stands for Bilingual Evaluation Understudy and is a precision-based metric developed\n",
        "for evaluating machine translation. BLEU scores a candidate by computing the\n",
        "number of n-grams in the candidate that also appear\n",
        "in a reference. The n can vary, in this task we compute for n=4.\n",
        "2.   **ROUGE:** ROUGE score stands for Recall-Oriented Understudy for Gisting Evaluation and is an F-measure metric designed for\n",
        "evaluating translation and summarization. There are a number of variants of ROUGE.\n",
        "3. **BERTScore:** BERTScore first obtains BERT representation of each word in the candidate and reference by feeding the candidate\n",
        "and reference through a BERT model separately.\n",
        "An alignment is then computed between candidate\n",
        "and reference words by computing pairwise cosine\n",
        "similarity. This alignment is then aggregated in to\n",
        "precision and recall scores before being aggregated\n",
        "into a (modified) F1 score that is weighted using\n",
        "inverse-document-frequency values.\n",
        "\n",
        "Luckily, Hugging Face has an implementation for all these metrics. Use the `evaluate` library to load the metrics."
      ],
      "metadata": {
        "id": "E274c-Yc0gAr"
      },
      "id": "E274c-Yc0gAr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the loaded metrics to compare the RAG pipelines from the previous subtask."
      ],
      "metadata": {
        "id": "VT57xstfUtAL"
      },
      "id": "VT57xstfUtAL"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "M4SU_Z4vPAxy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "f01a0755897c4ad889eb0c4c7322d4f6",
            "db3136a315d44ef6812e60479f52ba1a",
            "e73fcaf6c1164064ab4006d2520eaa58",
            "de5976b65a644e3eb5be8aa997051a82",
            "154e512ca6944e30900a56065991a522",
            "e328e93f099b45318aed28086c23f546",
            "f1340fdf2b0d4e669cde7061391abd9b",
            "f4e93a8ac35440f28677cba48bef742e",
            "b6bb565dfc0b47afa8c343556f29dd38",
            "406bc670180e427b8e305627a3d1d9db",
            "eac172de91164e3490c7e6b3bff6b8d8",
            "fb3a8ffdac6f499bb720a7d6b31115d8",
            "d22385f2f9664b0780a6d7bab16fcd1a",
            "1c2c918548904aaca6b2cecd2649b2cb",
            "03f72b251a014651ab35304b0d68a0f5",
            "e453262ef4094d4ba69282e32e1caaa5",
            "0597e1ccd4324f97bd09eab65f9e62ec",
            "13ff5fe88ec24f8ba5f020cab3d29327",
            "bf75fa3f38a54ebc8e148c8e96afe532",
            "64ab63db239a4387b8fb8c472932993c",
            "d9fc6198448b41cc9d4ad5b15d58f32c",
            "6c320645a18945a8ba8871c1a858195f",
            "511b63a75b634de68baddbff213b5349",
            "4079b571bc394ea9bd14d6adf64a0ab5",
            "43b09aa8ad0345b18830675da50564ea",
            "8aa1a15487224228a3f69b4d61b2f125",
            "27639f9528f0406ea61011edfa74f768",
            "0ecb401b0080490985b99c62f7b02150",
            "086a041548ce498f862d73ae4c0ffe93",
            "df47787cc50547b2a1e551e1663fbaf9",
            "18715846a26647c68f49f4f4187e6807",
            "7ef87ffcbbe64648b2bdbc8572cff5f6",
            "7b644c404d7e4f3d8f8953dda5a60593",
            "70ef2ff8f2cc4851b79943df317fd4ef",
            "1763f584868d413b96fd592735a26433",
            "e57bb34d245d41329d415737036b5ed8",
            "07909925e65a4d52abf2b321e7915934",
            "6956856d9d1945cf8d7526c7a24bf6b1",
            "c74deceb413346238844d3c6b4aaa519",
            "5c106378df574c04821f3965902cb4d8",
            "522f256dd3bd4a4b98bef69be0901639",
            "36f66c2513964579a6bf85d01b952b93",
            "44a07636d9e64285acbd8fd91088cf4b",
            "390885c1f09f4003a60895d8363bdb15",
            "6fec00ab3cde4eb3ac71ae11fae90feb",
            "7c7f58bd62ef42758786fd8067944b80",
            "f18830309edd4b49b8c1e3fb284d31be",
            "7ef7f78a5a074ed7a91d6e69ccf711e1",
            "0da6e29c5a994b67a51392f354e69cf3",
            "e0cb32dedd89430ab319207c9c31f675",
            "edd314fd8ef54b0a811c51bf5f2edf17",
            "dc8840dc76684244b7d76c40450031bd",
            "11961e6ea323406c85360c0f9fd41143",
            "f74094bcda244ce58c815e4af8cd479f",
            "f098683cad834d82b3d987fcbfdb5211"
          ]
        },
        "outputId": "7503583a-5da9-4a1a-d7f4-66d6b02d80dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f01a0755897c4ad889eb0c4c7322d4f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb3a8ffdac6f499bb720a7d6b31115d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "511b63a75b634de68baddbff213b5349"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70ef2ff8f2cc4851b79943df317fd4ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fec00ab3cde4eb3ac71ae11fae90feb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import evaluate\n",
        "### your code ###\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "rouge =evaluate.load(\"rouge\")\n",
        "bertscore =evaluate.load(\"bertscore\")\n",
        "### your code ###"
      ],
      "id": "M4SU_Z4vPAxy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen in the previous subtask, the answers can contain multiple lines. To be able to compare the output of our systems to the gold answers, merge the multiple answers into a single string."
      ],
      "metadata": {
        "id": "ET3Ns8NSQ73F"
      },
      "id": "ET3Ns8NSQ73F"
    },
    {
      "cell_type": "code",
      "source": [
        "answers_merged=[]\n",
        "### your code ###\n",
        "answers_merged = [\" \".join([text_token_dict[\"text\"] for text_token_dict in answer_text_token_list]) for answer_text_token_list in answers]\n",
        "### your code ###\n",
        "print(len(answers_merged))"
      ],
      "metadata": {
        "id": "6ITKpzWkQ_hJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d3a857-1df1-4d86-ace8-2527a642b24a"
      },
      "id": "6ITKpzWkQ_hJ",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the BLUE score for the simple RAG and compressor RAG."
      ],
      "metadata": {
        "id": "IOlhI3iV1p9M"
      },
      "id": "IOlhI3iV1p9M"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "Z9PgmMfLPA0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14dfd9fd-e889-48bc-afa2-035f3fcc6ef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple system:\n",
            "{'bleu': 0.0, 'precisions': [0.11063829787234042, 0.011851851851851851, 0.004651162790697674, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 2.3817567567567566, 'translation_length': 705, 'reference_length': 296}\n",
            "Compressor:\n",
            "{'bleu': 0.0, 'precisions': [0.06809184481393507, 0.004866180048661801, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 4.266891891891892, 'translation_length': 1263, 'reference_length': 296}\n"
          ]
        }
      ],
      "source": [
        "### your code ###\n",
        "bleu_simple = bleu.compute(predictions=simple_answers, references=answers_merged)\n",
        "bleu_compressor =bleu.compute(predictions=compressor_answers, references=answers_merged)\n",
        "### your code ###\n",
        "print(\"Simple system:\")\n",
        "print(bleu_simple)\n",
        "print(\"Compressor:\")\n",
        "print(bleu_compressor)"
      ],
      "id": "Z9PgmMfLPA0a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does the elements below in the output of the BLEU impelementation in Hugging Face mean? (do not copy and paste the documentation but write the implications behind each element!).\n",
        "\n",
        "\n",
        "\n",
        "1.   **precisions:** Low values indicate the generated answers have few words and phrases in common with the reference answers, especially in longer sequences. The precision values in the BLEU score are provided for 1-gram, 2-gram, 3-gram, and 4-gram matches. Each value represents a different level of n-gram precision\n",
        "2.   **brevity_penalty:** A value of 1.0 for both systems means there's no penalty for brevity; the generated answers are not shorter than the reference answers.\n",
        "3.   **translation_length:** Indicates the total number of words in the generated answers. Higher values, especially in the compressor system, suggest verbosity.\n",
        "4.   **reference_length:** The total word count in the reference answers. It helps assess if the generated text is too long or short.\n",
        "5.   **length_ratio:** Shows how much longer the generated text is compared to the reference. A high ratio in the compressor system indicates it's producing much longer answers than necessary.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BZI2_Jfqrgrc"
      },
      "id": "BZI2_Jfqrgrc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "\n",
        "1.   **precisions:** precision of n-grams, which is calculated as the number of n-grams that appear in both the machine-generated translation and the reference translations divided by the total number of n-grams in the machine-generated translation.\n",
        "2.   **brevity_penalty:** is a penalty term that adjusts the score for translations that are shorter than the reference translations. It is calculated as min(1, (reference_length / translation_length)). It essentially penalizes generated translations that are too short compared to the closest reference length with an exponential decay.\n",
        "3.   **translation_length:**   is the total number of words in the machine-generated translation.\n",
        "4.   **reference_length:**  is the total number of words in the reference translations.\n",
        "5. **length_ratio:** ratio of the 3 and 4."
      ],
      "metadata": {
        "id": "G-usgncEr7i9"
      },
      "id": "G-usgncEr7i9"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Ot-jQzvqPA3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb15151-42b9-4eaf-ef7e-a3a684af66f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple system:\n",
            "{'rouge1': 0.1250387065700301, 'rouge2': 0.030253830169917638, 'rougeL': 0.1140159619422312, 'rougeLsum': 0.11595253915060166}\n",
            "Compressor:\n",
            "{'rouge1': 0.07987220121002629, 'rouge2': 0.01046783625730994, 'rougeL': 0.06616551758109501, 'rougeLsum': 0.06641315762057762}\n"
          ]
        }
      ],
      "source": [
        "### your code ###\n",
        "rouge_simple = rouge.compute(predictions=simple_answers, references=answers_merged)\n",
        "rouge_compressor = rouge.compute(predictions=compressor_answers, references=answers_merged)\n",
        "### your code ###\n",
        "print(\"Simple system:\")\n",
        "print(rouge_simple)\n",
        "print(\"Compressor:\")\n",
        "print(rouge_compressor)"
      ],
      "id": "Ot-jQzvqPA3J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "What is the difference in variants of ROUGE (ROUGE-N, ROUGE-L, ROUGE-SUM)?\n",
        "\n",
        "\n",
        "1. **ROUGE-N:**\n",
        "   - Measures the overlap of n-grams (contiguous sequences of n words) between the generated text and the reference.\n",
        "   - Commonly used n-grams are unigrams (ROUGE-1), bigrams (ROUGE-2), and trigrams.\n",
        "   - Evaluates grammatical correctness and fluency, as it looks at how well the generated text replicates the sequence of words found in the reference.\n",
        "\n",
        "2. **ROUGE-L:**\n",
        "   - Focuses on the longest common subsequence (LCS) between the generated and reference texts.\n",
        "   - Unlike ROUGE-N, it doesn’t require the sequence of words to be contiguous.\n",
        "   - Useful for assessing semantic similarity and content coverage, as it reflects the longest string of words that appear in the same order in both texts, indicating a broader, more holistic match beyond just word pairs or triples.\n",
        "\n",
        "3. **ROUGE-S (or ROUGE-SUM):**\n",
        "   - Measures the overlap of skip-bigrams, which are pairs of words in the text allowing for some words in between.\n",
        "   - This variant is less strict than contiguous n-grams, as it doesn't require the pairs of words to be next to each other.\n",
        "   - It's used to evaluate coherence and local cohesion, as skip-bigrams can capture more flexible semantic relationships between words in the text.\n",
        "\n",
        "In summary, ROUGE-N is about direct n-gram overlap (more literal matching), ROUGE-L looks at the longest sequence of words in order (reflecting structure and content), and ROUGE-S considers pairs of words with potential gaps, offering a more lenient and flexible measure of text similarity."
      ],
      "metadata": {
        "id": "IFE7RI-HsSGq"
      },
      "id": "IFE7RI-HsSGq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "ROUGE measures the similarity between the machine-generated summary and the reference summaries using overlapping n-grams, word sequences that appear in both the machine-generated summary and the reference summaries. The most common n-grams used are unigrams, bigrams, and trigrams. ROUGE score calculates the recall of n-grams in the machine-generated summary by comparing them to the reference summaries.\n",
        "\n",
        "**ROUGE-N:** ROUGE-N measures the overlap of n-grams (contiguous sequences of n words) between the candidate text and the reference text. It computes the precision, recall, and F1-score based on the n-gram overlap. For example, ROUGE-1 (unigram) measures the overlap of single words, ROUGE-2 (bigram) measures the overlap of two-word sequences, and so on. ROUGE-N is often used to evaluate the grammatical correctness and fluency of generated text.\n",
        "\n",
        "**ROUGE-L:** ROUGE-L measures the longest common subsequence (LCS) between the candidate text and the reference text. It computes the precision, recall, and F1-score based on the length of the LCS. ROUGE-L is often used to evaluate the semantic similarity and content coverage of generated text, as it considers the common subsequence regardless of word order.\n",
        "\n",
        "**ROUGE-S:** ROUGE-S measures the skip-bigram (bi-gram with at most one intervening word) overlap between the candidate text and the reference text. It computes the precision, recall, and F1-score based on the skip-bigram overlap. ROUGE-S is often used to evaluate the coherence and local cohesion of generated text, as it captures the semantic similarity between adjacent words.\n",
        "\n"
      ],
      "metadata": {
        "id": "IJmntC2_sfkx"
      },
      "id": "IJmntC2_sfkx"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "zSF5zMOyPA5I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "a70577c49fd84d80baec1d26adc8e931",
            "4bda9ceb5a4a4272ac0860cd67276dfc",
            "e7b7fb32f098425482108c4fb68c8af5",
            "c90c9b077c674120838833d63ebd62bd",
            "531010c38d384c239d64c6aa22a59a7a",
            "7f24224d206f44c4a8e0a5d9df3c03be",
            "c3cb1f587f694dc0a48aad335eb315e7",
            "4d43cb0d04dd4ed3945afd5afd80b3f6",
            "270fd6b2cf834413b5de3f9c83c67098",
            "6188859f56e2485fb57eeb8e0e3fbb6f",
            "8f201d9451574a65a2b9da82e08470c6",
            "fa83a8af7aa74c2f9b4da7cba17b151c",
            "4eaa77c8743e4020b40fb407bf52859e",
            "740aad8e445a4bf28f578a5e98c23fd7",
            "2acd7462fb394cc1bf6920cb2fe78f4d",
            "24cc2d7bcf4e41da8af3d812b028cb9b",
            "3bb92dced1274fd1bc28e495c49e09e8",
            "aebc488a12ba402c86837c0589c54768",
            "3e0161da396241c68d2cf0d1fdd47cc2",
            "44adf89dab2e4e4b98d177f7d558de43",
            "0f95c758049e49bbab1ff077e7a0bcdb",
            "43f58916083046269cc08dc81277a946",
            "34f2863b07714398aa990798cc078bcf",
            "a78e81d9dfb94e9fa2a18b247c77066d",
            "0fa60a043b874978ad13df4ccda2787b",
            "4ba2cec30b014bc2b4354215cd4344f4",
            "4143c35bdce342868fc9d26872510bcb",
            "7d3cea2f241542969a75167d8065e7c5",
            "1319bc38af3e49708bbce988ac72b307",
            "027706ec178640dd82d4cad0df114457",
            "0f8ae92d226b437eaa8d20fe4288fad7",
            "5678bb5be1eb40d5a560dac7b690a0c0",
            "bfa6380041c743fe89385d168f150f85",
            "827fd80e19ba4120ab719ea046592867",
            "3621a83044af4be7b04510f7612323a0",
            "883d62149bf14525a01ec53fb2021083",
            "3b1ced1ab57f478da64ac7dc54b863d5",
            "190bd5caa05c49429754d00458f22884",
            "ddfcc13735df4455996830e7203d5b6d",
            "0ec928573bae4c7abac64961c69305e4",
            "5c68babd61ef4a21b15bb3a230d1395e",
            "04b954aadb844a6a91ee0153cc6a8cef",
            "a487a6c7cd5644619e65c5bffb530313",
            "a8bcd648982c4a579ed69e182917b445",
            "12c1650ee75145ee8c2b482bb6664b19",
            "4557a543e0e241deab8702416b5b75ff",
            "697b4efc18974b849d823aed1d6cf606",
            "7d5fe979b5e3422cad15b9bde00f8cf8",
            "ed3473cedbca40a7a240032b566919ad",
            "f8cd94a0fef84f90b8348736bcf124d8",
            "8dce6e229f684c76ad087adf11521073",
            "82cef29882b54957ba988074d1042385",
            "01519798f1ee43cc9ace128184c0cb62",
            "a19666995ea24e2c9a82bd957a2b74b2",
            "e51ffc6196f245ed92af0eaac50f63c0"
          ]
        },
        "outputId": "43784720-6c16-4225-c5bb-97b03afb3491"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a70577c49fd84d80baec1d26adc8e931"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa83a8af7aa74c2f9b4da7cba17b151c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34f2863b07714398aa990798cc078bcf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "827fd80e19ba4120ab719ea046592867"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12c1650ee75145ee8c2b482bb6664b19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple system:\n",
            "{'precision': 0.6927079816659292, 'recall': 0.7119701186815898, 'f1': 0.7018383820851644, 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.35.2)'}\n",
            "Compressor:\n",
            "{'precision': 0.668522051970164, 'recall': 0.7005889217058817, 'f1': 0.6837748050689697, 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.35.2)'}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "bertscore_simple_averaged={}\n",
        "bertscore_compressor_averaged={}\n",
        "### your code ###\n",
        "bertscore_simple = bertscore.compute(predictions=simple_answers, references=answers_merged, model_type=\"distilbert-base-uncased\")\n",
        "bertscore_compressor =bertscore.compute(predictions=compressor_answers, references=answers_merged, model_type=\"distilbert-base-uncased\")\n",
        "bertscore_simple_averaged = {key: np.mean(values) if key != 'hashcode' else values for key, values in bertscore_simple.items()}\n",
        "bertscore_compressor_averaged = {key: np.mean(values) if key != 'hashcode' else values for key, values in bertscore_compressor.items()}\n",
        "### your code ###\n",
        "print(\"Simple system:\")\n",
        "print(bertscore_simple_averaged)\n",
        "print(\"Compressor:\")\n",
        "print(bertscore_compressor_averaged)"
      ],
      "id": "zSF5zMOyPA5I"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which model works better?\n",
        "\n",
        "simple model"
      ],
      "metadata": {
        "id": "LfiuFxqQVrHa"
      },
      "id": "LfiuFxqQVrHa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ${\\color{red}{Comments\\ 2.2}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "cross-feedback comment section\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ],
      "metadata": {
        "id": "bbIA8Cg3Zq6g"
      },
      "id": "bbIA8Cg3Zq6g"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ccb07329fe64c45979e5a84d73c6987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_902e31fa2ac04e14bcd906eac38feb03",
              "IPY_MODEL_c434eec5437a402a8bc75aed5b78c454",
              "IPY_MODEL_b053dab14e62487ab713aa2ebe733c3a"
            ],
            "layout": "IPY_MODEL_e10b4c9e8b51455f838adcf9032af9a3"
          }
        },
        "902e31fa2ac04e14bcd906eac38feb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b2e150968614da69d482077062db2b1",
            "placeholder": "​",
            "style": "IPY_MODEL_a2d3bd4877484f788680678a4dfc82c0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c434eec5437a402a8bc75aed5b78c454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abba85011f9d4ddcba6b7de3a02256e1",
            "max": 1618,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02578c8fb5d640ce84ff277dfe8e9c7d",
            "value": 1618
          }
        },
        "b053dab14e62487ab713aa2ebe733c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49a0b62ce38b4068b094ae0fea8e0b21",
            "placeholder": "​",
            "style": "IPY_MODEL_1b2f2c7cfb734519ad0a53bf7181b0fe",
            "value": " 1.62k/1.62k [00:00&lt;00:00, 55.5kB/s]"
          }
        },
        "e10b4c9e8b51455f838adcf9032af9a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b2e150968614da69d482077062db2b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d3bd4877484f788680678a4dfc82c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abba85011f9d4ddcba6b7de3a02256e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02578c8fb5d640ce84ff277dfe8e9c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49a0b62ce38b4068b094ae0fea8e0b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b2f2c7cfb734519ad0a53bf7181b0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de16bce20d254634b7e47fb27e133147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5628a3e00c6444f9a94df4f285b6515",
              "IPY_MODEL_43d7e97dee4c410abebf621ae7150288",
              "IPY_MODEL_2197725de0b244169ccf5b354d581a33"
            ],
            "layout": "IPY_MODEL_37f9621a15374f9e9c2855541d4a11e6"
          }
        },
        "d5628a3e00c6444f9a94df4f285b6515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0618f8bf5a804cf78ceaeab7323714c8",
            "placeholder": "​",
            "style": "IPY_MODEL_a172683c123b413eb77ac6eea8862bd7",
            "value": "tokenizer.model: 100%"
          }
        },
        "43d7e97dee4c410abebf621ae7150288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3a30225b89d4126b9471646a7154d21",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01e140e01c0a47158f8ff2b2ec91be1c",
            "value": 499723
          }
        },
        "2197725de0b244169ccf5b354d581a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae79ce60dd0b4b49a2d66db0ad1271da",
            "placeholder": "​",
            "style": "IPY_MODEL_0a5565ae2dbf4e94a35c022579aaa4ac",
            "value": " 500k/500k [00:00&lt;00:00, 8.70MB/s]"
          }
        },
        "37f9621a15374f9e9c2855541d4a11e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0618f8bf5a804cf78ceaeab7323714c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a172683c123b413eb77ac6eea8862bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3a30225b89d4126b9471646a7154d21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01e140e01c0a47158f8ff2b2ec91be1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae79ce60dd0b4b49a2d66db0ad1271da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5565ae2dbf4e94a35c022579aaa4ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56e7ef1f600f47f78d47ebe7ef410250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1aa02ede152b4ba8b5d08195a67283d7",
              "IPY_MODEL_e382feb2e4f149aca553d5398b39decb",
              "IPY_MODEL_07af4cd164ec416f80eeb710bea8ea73"
            ],
            "layout": "IPY_MODEL_940047c7b9834c0096028cdaabb105a4"
          }
        },
        "1aa02ede152b4ba8b5d08195a67283d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07ed592ed6a04586a070ba954add993c",
            "placeholder": "​",
            "style": "IPY_MODEL_1882d960e85e4572989566e4fbf8bbd0",
            "value": "tokenizer.json: 100%"
          }
        },
        "e382feb2e4f149aca553d5398b39decb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed829a223e7b47839c5e81e743267e4c",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_552b05234611493da3ec3b9e07ee1fc6",
            "value": 1842767
          }
        },
        "07af4cd164ec416f80eeb710bea8ea73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_824454dd0ecd4187ac267adc6971ad90",
            "placeholder": "​",
            "style": "IPY_MODEL_ea40370675804b10b070330084c790f1",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 5.49MB/s]"
          }
        },
        "940047c7b9834c0096028cdaabb105a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ed592ed6a04586a070ba954add993c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1882d960e85e4572989566e4fbf8bbd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed829a223e7b47839c5e81e743267e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "552b05234611493da3ec3b9e07ee1fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "824454dd0ecd4187ac267adc6971ad90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea40370675804b10b070330084c790f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "989f3aed257e4428a6fbe020a272d773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1441a98a67a49a893fddffa652f0076",
              "IPY_MODEL_0200909aecd74596b4ed3e240f16a1f9",
              "IPY_MODEL_161f3006519e4142b214cffd6d6b0ada"
            ],
            "layout": "IPY_MODEL_b28b7c20812b4a609b7a7da39d6ace47"
          }
        },
        "d1441a98a67a49a893fddffa652f0076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_082bcffbf6f344ce926fb1bfee46023e",
            "placeholder": "​",
            "style": "IPY_MODEL_fa781d501bef462aacabc47c556ea231",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "0200909aecd74596b4ed3e240f16a1f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0460e4e964d445192e8b67892afd1fa",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c25b8574beb4b1e9886bf160668b524",
            "value": 414
          }
        },
        "161f3006519e4142b214cffd6d6b0ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5aec05a290934d9d90166eb5e023e273",
            "placeholder": "​",
            "style": "IPY_MODEL_7879b1b798ab401c8517b259a1b50f2d",
            "value": " 414/414 [00:00&lt;00:00, 31.2kB/s]"
          }
        },
        "b28b7c20812b4a609b7a7da39d6ace47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "082bcffbf6f344ce926fb1bfee46023e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa781d501bef462aacabc47c556ea231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0460e4e964d445192e8b67892afd1fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c25b8574beb4b1e9886bf160668b524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5aec05a290934d9d90166eb5e023e273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7879b1b798ab401c8517b259a1b50f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7e8d27d92b84e0eac98f19f0410e5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_209596331cd5493eb03d3714bc0e9e9c",
              "IPY_MODEL_29b47c4a62f3446b80687eff7fe365ca",
              "IPY_MODEL_46462e4a232a4b6c83899929bfa90807"
            ],
            "layout": "IPY_MODEL_18b3f5ef35b3400cace877a614edc245"
          }
        },
        "209596331cd5493eb03d3714bc0e9e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cd95aa778b040bbbb2f8c078ce52864",
            "placeholder": "​",
            "style": "IPY_MODEL_961cc787f8d34566bcccd2bb7315d22e",
            "value": "100%"
          }
        },
        "29b47c4a62f3446b80687eff7fe365ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45d84b0b23464e3082a7b0427e5c5b2e",
            "max": 423,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33ff5fbaf7004618a800ec549f5a8b11",
            "value": 423
          }
        },
        "46462e4a232a4b6c83899929bfa90807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d6f40f56ea849409f290557741ddd10",
            "placeholder": "​",
            "style": "IPY_MODEL_f375edc9e30b4ccbaa3e3c666441382d",
            "value": " 423/423 [00:56&lt;00:00,  8.41it/s]"
          }
        },
        "18b3f5ef35b3400cace877a614edc245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cd95aa778b040bbbb2f8c078ce52864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "961cc787f8d34566bcccd2bb7315d22e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45d84b0b23464e3082a7b0427e5c5b2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ff5fbaf7004618a800ec549f5a8b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d6f40f56ea849409f290557741ddd10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f375edc9e30b4ccbaa3e3c666441382d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d3f496804e545139c2ba7d2cdc8d4f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2adae775f6b4e6392a9b0f073aba0d8",
              "IPY_MODEL_68e776360d8c4e6889f623834cd8479e",
              "IPY_MODEL_c5cded1de1b44b6fb5a4ac4f6aa1c26e"
            ],
            "layout": "IPY_MODEL_944554d50b474122b8dfc0685b27bd73"
          }
        },
        "a2adae775f6b4e6392a9b0f073aba0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6a8a852549e4844863d7aa9d2d7caa6",
            "placeholder": "​",
            "style": "IPY_MODEL_7e1d28d429694ace9240ef41914b810a",
            "value": ".gitattributes: 100%"
          }
        },
        "68e776360d8c4e6889f623834cd8479e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6002460355748c8a9507a95ca4d7b1c",
            "max": 1175,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8132fd54182456095d4e4d252470418",
            "value": 1175
          }
        },
        "c5cded1de1b44b6fb5a4ac4f6aa1c26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ed5b5a62cf047209863cc4dd2058263",
            "placeholder": "​",
            "style": "IPY_MODEL_ae7d8269695b40c1a46b2f5ae8262336",
            "value": " 1.18k/1.18k [00:00&lt;00:00, 85.3kB/s]"
          }
        },
        "944554d50b474122b8dfc0685b27bd73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6a8a852549e4844863d7aa9d2d7caa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1d28d429694ace9240ef41914b810a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6002460355748c8a9507a95ca4d7b1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8132fd54182456095d4e4d252470418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ed5b5a62cf047209863cc4dd2058263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae7d8269695b40c1a46b2f5ae8262336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35025a25703b477c87319678313f4db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d954b5a549504b3389bf4260540afb74",
              "IPY_MODEL_3e47a4a98a044454bd17e8226b30d433",
              "IPY_MODEL_41725f4f170b44d58be81fc81605375b"
            ],
            "layout": "IPY_MODEL_f3c9082254044123b7445b0918e8db19"
          }
        },
        "d954b5a549504b3389bf4260540afb74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a441ff25338a443d960f37e0cc31b6ff",
            "placeholder": "​",
            "style": "IPY_MODEL_4675c69bb48041bebddc21e22c556097",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "3e47a4a98a044454bd17e8226b30d433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b53d6f4c147742af9b72819e1090c8be",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3c0f49ffa7343ad947e55a6ec23ec45",
            "value": 190
          }
        },
        "41725f4f170b44d58be81fc81605375b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f92f2a7f5df4feb9032c1a6ced5fdf4",
            "placeholder": "​",
            "style": "IPY_MODEL_33707e8a9ab8450dba5ede0803977a22",
            "value": " 190/190 [00:00&lt;00:00, 13.3kB/s]"
          }
        },
        "f3c9082254044123b7445b0918e8db19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a441ff25338a443d960f37e0cc31b6ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4675c69bb48041bebddc21e22c556097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b53d6f4c147742af9b72819e1090c8be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3c0f49ffa7343ad947e55a6ec23ec45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f92f2a7f5df4feb9032c1a6ced5fdf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33707e8a9ab8450dba5ede0803977a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "991d36d1feaf4a72b9b9cee579c6ba02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd4995ceee0c423ba48e7b035901721f",
              "IPY_MODEL_49a69b68d15e4336a4dcf0114771d47f",
              "IPY_MODEL_f0558ccee59e48e2ac7d90ec382a854d"
            ],
            "layout": "IPY_MODEL_64d4cb392e8e4c8e98056bc8f1d70acd"
          }
        },
        "dd4995ceee0c423ba48e7b035901721f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcc2b3f4072d4a1aba8f6c50f9c84ccc",
            "placeholder": "​",
            "style": "IPY_MODEL_dc2566e2d8f344c7ac6e73fc98b3173d",
            "value": "README.md: 100%"
          }
        },
        "49a69b68d15e4336a4dcf0114771d47f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a4cf49e08924669a569380d9c78b20c",
            "max": 10610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_685910c9fb6544f5aa695bd06295547b",
            "value": 10610
          }
        },
        "f0558ccee59e48e2ac7d90ec382a854d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c833ee30a494ed9b63fec3fe9a28aae",
            "placeholder": "​",
            "style": "IPY_MODEL_ad15920b4bbe4f658319ac8bc44b2ac2",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 651kB/s]"
          }
        },
        "64d4cb392e8e4c8e98056bc8f1d70acd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcc2b3f4072d4a1aba8f6c50f9c84ccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc2566e2d8f344c7ac6e73fc98b3173d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a4cf49e08924669a569380d9c78b20c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "685910c9fb6544f5aa695bd06295547b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c833ee30a494ed9b63fec3fe9a28aae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad15920b4bbe4f658319ac8bc44b2ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88b401a83f4846b08830dd094ead7797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9177e8c21f54adb94426ea0f8f0eef3",
              "IPY_MODEL_39b7bb2a748448189de3856a8cf4ab17",
              "IPY_MODEL_56c1c684807e4cbaaa0fa8f6cb120d90"
            ],
            "layout": "IPY_MODEL_e768fc69473049f8b915b9b4366461dd"
          }
        },
        "a9177e8c21f54adb94426ea0f8f0eef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2be14bc8ce649e0abdab4538a8a44df",
            "placeholder": "​",
            "style": "IPY_MODEL_76830310483f42f4ae97eb20bb3c5f86",
            "value": "config.json: 100%"
          }
        },
        "39b7bb2a748448189de3856a8cf4ab17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bba0780bf8b849fa9673204773006d05",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b79db89091ed405892c371e57385fe40",
            "value": 612
          }
        },
        "56c1c684807e4cbaaa0fa8f6cb120d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f78c369e4148465998652ede4b42654c",
            "placeholder": "​",
            "style": "IPY_MODEL_1e0e82b87e7c40c197866f57f6f6c85a",
            "value": " 612/612 [00:00&lt;00:00, 41.2kB/s]"
          }
        },
        "e768fc69473049f8b915b9b4366461dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2be14bc8ce649e0abdab4538a8a44df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76830310483f42f4ae97eb20bb3c5f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bba0780bf8b849fa9673204773006d05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b79db89091ed405892c371e57385fe40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f78c369e4148465998652ede4b42654c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e0e82b87e7c40c197866f57f6f6c85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74836699da4d43d9840af9509b7a87ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21ee6d74a4bc4299a6dff98308ae6d6b",
              "IPY_MODEL_b2518b16df05478694e1a17671baf1b5",
              "IPY_MODEL_d9c4eb2ba2eb46c4a72b83d927de3eac"
            ],
            "layout": "IPY_MODEL_10eacfc52a004e12ab9699e31d2e05b9"
          }
        },
        "21ee6d74a4bc4299a6dff98308ae6d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c82399a0b24f48adbd3f4e0f569e9d0e",
            "placeholder": "​",
            "style": "IPY_MODEL_5629e6400af846c7a0fb8e9eb56e42fa",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "b2518b16df05478694e1a17671baf1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_677def5b965b4986b2316da7f2c94b42",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a9d3168de164f0796ce3c29693b30d8",
            "value": 116
          }
        },
        "d9c4eb2ba2eb46c4a72b83d927de3eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_541296c2bd514bb594a1efbd69b2d0d6",
            "placeholder": "​",
            "style": "IPY_MODEL_a501eb02940d4efebea94dd3f26834a2",
            "value": " 116/116 [00:00&lt;00:00, 8.31kB/s]"
          }
        },
        "10eacfc52a004e12ab9699e31d2e05b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c82399a0b24f48adbd3f4e0f569e9d0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5629e6400af846c7a0fb8e9eb56e42fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "677def5b965b4986b2316da7f2c94b42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a9d3168de164f0796ce3c29693b30d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "541296c2bd514bb594a1efbd69b2d0d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a501eb02940d4efebea94dd3f26834a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13b1b7814f7440fcb5f2e37cca347ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1f9817758964541af0326cf9a8b2dc4",
              "IPY_MODEL_9cf73c44f09240f38f4c2a55499378aa",
              "IPY_MODEL_29e029eaf997407590aa0b779d8c1251"
            ],
            "layout": "IPY_MODEL_9bcde184be944ccbbd375bd1dfbced97"
          }
        },
        "a1f9817758964541af0326cf9a8b2dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b83e0da4d60428fa5183b622f02bc6f",
            "placeholder": "​",
            "style": "IPY_MODEL_829112c3fc8344aeb6b74f9c7e003c69",
            "value": "data_config.json: 100%"
          }
        },
        "9cf73c44f09240f38f4c2a55499378aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2984176e76c7436a880298676eab641e",
            "max": 39265,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_122b08f41f2148ed98be1acb497b38db",
            "value": 39265
          }
        },
        "29e029eaf997407590aa0b779d8c1251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cee1b1435704c85893cf0fdde22f06c",
            "placeholder": "​",
            "style": "IPY_MODEL_ee46d4c8b5874f068f5db13ca3068d43",
            "value": " 39.3k/39.3k [00:00&lt;00:00, 2.65MB/s]"
          }
        },
        "9bcde184be944ccbbd375bd1dfbced97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b83e0da4d60428fa5183b622f02bc6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "829112c3fc8344aeb6b74f9c7e003c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2984176e76c7436a880298676eab641e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122b08f41f2148ed98be1acb497b38db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cee1b1435704c85893cf0fdde22f06c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee46d4c8b5874f068f5db13ca3068d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b8b2dc3522b4a6daaa9c8f9242515e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_301f9364b4374492a2214a8544fd7487",
              "IPY_MODEL_bb355d116d4845f1b87e4e9cc721eb4e",
              "IPY_MODEL_dae0a4134701445e915e2e68e6674b6d"
            ],
            "layout": "IPY_MODEL_8c36d710325f42e8856aa6f2af220954"
          }
        },
        "301f9364b4374492a2214a8544fd7487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d24cea188c2647798280b05f4ff9fd75",
            "placeholder": "​",
            "style": "IPY_MODEL_33453ab8619a4ebeb0791d703304a2a3",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "bb355d116d4845f1b87e4e9cc721eb4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eee4bdfa7a94933ae6a2ea65caea012",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc3cc36aa9ac42f98630fa7b3eca8039",
            "value": 90888945
          }
        },
        "dae0a4134701445e915e2e68e6674b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_550d3a368ba442d486331e1a929ae99c",
            "placeholder": "​",
            "style": "IPY_MODEL_40fb2dc48efa4f048a1440737d875208",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 86.2MB/s]"
          }
        },
        "8c36d710325f42e8856aa6f2af220954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d24cea188c2647798280b05f4ff9fd75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33453ab8619a4ebeb0791d703304a2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9eee4bdfa7a94933ae6a2ea65caea012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc3cc36aa9ac42f98630fa7b3eca8039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "550d3a368ba442d486331e1a929ae99c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40fb2dc48efa4f048a1440737d875208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26f6c4a21af447729a7fc9afc4a11096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed4067b6a5fa4af38909dc9f8078e08b",
              "IPY_MODEL_d78cef16755146608c6c09577c41697d",
              "IPY_MODEL_58e6f77e76fe480296d454f55939beab"
            ],
            "layout": "IPY_MODEL_8ec6141aaee74c9e94c3721686dae95b"
          }
        },
        "ed4067b6a5fa4af38909dc9f8078e08b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f44fa1de740488db039732a4cf980fa",
            "placeholder": "​",
            "style": "IPY_MODEL_87aee0cbdd784cfbaa1071e81e5eccb9",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "d78cef16755146608c6c09577c41697d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0336c061669e4a42aee202c9e43d3b97",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00f10a40e7a7407fbe6eb926b4468fd4",
            "value": 53
          }
        },
        "58e6f77e76fe480296d454f55939beab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb1b502fc8894ee3b00a6f47e92fe13b",
            "placeholder": "​",
            "style": "IPY_MODEL_5a4bb50e89f941aa8997f4ae37498c84",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.06kB/s]"
          }
        },
        "8ec6141aaee74c9e94c3721686dae95b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f44fa1de740488db039732a4cf980fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87aee0cbdd784cfbaa1071e81e5eccb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0336c061669e4a42aee202c9e43d3b97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00f10a40e7a7407fbe6eb926b4468fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb1b502fc8894ee3b00a6f47e92fe13b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a4bb50e89f941aa8997f4ae37498c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "303b3ba8f7d44a6dace4bbfef816a035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5c5afae2bc342149a419df94624524c",
              "IPY_MODEL_74cc4dcf1f8a461aa4b75fdfce42e6ee",
              "IPY_MODEL_40cc40cbad074622b26de796e6fe59b5"
            ],
            "layout": "IPY_MODEL_ff68a5818a2c401a976e5f7643054680"
          }
        },
        "c5c5afae2bc342149a419df94624524c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03e14647b6204109a688ee47e379f280",
            "placeholder": "​",
            "style": "IPY_MODEL_65f6ca51972240739986b1c228bf7fbc",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "74cc4dcf1f8a461aa4b75fdfce42e6ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06e1f36f992d430490c1728eadbccfa6",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_396561cdb27343da994f53d96550766e",
            "value": 112
          }
        },
        "40cc40cbad074622b26de796e6fe59b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_514afedb9f6b420f855847df4d03a4dd",
            "placeholder": "​",
            "style": "IPY_MODEL_4cd90c8d434547a8a362665b81270f2f",
            "value": " 112/112 [00:00&lt;00:00, 4.28kB/s]"
          }
        },
        "ff68a5818a2c401a976e5f7643054680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03e14647b6204109a688ee47e379f280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65f6ca51972240739986b1c228bf7fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06e1f36f992d430490c1728eadbccfa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "396561cdb27343da994f53d96550766e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "514afedb9f6b420f855847df4d03a4dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd90c8d434547a8a362665b81270f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6381875468c647d5abf322b6f4156bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a878e8a63ea486fa33b6fdd9591e525",
              "IPY_MODEL_2f2c08f19efb4d85b78fee82222ecdd3",
              "IPY_MODEL_eee05cd85ef0412199ebcd62c4bcf993"
            ],
            "layout": "IPY_MODEL_c2c70ec66da44f5797a80344736caeec"
          }
        },
        "9a878e8a63ea486fa33b6fdd9591e525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a354259fc6f14c8f8006719e2d06712d",
            "placeholder": "​",
            "style": "IPY_MODEL_3a52e5719ceb463395c08c2f58b8eea8",
            "value": "tokenizer.json: 100%"
          }
        },
        "2f2c08f19efb4d85b78fee82222ecdd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d157f8028106462aad29e23b3d8670d2",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2ca58f531844e389362066d313f6836",
            "value": 466247
          }
        },
        "eee05cd85ef0412199ebcd62c4bcf993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44edb04cfe404865bf59133e76cd353e",
            "placeholder": "​",
            "style": "IPY_MODEL_c38684263b8a4ec999cf90f58de2c246",
            "value": " 466k/466k [00:00&lt;00:00, 3.60MB/s]"
          }
        },
        "c2c70ec66da44f5797a80344736caeec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a354259fc6f14c8f8006719e2d06712d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a52e5719ceb463395c08c2f58b8eea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d157f8028106462aad29e23b3d8670d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2ca58f531844e389362066d313f6836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44edb04cfe404865bf59133e76cd353e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c38684263b8a4ec999cf90f58de2c246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88ae211a9e1e4a36bd5eb2a6dde0f449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b93c08f811c4b67a78584e869f02775",
              "IPY_MODEL_4184f10950c54ba180893e52e1387799",
              "IPY_MODEL_9ff2ac5108e44016aae4fb2385939937"
            ],
            "layout": "IPY_MODEL_8ec388a169444158a5b091a61e90368c"
          }
        },
        "5b93c08f811c4b67a78584e869f02775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd7738bf08d644528e9e0252ba29f0c1",
            "placeholder": "​",
            "style": "IPY_MODEL_418ef157a35b4637b61e76a6435bf4aa",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4184f10950c54ba180893e52e1387799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_616bf6fa36414fe1a4d7600889cc6808",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c827d348c174afd9685eb884eee831e",
            "value": 350
          }
        },
        "9ff2ac5108e44016aae4fb2385939937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2793c6370c404ee2b1f104bad333caea",
            "placeholder": "​",
            "style": "IPY_MODEL_55e966f6f50b4c459819eebc4e4af23f",
            "value": " 350/350 [00:00&lt;00:00, 23.7kB/s]"
          }
        },
        "8ec388a169444158a5b091a61e90368c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd7738bf08d644528e9e0252ba29f0c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "418ef157a35b4637b61e76a6435bf4aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "616bf6fa36414fe1a4d7600889cc6808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c827d348c174afd9685eb884eee831e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2793c6370c404ee2b1f104bad333caea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55e966f6f50b4c459819eebc4e4af23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb8520387dec40c6a894adfcd9142c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11951cd71bf342d48268c4f82bc3b7d5",
              "IPY_MODEL_87630f3c5bb04aa0a3c47d9815e9945e",
              "IPY_MODEL_206b41196f4a49af8447dc2a15b5ae78"
            ],
            "layout": "IPY_MODEL_d76a08b86b4c425086c4c28a523e6b44"
          }
        },
        "11951cd71bf342d48268c4f82bc3b7d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_026846d25be04e18821bc313d717db0b",
            "placeholder": "​",
            "style": "IPY_MODEL_6c2c75db41044b27bd9873a3a1181cf2",
            "value": "train_script.py: 100%"
          }
        },
        "87630f3c5bb04aa0a3c47d9815e9945e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bba2270caec141769ead43a33ea28c74",
            "max": 13156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83336490707b43d1aa3ebe5c21799082",
            "value": 13156
          }
        },
        "206b41196f4a49af8447dc2a15b5ae78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cd394c3509c4dd59db7737c1a53c26d",
            "placeholder": "​",
            "style": "IPY_MODEL_5440b65d71cc4e66bbcfe4deaabe1b1b",
            "value": " 13.2k/13.2k [00:00&lt;00:00, 930kB/s]"
          }
        },
        "d76a08b86b4c425086c4c28a523e6b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "026846d25be04e18821bc313d717db0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c2c75db41044b27bd9873a3a1181cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bba2270caec141769ead43a33ea28c74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83336490707b43d1aa3ebe5c21799082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cd394c3509c4dd59db7737c1a53c26d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5440b65d71cc4e66bbcfe4deaabe1b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4649e5e1451541a499301da0dc6b3776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ef70f9726cf4a92939387a5dd1a19ec",
              "IPY_MODEL_0304c68710fc4682a247d703a91f00fe",
              "IPY_MODEL_84c9d299bc7b42959c5aa46619279b9c"
            ],
            "layout": "IPY_MODEL_9f36a8f6e75642b789dcde9c05bbc854"
          }
        },
        "8ef70f9726cf4a92939387a5dd1a19ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fe007423d114b6c85532a2c72462b47",
            "placeholder": "​",
            "style": "IPY_MODEL_cec11f92fa1b45fd88d0d259d9719ab5",
            "value": "vocab.txt: 100%"
          }
        },
        "0304c68710fc4682a247d703a91f00fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ec04998e14f448a921b71f312693e35",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_553596d1c2ec42bc87b607f4947b1d4f",
            "value": 231508
          }
        },
        "84c9d299bc7b42959c5aa46619279b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0975f48b0984638a7e786c2f3809724",
            "placeholder": "​",
            "style": "IPY_MODEL_9a9f6e881dd34f429b8fa5acac5b553b",
            "value": " 232k/232k [00:00&lt;00:00, 14.9MB/s]"
          }
        },
        "9f36a8f6e75642b789dcde9c05bbc854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fe007423d114b6c85532a2c72462b47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cec11f92fa1b45fd88d0d259d9719ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ec04998e14f448a921b71f312693e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "553596d1c2ec42bc87b607f4947b1d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0975f48b0984638a7e786c2f3809724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a9f6e881dd34f429b8fa5acac5b553b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5deccd2fbe64a0796678e8c145af145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ff99935fbc443819576bdfb9bc2eb86",
              "IPY_MODEL_6b8afc9fec4743099e8b3dc242a04044",
              "IPY_MODEL_cf9dfc49f8814af096cd21114f055be9"
            ],
            "layout": "IPY_MODEL_dd5bfb8c7d9a40018e931e60121250dc"
          }
        },
        "8ff99935fbc443819576bdfb9bc2eb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73a8840e2dab45a189fdeebc0b12541b",
            "placeholder": "​",
            "style": "IPY_MODEL_dd395def6874437f8f8ae4ca85c2c557",
            "value": "modules.json: 100%"
          }
        },
        "6b8afc9fec4743099e8b3dc242a04044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0f76b34d61d46f58cf5cadfa0abd214",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9feb5bdff9fa4ec3b252f90308bc3449",
            "value": 349
          }
        },
        "cf9dfc49f8814af096cd21114f055be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23c57f46a5be4b949d6fc7a48dc55234",
            "placeholder": "​",
            "style": "IPY_MODEL_c33b92492d9c4f119e7fc2ee1d0aa99d",
            "value": " 349/349 [00:00&lt;00:00, 25.1kB/s]"
          }
        },
        "dd5bfb8c7d9a40018e931e60121250dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73a8840e2dab45a189fdeebc0b12541b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd395def6874437f8f8ae4ca85c2c557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0f76b34d61d46f58cf5cadfa0abd214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9feb5bdff9fa4ec3b252f90308bc3449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23c57f46a5be4b949d6fc7a48dc55234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c33b92492d9c4f119e7fc2ee1d0aa99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "317b8d13be2a42388e9047f341d06d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e68e5cf14da841bbace42e5b20127955",
              "IPY_MODEL_17ed63cc78fa4ac390a072ef358e6c95",
              "IPY_MODEL_4a5b8d8bbd4f4ffb92650e575a34469b"
            ],
            "layout": "IPY_MODEL_7be48439fb6448acbeb0e4966e9b863c"
          }
        },
        "e68e5cf14da841bbace42e5b20127955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_323479d062f9429e851f3b3da5d77f81",
            "placeholder": "​",
            "style": "IPY_MODEL_329a96844904456f9ace515e9d2f056a",
            "value": "config.json: 100%"
          }
        },
        "17ed63cc78fa4ac390a072ef358e6c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7871f650764b4010b1e7c04cdecbfb37",
            "max": 587,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a67ebf98861a4c97b5bddfaa0c181937",
            "value": 587
          }
        },
        "4a5b8d8bbd4f4ffb92650e575a34469b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70bb84313614f8bae5e379af830d51e",
            "placeholder": "​",
            "style": "IPY_MODEL_97f521297e1043e58896b8ca40fd8444",
            "value": " 587/587 [00:00&lt;00:00, 32.8kB/s]"
          }
        },
        "7be48439fb6448acbeb0e4966e9b863c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "323479d062f9429e851f3b3da5d77f81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "329a96844904456f9ace515e9d2f056a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7871f650764b4010b1e7c04cdecbfb37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a67ebf98861a4c97b5bddfaa0c181937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b70bb84313614f8bae5e379af830d51e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97f521297e1043e58896b8ca40fd8444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf1c3b2224c146cbabbe6cb6bad690f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26c7a0b69fc848efb0b35896c94f1409",
              "IPY_MODEL_0fc56e2737a24145b8cee1c600543aea",
              "IPY_MODEL_efde1b2b98284d799de17f451d447288"
            ],
            "layout": "IPY_MODEL_2923ec0a08654ca2b5c8cfbd58808fa9"
          }
        },
        "26c7a0b69fc848efb0b35896c94f1409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84864580f8974f09be816cfd9019f805",
            "placeholder": "​",
            "style": "IPY_MODEL_27bff3f8af6e45a88e7791ec60244995",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "0fc56e2737a24145b8cee1c600543aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c5b3078e17746d19219486ddc9663fc",
            "max": 33444,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7e74e6ebb1c4e0b89087e44917b476a",
            "value": 33444
          }
        },
        "efde1b2b98284d799de17f451d447288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dc394dae74543fe92775295b36c9bf1",
            "placeholder": "​",
            "style": "IPY_MODEL_3e2f4d93fb0b4cc7bf9afdddb49b9f42",
            "value": " 33.4k/33.4k [00:00&lt;00:00, 1.86MB/s]"
          }
        },
        "2923ec0a08654ca2b5c8cfbd58808fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84864580f8974f09be816cfd9019f805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27bff3f8af6e45a88e7791ec60244995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c5b3078e17746d19219486ddc9663fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7e74e6ebb1c4e0b89087e44917b476a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3dc394dae74543fe92775295b36c9bf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e2f4d93fb0b4cc7bf9afdddb49b9f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cded74f0f53e44dda2dd7dd42c6bd30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_157b06454e274c8a850ac56e64c8e7cd",
              "IPY_MODEL_73463f4225d24a14a8183ea9f234667a",
              "IPY_MODEL_a094ec16cdc64d52ae0c0685224b645f"
            ],
            "layout": "IPY_MODEL_10ed004d8c784a8cabadc74f4c3b9c81"
          }
        },
        "157b06454e274c8a850ac56e64c8e7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_733cf6cc08b742cc931681eee162c511",
            "placeholder": "​",
            "style": "IPY_MODEL_86ac67d8aaf3404ebb810762479a9255",
            "value": "Downloading shards: 100%"
          }
        },
        "73463f4225d24a14a8183ea9f234667a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1a7d520fad04351ae2676c88f28f778",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0944e8c4266540009d5b86275de253ec",
            "value": 3
          }
        },
        "a094ec16cdc64d52ae0c0685224b645f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b3fc774dc6b4e0cba6e6303bd8744b9",
            "placeholder": "​",
            "style": "IPY_MODEL_c825ca069421469d83972afd1306df61",
            "value": " 3/3 [05:29&lt;00:00, 103.89s/it]"
          }
        },
        "10ed004d8c784a8cabadc74f4c3b9c81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "733cf6cc08b742cc931681eee162c511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86ac67d8aaf3404ebb810762479a9255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1a7d520fad04351ae2676c88f28f778": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0944e8c4266540009d5b86275de253ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b3fc774dc6b4e0cba6e6303bd8744b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c825ca069421469d83972afd1306df61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "432c89b3be0341e4b1b12fd5f157afa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_582b8355b004405abad99c4808ca3198",
              "IPY_MODEL_311377797f1542948a1d3078cbcc2ea3",
              "IPY_MODEL_cafaae5ce0af40029d483b50d3cbf216"
            ],
            "layout": "IPY_MODEL_158670070a4d464d89d4090fe96a3c43"
          }
        },
        "582b8355b004405abad99c4808ca3198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee192887ea024c4dafd6ea616ea13d13",
            "placeholder": "​",
            "style": "IPY_MODEL_9930f4a8ba3b4eec92f01029422e140e",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "311377797f1542948a1d3078cbcc2ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e41a8f6466744056a3de1afef4760341",
            "max": 9948693272,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f1844f863a44e1aadba1fa8caaefafd",
            "value": 9948693272
          }
        },
        "cafaae5ce0af40029d483b50d3cbf216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b7d84fcf55c48d5b021eaade3c49491",
            "placeholder": "​",
            "style": "IPY_MODEL_2c639b0a1d4f4a3f8fb763958e1453ee",
            "value": " 9.95G/9.95G [02:05&lt;00:00, 86.6MB/s]"
          }
        },
        "158670070a4d464d89d4090fe96a3c43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee192887ea024c4dafd6ea616ea13d13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9930f4a8ba3b4eec92f01029422e140e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e41a8f6466744056a3de1afef4760341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f1844f863a44e1aadba1fa8caaefafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b7d84fcf55c48d5b021eaade3c49491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c639b0a1d4f4a3f8fb763958e1453ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a01f945887394424bc6f2b463dde671e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0282f10da324b809e0d29e4fdd4e6af",
              "IPY_MODEL_282ab759840145d7a32a4eb016edf407",
              "IPY_MODEL_15a362319928438a8e403983dbbc7be7"
            ],
            "layout": "IPY_MODEL_79c51b48fcdb46ea9fde894e8779a9cb"
          }
        },
        "f0282f10da324b809e0d29e4fdd4e6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25e84319e30f4ed4a4f3cddd151f9fa4",
            "placeholder": "​",
            "style": "IPY_MODEL_c8ad09109d5b42f88c393691fe80a1d1",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "282ab759840145d7a32a4eb016edf407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_605667f5fd56411ba61935ccac58f2ec",
            "max": 9904129368,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee947e94cfc54744867343e8e614cd43",
            "value": 9904129368
          }
        },
        "15a362319928438a8e403983dbbc7be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc9b0380036e4fce99a9e5ed64d60758",
            "placeholder": "​",
            "style": "IPY_MODEL_ce912d904fdd4a1982e4d46c040a6b5e",
            "value": " 9.90G/9.90G [02:05&lt;00:00, 84.0MB/s]"
          }
        },
        "79c51b48fcdb46ea9fde894e8779a9cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e84319e30f4ed4a4f3cddd151f9fa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8ad09109d5b42f88c393691fe80a1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "605667f5fd56411ba61935ccac58f2ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee947e94cfc54744867343e8e614cd43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc9b0380036e4fce99a9e5ed64d60758": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce912d904fdd4a1982e4d46c040a6b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b87b075f51744438c2419f2f97411f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a7dbe69f6084b3cb89332b633b6f385",
              "IPY_MODEL_02e194bcbf4a4e8188fbfaf4af1dd3e7",
              "IPY_MODEL_2343c6dffd434938a985322b58e84a61"
            ],
            "layout": "IPY_MODEL_3cecf3191af34552acc6193579852144"
          }
        },
        "8a7dbe69f6084b3cb89332b633b6f385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18a2256e78314cc59cf667a5305af7e6",
            "placeholder": "​",
            "style": "IPY_MODEL_0c93c5893f3c40889687b934316d8c94",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "02e194bcbf4a4e8188fbfaf4af1dd3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_639b85b5739146a1a13b807c8a48e26a",
            "max": 6178962272,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50283174aad340518b8ad3890d26f7d3",
            "value": 6178962272
          }
        },
        "2343c6dffd434938a985322b58e84a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26b641917f4e49d09a30b4ce6056c57a",
            "placeholder": "​",
            "style": "IPY_MODEL_300b2643bdc9469ebfe3a51e26f627fb",
            "value": " 6.18G/6.18G [01:17&lt;00:00, 82.6MB/s]"
          }
        },
        "3cecf3191af34552acc6193579852144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18a2256e78314cc59cf667a5305af7e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c93c5893f3c40889687b934316d8c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "639b85b5739146a1a13b807c8a48e26a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50283174aad340518b8ad3890d26f7d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26b641917f4e49d09a30b4ce6056c57a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "300b2643bdc9469ebfe3a51e26f627fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8571fe617174ec7923473191283dca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4583010c83824a088de8d16e6abe308b",
              "IPY_MODEL_e72d7ea238fc4b7ca694405fcf4c278c",
              "IPY_MODEL_0e975299f7234f99a1d8be78f49aebcc"
            ],
            "layout": "IPY_MODEL_8d482bc69cb84444856720fcccdbf8f5"
          }
        },
        "4583010c83824a088de8d16e6abe308b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f64db26c5564a9cb9ce769277be5bbd",
            "placeholder": "​",
            "style": "IPY_MODEL_a4865495f3ad417fa031f7c5818e45b3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e72d7ea238fc4b7ca694405fcf4c278c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e40a55b6d7c4b83b4327925a3e0f04c",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e6c522823f24df4836aec96bfe2936f",
            "value": 3
          }
        },
        "0e975299f7234f99a1d8be78f49aebcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2541b8f546644fd78748ed5e0b71f708",
            "placeholder": "​",
            "style": "IPY_MODEL_d4abf97865504e1bb2f9a8179272fe40",
            "value": " 3/3 [01:46&lt;00:00, 33.73s/it]"
          }
        },
        "8d482bc69cb84444856720fcccdbf8f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f64db26c5564a9cb9ce769277be5bbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4865495f3ad417fa031f7c5818e45b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e40a55b6d7c4b83b4327925a3e0f04c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e6c522823f24df4836aec96bfe2936f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2541b8f546644fd78748ed5e0b71f708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4abf97865504e1bb2f9a8179272fe40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b4d5a8c8b264dcaacc0667e49c4fabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cccb92a1294b4f84b0ddfe33b3a4bf68",
              "IPY_MODEL_71b08ff4d96c424ea37b0ff0d1aef5cb",
              "IPY_MODEL_2d3abd07886d426caa7a3f1383d5e45a"
            ],
            "layout": "IPY_MODEL_380fd9af234a4af2baf8e0ef40d690e2"
          }
        },
        "cccb92a1294b4f84b0ddfe33b3a4bf68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e215669c68734cafa7e5d4fc79642baa",
            "placeholder": "​",
            "style": "IPY_MODEL_29d3ab5dc3ed499b9085446380988c4f",
            "value": "generation_config.json: 100%"
          }
        },
        "71b08ff4d96c424ea37b0ff0d1aef5cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_740efc74440d4243b5fd593dd5dc0069",
            "max": 188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a7328d1399847a99bcacddb36fb3873",
            "value": 188
          }
        },
        "2d3abd07886d426caa7a3f1383d5e45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0d96200bd1244bf8fd3eb5f14b9714b",
            "placeholder": "​",
            "style": "IPY_MODEL_0de12cc978f04f05b6386391aa364887",
            "value": " 188/188 [00:00&lt;00:00, 7.49kB/s]"
          }
        },
        "380fd9af234a4af2baf8e0ef40d690e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e215669c68734cafa7e5d4fc79642baa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29d3ab5dc3ed499b9085446380988c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "740efc74440d4243b5fd593dd5dc0069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a7328d1399847a99bcacddb36fb3873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0d96200bd1244bf8fd3eb5f14b9714b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0de12cc978f04f05b6386391aa364887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4f6f625cf024fdeac3b1067ce224f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_112292f466e64cab8c0a24c61d4abc35",
              "IPY_MODEL_0ce3e21a43984ea3a96425ccd321b752",
              "IPY_MODEL_30a42f2b4e734d8f99c477e079ce8529"
            ],
            "layout": "IPY_MODEL_bcc8305e52024462bdba78df1cf5345a"
          }
        },
        "112292f466e64cab8c0a24c61d4abc35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddb291ae4911410eb2d10e7e88df8c58",
            "placeholder": "​",
            "style": "IPY_MODEL_a8a752d9519b477c9d258d314a81ab0c",
            "value": "Downloading readme: 100%"
          }
        },
        "0ce3e21a43984ea3a96425ccd321b752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae90d7107c034b7c9e31155391744063",
            "max": 997,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b782fd037e14371ac03a3f30695b8fc",
            "value": 997
          }
        },
        "30a42f2b4e734d8f99c477e079ce8529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e3cf3ae61744193b6634081147a43cc",
            "placeholder": "​",
            "style": "IPY_MODEL_cf07a8dd5d744c1496750e2bea97b4ac",
            "value": " 997/997 [00:00&lt;00:00, 49.5kB/s]"
          }
        },
        "bcc8305e52024462bdba78df1cf5345a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb291ae4911410eb2d10e7e88df8c58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8a752d9519b477c9d258d314a81ab0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae90d7107c034b7c9e31155391744063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b782fd037e14371ac03a3f30695b8fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e3cf3ae61744193b6634081147a43cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf07a8dd5d744c1496750e2bea97b4ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c3bf4c2bb0f4ab8a5670b6e15fe6a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99201e440c0c4879bc003fb13c3195b0",
              "IPY_MODEL_435b00d26c664c15a4082f8bbb4f1e44",
              "IPY_MODEL_60089c5685294cd693ba9c44ae83cd2b"
            ],
            "layout": "IPY_MODEL_09f2b9d12bd7437e82f4a471b8dc1c8a"
          }
        },
        "99201e440c0c4879bc003fb13c3195b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_080c0bbb9e6b4b0b81661d4a79385c00",
            "placeholder": "​",
            "style": "IPY_MODEL_d5211f0dcd5647e7af39d5ecb4dc1dad",
            "value": "Downloading data: 100%"
          }
        },
        "435b00d26c664c15a4082f8bbb4f1e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ddc2cc0a7e24d8d982d45f9c0897988",
            "max": 2272692,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33d2e4f7e7b948628d4b5b5818412b86",
            "value": 2272692
          }
        },
        "60089c5685294cd693ba9c44ae83cd2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f0f6ac974f142f6ae15c4c74ffa9eac",
            "placeholder": "​",
            "style": "IPY_MODEL_de450b2a8f3f45838d42701e3e622251",
            "value": " 2.27M/2.27M [00:00&lt;00:00, 4.98MB/s]"
          }
        },
        "09f2b9d12bd7437e82f4a471b8dc1c8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "080c0bbb9e6b4b0b81661d4a79385c00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5211f0dcd5647e7af39d5ecb4dc1dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ddc2cc0a7e24d8d982d45f9c0897988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33d2e4f7e7b948628d4b5b5818412b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f0f6ac974f142f6ae15c4c74ffa9eac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de450b2a8f3f45838d42701e3e622251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bee540d79414caeb9a358cf8aebc20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_892e2d34825349e9b04a1afae51ef993",
              "IPY_MODEL_9ab514ee01684b9eb8e37c339a0ecf96",
              "IPY_MODEL_8097090e59c44886aff32a8cdaddb8cd"
            ],
            "layout": "IPY_MODEL_bd69f8be94db40f8b6dbf3c88eee3e1a"
          }
        },
        "892e2d34825349e9b04a1afae51ef993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80126ff1d7a8468f829295b742b4b19e",
            "placeholder": "​",
            "style": "IPY_MODEL_48b925d25cba4963ba5da2ca1ba37f27",
            "value": "Generating train split: 100%"
          }
        },
        "9ab514ee01684b9eb8e37c339a0ecf96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58aa43cbe3db40a69f45d2c8b5a5448a",
            "max": 317,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7320c873fe954e338e359413badea3a6",
            "value": 317
          }
        },
        "8097090e59c44886aff32a8cdaddb8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25b6a49faca2469aae2bd539c150f4fa",
            "placeholder": "​",
            "style": "IPY_MODEL_556c33dbc08641c28cba12b1c0cc9ac1",
            "value": " 317/317 [00:00&lt;00:00, 805.91 examples/s]"
          }
        },
        "bd69f8be94db40f8b6dbf3c88eee3e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80126ff1d7a8468f829295b742b4b19e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48b925d25cba4963ba5da2ca1ba37f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58aa43cbe3db40a69f45d2c8b5a5448a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7320c873fe954e338e359413badea3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25b6a49faca2469aae2bd539c150f4fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "556c33dbc08641c28cba12b1c0cc9ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f01a0755897c4ad889eb0c4c7322d4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db3136a315d44ef6812e60479f52ba1a",
              "IPY_MODEL_e73fcaf6c1164064ab4006d2520eaa58",
              "IPY_MODEL_de5976b65a644e3eb5be8aa997051a82"
            ],
            "layout": "IPY_MODEL_154e512ca6944e30900a56065991a522"
          }
        },
        "db3136a315d44ef6812e60479f52ba1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e328e93f099b45318aed28086c23f546",
            "placeholder": "​",
            "style": "IPY_MODEL_f1340fdf2b0d4e669cde7061391abd9b",
            "value": "Downloading builder script: 100%"
          }
        },
        "e73fcaf6c1164064ab4006d2520eaa58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4e93a8ac35440f28677cba48bef742e",
            "max": 5937,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6bb565dfc0b47afa8c343556f29dd38",
            "value": 5937
          }
        },
        "de5976b65a644e3eb5be8aa997051a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_406bc670180e427b8e305627a3d1d9db",
            "placeholder": "​",
            "style": "IPY_MODEL_eac172de91164e3490c7e6b3bff6b8d8",
            "value": " 5.94k/5.94k [00:00&lt;00:00, 412kB/s]"
          }
        },
        "154e512ca6944e30900a56065991a522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e328e93f099b45318aed28086c23f546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1340fdf2b0d4e669cde7061391abd9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4e93a8ac35440f28677cba48bef742e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6bb565dfc0b47afa8c343556f29dd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "406bc670180e427b8e305627a3d1d9db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eac172de91164e3490c7e6b3bff6b8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb3a8ffdac6f499bb720a7d6b31115d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d22385f2f9664b0780a6d7bab16fcd1a",
              "IPY_MODEL_1c2c918548904aaca6b2cecd2649b2cb",
              "IPY_MODEL_03f72b251a014651ab35304b0d68a0f5"
            ],
            "layout": "IPY_MODEL_e453262ef4094d4ba69282e32e1caaa5"
          }
        },
        "d22385f2f9664b0780a6d7bab16fcd1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0597e1ccd4324f97bd09eab65f9e62ec",
            "placeholder": "​",
            "style": "IPY_MODEL_13ff5fe88ec24f8ba5f020cab3d29327",
            "value": "Downloading extra modules: "
          }
        },
        "1c2c918548904aaca6b2cecd2649b2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf75fa3f38a54ebc8e148c8e96afe532",
            "max": 1554,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64ab63db239a4387b8fb8c472932993c",
            "value": 1554
          }
        },
        "03f72b251a014651ab35304b0d68a0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9fc6198448b41cc9d4ad5b15d58f32c",
            "placeholder": "​",
            "style": "IPY_MODEL_6c320645a18945a8ba8871c1a858195f",
            "value": " 4.07k/? [00:00&lt;00:00, 219kB/s]"
          }
        },
        "e453262ef4094d4ba69282e32e1caaa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0597e1ccd4324f97bd09eab65f9e62ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13ff5fe88ec24f8ba5f020cab3d29327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf75fa3f38a54ebc8e148c8e96afe532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64ab63db239a4387b8fb8c472932993c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9fc6198448b41cc9d4ad5b15d58f32c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c320645a18945a8ba8871c1a858195f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "511b63a75b634de68baddbff213b5349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4079b571bc394ea9bd14d6adf64a0ab5",
              "IPY_MODEL_43b09aa8ad0345b18830675da50564ea",
              "IPY_MODEL_8aa1a15487224228a3f69b4d61b2f125"
            ],
            "layout": "IPY_MODEL_27639f9528f0406ea61011edfa74f768"
          }
        },
        "4079b571bc394ea9bd14d6adf64a0ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ecb401b0080490985b99c62f7b02150",
            "placeholder": "​",
            "style": "IPY_MODEL_086a041548ce498f862d73ae4c0ffe93",
            "value": "Downloading extra modules: 100%"
          }
        },
        "43b09aa8ad0345b18830675da50564ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df47787cc50547b2a1e551e1663fbaf9",
            "max": 3344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18715846a26647c68f49f4f4187e6807",
            "value": 3344
          }
        },
        "8aa1a15487224228a3f69b4d61b2f125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ef87ffcbbe64648b2bdbc8572cff5f6",
            "placeholder": "​",
            "style": "IPY_MODEL_7b644c404d7e4f3d8f8953dda5a60593",
            "value": " 3.34k/3.34k [00:00&lt;00:00, 243kB/s]"
          }
        },
        "27639f9528f0406ea61011edfa74f768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ecb401b0080490985b99c62f7b02150": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "086a041548ce498f862d73ae4c0ffe93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df47787cc50547b2a1e551e1663fbaf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18715846a26647c68f49f4f4187e6807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ef87ffcbbe64648b2bdbc8572cff5f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b644c404d7e4f3d8f8953dda5a60593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70ef2ff8f2cc4851b79943df317fd4ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1763f584868d413b96fd592735a26433",
              "IPY_MODEL_e57bb34d245d41329d415737036b5ed8",
              "IPY_MODEL_07909925e65a4d52abf2b321e7915934"
            ],
            "layout": "IPY_MODEL_6956856d9d1945cf8d7526c7a24bf6b1"
          }
        },
        "1763f584868d413b96fd592735a26433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c74deceb413346238844d3c6b4aaa519",
            "placeholder": "​",
            "style": "IPY_MODEL_5c106378df574c04821f3965902cb4d8",
            "value": "Downloading builder script: 100%"
          }
        },
        "e57bb34d245d41329d415737036b5ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_522f256dd3bd4a4b98bef69be0901639",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36f66c2513964579a6bf85d01b952b93",
            "value": 6270
          }
        },
        "07909925e65a4d52abf2b321e7915934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44a07636d9e64285acbd8fd91088cf4b",
            "placeholder": "​",
            "style": "IPY_MODEL_390885c1f09f4003a60895d8363bdb15",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 406kB/s]"
          }
        },
        "6956856d9d1945cf8d7526c7a24bf6b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c74deceb413346238844d3c6b4aaa519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c106378df574c04821f3965902cb4d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "522f256dd3bd4a4b98bef69be0901639": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36f66c2513964579a6bf85d01b952b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44a07636d9e64285acbd8fd91088cf4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390885c1f09f4003a60895d8363bdb15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fec00ab3cde4eb3ac71ae11fae90feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c7f58bd62ef42758786fd8067944b80",
              "IPY_MODEL_f18830309edd4b49b8c1e3fb284d31be",
              "IPY_MODEL_7ef7f78a5a074ed7a91d6e69ccf711e1"
            ],
            "layout": "IPY_MODEL_0da6e29c5a994b67a51392f354e69cf3"
          }
        },
        "7c7f58bd62ef42758786fd8067944b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0cb32dedd89430ab319207c9c31f675",
            "placeholder": "​",
            "style": "IPY_MODEL_edd314fd8ef54b0a811c51bf5f2edf17",
            "value": "Downloading builder script: 100%"
          }
        },
        "f18830309edd4b49b8c1e3fb284d31be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc8840dc76684244b7d76c40450031bd",
            "max": 7950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11961e6ea323406c85360c0f9fd41143",
            "value": 7950
          }
        },
        "7ef7f78a5a074ed7a91d6e69ccf711e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f74094bcda244ce58c815e4af8cd479f",
            "placeholder": "​",
            "style": "IPY_MODEL_f098683cad834d82b3d987fcbfdb5211",
            "value": " 7.95k/7.95k [00:00&lt;00:00, 373kB/s]"
          }
        },
        "0da6e29c5a994b67a51392f354e69cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0cb32dedd89430ab319207c9c31f675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edd314fd8ef54b0a811c51bf5f2edf17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc8840dc76684244b7d76c40450031bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11961e6ea323406c85360c0f9fd41143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f74094bcda244ce58c815e4af8cd479f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f098683cad834d82b3d987fcbfdb5211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a70577c49fd84d80baec1d26adc8e931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bda9ceb5a4a4272ac0860cd67276dfc",
              "IPY_MODEL_e7b7fb32f098425482108c4fb68c8af5",
              "IPY_MODEL_c90c9b077c674120838833d63ebd62bd"
            ],
            "layout": "IPY_MODEL_531010c38d384c239d64c6aa22a59a7a"
          }
        },
        "4bda9ceb5a4a4272ac0860cd67276dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f24224d206f44c4a8e0a5d9df3c03be",
            "placeholder": "​",
            "style": "IPY_MODEL_c3cb1f587f694dc0a48aad335eb315e7",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e7b7fb32f098425482108c4fb68c8af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d43cb0d04dd4ed3945afd5afd80b3f6",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_270fd6b2cf834413b5de3f9c83c67098",
            "value": 28
          }
        },
        "c90c9b077c674120838833d63ebd62bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6188859f56e2485fb57eeb8e0e3fbb6f",
            "placeholder": "​",
            "style": "IPY_MODEL_8f201d9451574a65a2b9da82e08470c6",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.69kB/s]"
          }
        },
        "531010c38d384c239d64c6aa22a59a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f24224d206f44c4a8e0a5d9df3c03be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3cb1f587f694dc0a48aad335eb315e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d43cb0d04dd4ed3945afd5afd80b3f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "270fd6b2cf834413b5de3f9c83c67098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6188859f56e2485fb57eeb8e0e3fbb6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f201d9451574a65a2b9da82e08470c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa83a8af7aa74c2f9b4da7cba17b151c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eaa77c8743e4020b40fb407bf52859e",
              "IPY_MODEL_740aad8e445a4bf28f578a5e98c23fd7",
              "IPY_MODEL_2acd7462fb394cc1bf6920cb2fe78f4d"
            ],
            "layout": "IPY_MODEL_24cc2d7bcf4e41da8af3d812b028cb9b"
          }
        },
        "4eaa77c8743e4020b40fb407bf52859e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bb92dced1274fd1bc28e495c49e09e8",
            "placeholder": "​",
            "style": "IPY_MODEL_aebc488a12ba402c86837c0589c54768",
            "value": "config.json: 100%"
          }
        },
        "740aad8e445a4bf28f578a5e98c23fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e0161da396241c68d2cf0d1fdd47cc2",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44adf89dab2e4e4b98d177f7d558de43",
            "value": 483
          }
        },
        "2acd7462fb394cc1bf6920cb2fe78f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f95c758049e49bbab1ff077e7a0bcdb",
            "placeholder": "​",
            "style": "IPY_MODEL_43f58916083046269cc08dc81277a946",
            "value": " 483/483 [00:00&lt;00:00, 34.3kB/s]"
          }
        },
        "24cc2d7bcf4e41da8af3d812b028cb9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bb92dced1274fd1bc28e495c49e09e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aebc488a12ba402c86837c0589c54768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e0161da396241c68d2cf0d1fdd47cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44adf89dab2e4e4b98d177f7d558de43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f95c758049e49bbab1ff077e7a0bcdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43f58916083046269cc08dc81277a946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34f2863b07714398aa990798cc078bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a78e81d9dfb94e9fa2a18b247c77066d",
              "IPY_MODEL_0fa60a043b874978ad13df4ccda2787b",
              "IPY_MODEL_4ba2cec30b014bc2b4354215cd4344f4"
            ],
            "layout": "IPY_MODEL_4143c35bdce342868fc9d26872510bcb"
          }
        },
        "a78e81d9dfb94e9fa2a18b247c77066d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d3cea2f241542969a75167d8065e7c5",
            "placeholder": "​",
            "style": "IPY_MODEL_1319bc38af3e49708bbce988ac72b307",
            "value": "vocab.txt: 100%"
          }
        },
        "0fa60a043b874978ad13df4ccda2787b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_027706ec178640dd82d4cad0df114457",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f8ae92d226b437eaa8d20fe4288fad7",
            "value": 231508
          }
        },
        "4ba2cec30b014bc2b4354215cd4344f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5678bb5be1eb40d5a560dac7b690a0c0",
            "placeholder": "​",
            "style": "IPY_MODEL_bfa6380041c743fe89385d168f150f85",
            "value": " 232k/232k [00:00&lt;00:00, 6.51MB/s]"
          }
        },
        "4143c35bdce342868fc9d26872510bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d3cea2f241542969a75167d8065e7c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1319bc38af3e49708bbce988ac72b307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "027706ec178640dd82d4cad0df114457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f8ae92d226b437eaa8d20fe4288fad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5678bb5be1eb40d5a560dac7b690a0c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfa6380041c743fe89385d168f150f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "827fd80e19ba4120ab719ea046592867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3621a83044af4be7b04510f7612323a0",
              "IPY_MODEL_883d62149bf14525a01ec53fb2021083",
              "IPY_MODEL_3b1ced1ab57f478da64ac7dc54b863d5"
            ],
            "layout": "IPY_MODEL_190bd5caa05c49429754d00458f22884"
          }
        },
        "3621a83044af4be7b04510f7612323a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddfcc13735df4455996830e7203d5b6d",
            "placeholder": "​",
            "style": "IPY_MODEL_0ec928573bae4c7abac64961c69305e4",
            "value": "tokenizer.json: 100%"
          }
        },
        "883d62149bf14525a01ec53fb2021083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c68babd61ef4a21b15bb3a230d1395e",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04b954aadb844a6a91ee0153cc6a8cef",
            "value": 466062
          }
        },
        "3b1ced1ab57f478da64ac7dc54b863d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a487a6c7cd5644619e65c5bffb530313",
            "placeholder": "​",
            "style": "IPY_MODEL_a8bcd648982c4a579ed69e182917b445",
            "value": " 466k/466k [00:00&lt;00:00, 25.8MB/s]"
          }
        },
        "190bd5caa05c49429754d00458f22884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddfcc13735df4455996830e7203d5b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ec928573bae4c7abac64961c69305e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c68babd61ef4a21b15bb3a230d1395e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04b954aadb844a6a91ee0153cc6a8cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a487a6c7cd5644619e65c5bffb530313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8bcd648982c4a579ed69e182917b445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12c1650ee75145ee8c2b482bb6664b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4557a543e0e241deab8702416b5b75ff",
              "IPY_MODEL_697b4efc18974b849d823aed1d6cf606",
              "IPY_MODEL_7d5fe979b5e3422cad15b9bde00f8cf8"
            ],
            "layout": "IPY_MODEL_ed3473cedbca40a7a240032b566919ad"
          }
        },
        "4557a543e0e241deab8702416b5b75ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8cd94a0fef84f90b8348736bcf124d8",
            "placeholder": "​",
            "style": "IPY_MODEL_8dce6e229f684c76ad087adf11521073",
            "value": "model.safetensors: 100%"
          }
        },
        "697b4efc18974b849d823aed1d6cf606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82cef29882b54957ba988074d1042385",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01519798f1ee43cc9ace128184c0cb62",
            "value": 267954768
          }
        },
        "7d5fe979b5e3422cad15b9bde00f8cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a19666995ea24e2c9a82bd957a2b74b2",
            "placeholder": "​",
            "style": "IPY_MODEL_e51ffc6196f245ed92af0eaac50f63c0",
            "value": " 268M/268M [00:04&lt;00:00, 63.2MB/s]"
          }
        },
        "ed3473cedbca40a7a240032b566919ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8cd94a0fef84f90b8348736bcf124d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dce6e229f684c76ad087adf11521073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82cef29882b54957ba988074d1042385": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01519798f1ee43cc9ace128184c0cb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a19666995ea24e2c9a82bd957a2b74b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e51ffc6196f245ed92af0eaac50f63c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}