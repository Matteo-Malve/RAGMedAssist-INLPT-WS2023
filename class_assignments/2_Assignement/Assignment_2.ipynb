{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9f7653",
   "metadata": {
    "id": "be9f7653"
   },
   "source": [
    "**Heidelberg University**\n",
    "\n",
    "**Data Science  Group**\n",
    "    \n",
    "Prof. Dr. Michael Gertz  \n",
    "\n",
    "Ashish Chouhan, Satya Almasian, John Ziegler, Jayson Salazar, Nicolas Reuter\n",
    "    \n",
    "November 13, 2023\n",
    "    \n",
    "Natural Language Processing with Transformers\n",
    "\n",
    "Winter Semster 2023/2024     \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e9648",
   "metadata": {
    "id": "258e9648"
   },
   "source": [
    "# **Assignment 2: “Sequence Models”**\n",
    "**Due**: Monday, November 27, 2pm, via [Moodle](https://moodle.uni-heidelberg.de/course/view.php?id=19251)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc27ad9e",
   "metadata": {
    "id": "fc27ad9e"
   },
   "source": [
    "### **Submission Guidelines**\n",
    "\n",
    "- Solutions need to be uploaded as a **single** Jupyter notebook. You will find several pre-filled code segments in the notebook, your task is to fill in the missing cells.\n",
    "- For the written solution, use LaTeX in markdown inside the same notebook. Do **not** hand in a separate file for it.\n",
    "- Download the .zip file containing the dataset but do **not** upload it with your solution.\n",
    "- It is sufficient if one person per group uploads the solution to Moodle, but make sure that the complete names of all team members are given in the notebook.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e322e8b0",
   "metadata": {
    "id": "e322e8b0"
   },
   "source": [
    "## **Task 1: Part-of-Speech Tagging with a Bidirectional LSTM**  (2+4+5=11 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca26ac",
   "metadata": {
    "id": "b4ca26ac"
   },
   "source": [
    "In this task we will be building a sequence tagger that produces an output for every element in an input sequence, using `PyTorch` and `TorchText`, where `TorchText` consists of data processing utilities and popular datasets for natural language.\n",
    "\n",
    "\n",
    "*   **input:** a sequence of text\n",
    "*   **output:** part-of-speech (POS) tag for each token in the input text\n",
    "\n",
    "We tackle this task using a multi-layer bi-directional LSTM (BiLSTM) to predict POS tags using the [Universal Dependencies](https://universaldependencies.org/) English Web Treebank (UDPOS) dataset. This dataset is contained in the `TorchText` library and we do not require an external file for it. The dataset in  `TorchText`  has two different sets of tags, universal dependency (UD) tags and Penn Treebank (PTB) tags. We only focus on the UD tags for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nnBfLC1P5QXw",
   "metadata": {
    "id": "nnBfLC1P5QXw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: portalocker in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (2.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install portalocker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nT5geerO7d1P",
   "metadata": {
    "id": "nT5geerO7d1P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchdata in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (0.7.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torchdata) (2.0.7)\n",
      "Requirement already satisfied: requests in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torchdata) (2.31.0)\n",
      "Requirement already satisfied: torch>=2 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torchdata) (2.1.1)\n",
      "Requirement already satisfied: filelock in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torch>=2->torchdata) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torch>=2->torchdata) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torch>=2->torchdata) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torch>=2->torchdata) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torch>=2->torchdata) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torch>=2->torchdata) (2023.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from requests->torchdata) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from requests->torchdata) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from requests->torchdata) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from jinja2->torch>=2->torchdata) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "_pIBtTh3sOQe",
   "metadata": {
    "id": "_pIBtTh3sOQe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (0.16.1)\n",
      "Requirement already satisfied: tqdm in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torchtext) (4.66.1)\n",
      "Requirement already satisfied: requests in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torchtext) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.1 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torchtext) (2.1.1)\n",
      "Requirement already satisfied: numpy in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torchtext) (1.26.0)\n",
      "Requirement already satisfied: torchdata==0.7.1 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torchtext) (0.7.1)\n",
      "Requirement already satisfied: filelock in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torch==2.1.1->torchtext) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torch==2.1.1->torchtext) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torch==2.1.1->torchtext) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torch==2.1.1->torchtext) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torch==2.1.1->torchtext) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torch==2.1.1->torchtext) (2023.10.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from torchdata==0.7.1->torchtext) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from requests->torchtext) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from requests->torchtext) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from requests->torchtext) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from jinja2->torch==2.1.1->torchtext) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from sympy->torch==2.1.1->torchtext) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "787e2059",
   "metadata": {
    "id": "787e2059"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import UDPOS\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(77)\n",
    "np.random.seed(77)\n",
    "torch.manual_seed(77)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc29cb37",
   "metadata": {
    "id": "fc29cb37"
   },
   "source": [
    "### Subtask 1: Data Analysis\n",
    "The very basic components of the torchtext library include `vocab`, `word vectors`, and `tokenizer`. Those are the basic data processing building blocks for the raw text string.\n",
    "In this case, we use the tokenizer and the vocabulary. Use the `build_vocab_from_iterator` to create the vocabulary for the text field and add the `<unk>` and `<pad>` tokens to it. Use a minimal frequency of `2`.\n",
    "Also create a vocabulary for the labels (tag field). However, since the tags are predefined elements, you will not need an `<unk>` token.\n",
    " This dataset actually has two different sets of tags, universal dependency (UD) tags and Penn Treebank (PTB) tags. We train our model on the UD tags, which is the second element on the list of outputs (example below).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "IlEFywat4Gva",
   "metadata": {
    "id": "IlEFywat4Gva"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Al', '-', 'Zaman', ':', 'American', 'forces', 'killed', 'Shaikh', 'Abdullah', 'al', '-', 'Ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'Qaim', ',', 'near', 'the', 'Syrian', 'border', '.'], ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT'], ['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']]\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(UDPOS(split=\"train\"))\n",
    "print(next(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7HJWFvb3AgTI",
   "metadata": {
    "id": "7HJWFvb3AgTI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 12543\n",
      "Number of validation examples: 2002\n",
      "Number of testing examples: 2077\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(list(UDPOS(split='train')))}\")\n",
    "print(f\"Number of validation examples: {len(list(UDPOS(split='valid')))}\")\n",
    "print(f\"Number of testing examples: {len(list(UDPOS(split='test')))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RaAW09-n_5DC",
   "metadata": {
    "id": "RaAW09-n_5DC"
   },
   "source": [
    "Note that the data is already tokenized!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rcG-FcDu5DcA",
   "metadata": {
    "id": "rcG-FcDu5DcA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 708]\n",
      "[0, 2, 8]\n"
     ]
    }
   ],
   "source": [
    "train_iter = UDPOS(split=\"train\") # to get the training set\n",
    "\n",
    "### your code (make sure pad has id of 0) ####\n",
    "# Function to yield tokens from dataset\n",
    "def yield_tokens(data_iter, index):\n",
    "    for data in data_iter:\n",
    "        yield data[index]\n",
    "\n",
    "# Build vocabulary for text field\n",
    "# Ensure <pad> is the first special token so it gets index 0\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter, 0), min_freq=2, specials=['<pad>', '<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "# Reset train_iter for UD tags\n",
    "train_iter = UDPOS(split=\"train\")\n",
    "\n",
    "# Build vocabulary for UD tags\n",
    "# No need to set <pad> index as it's the only special token and will automatically get index 0\n",
    "ud_vocab = build_vocab_from_iterator(yield_tokens(train_iter, 1), specials=['<pad>'])\n",
    "ud_vocab.set_default_index(ud_vocab['<pad>'])\n",
    "\n",
    "#test\n",
    "print(vocab([\"<unk>\", \"<pad>\", \"news\"]))\n",
    "print(ud_vocab([\"<pad>\", \"PUNCT\", \"ADJ\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nzalgc92j2mG",
   "metadata": {
    "id": "nzalgc92j2mG"
   },
   "source": [
    "Prepare a text processing pipeline that takes raw input and labels and converts them to ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "BDqKYQnRj2D8",
   "metadata": {
    "id": "BDqKYQnRj2D8"
   },
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(x)\n",
    "label_pipeline = lambda x: ud_vocab(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wg36B2Z_Hdi0",
   "metadata": {
    "id": "wg36B2Z_Hdi0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 9271, 35, 9097, 0, 1]\n",
      "[6, 8, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(text_pipeline(['the', 'preacher', 'at', 'mosque', \"<pad>\",\"pppp\"])) #should output [3, 9271, 35, 9097, 0, 1]\n",
    "print(label_pipeline(['DET', 'ADJ', 'NOUN', 'PUNCT'])) # should output [6, 8, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cjn1qH2dHoaa",
   "metadata": {
    "id": "cjn1qH2dHoaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in input vocabulary: 9875\n",
      "Unique tokens in UD vocabulary: 18\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in input vocabulary: {len(vocab)}\")\n",
    "print(f\"Unique tokens in UD vocabulary: {len(ud_vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FUnDiAOW-N5S",
   "metadata": {
    "id": "FUnDiAOW-N5S"
   },
   "source": [
    "Write a custom function for the dataloader that applies the text and label pipeline and pads the sequences to have equal lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aN6s1UhoRhK",
   "metadata": {
    "id": "0aN6s1UhoRhK"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from torch import tensor\n",
    "\n",
    "def collate_batch(batch, pad_token_ix, pad_token_ix_ud):\n",
    "    text_list, label_list = [], []\n",
    "\n",
    "    for (_text, _label, _) in batch:\n",
    "        processed_text = text_pipeline(_text)\n",
    "        processed_label = label_pipeline(_label)\n",
    "        text_list.append(tensor(processed_text, dtype=torch.int64))\n",
    "        label_list.append(tensor(processed_label, dtype=torch.int64))\n",
    "\n",
    "    # Find the maximum length in the batch for both text and labels\n",
    "    max_length_text = max([len(x) for x in text_list])\n",
    "    max_length_label = max([len(y) for y in label_list])\n",
    "\n",
    "    # Pad the sequences manually\n",
    "    padded_text_list = [torch.cat([x, torch.full((max_length_text - len(x),), pad_token_ix, dtype=torch.int64)]) for x in text_list]\n",
    "    padded_label_list = [torch.cat([y, torch.full((max_length_label - len(y),), pad_token_ix_ud, dtype=torch.int64)]) for y in label_list]\n",
    "\n",
    "    # Stack padded sequences\n",
    "    x_padded = torch.stack(padded_text_list)\n",
    "    y_padded = torch.stack(padded_label_list)\n",
    "\n",
    "    return x_padded.to(device), y_padded.to(device)\n",
    "\n",
    "collate_fn = partial(collate_batch, pad_token_ix=vocab['<pad>'], pad_token_ix_ud=ud_vocab['<pad>'])\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    UDPOS(split=\"train\"), batch_size=128, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    UDPOS(split=\"valid\"), batch_size=128, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    UDPOS(split=\"test\"), batch_size=128, shuffle=True, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2X8ZZ0J4oek_",
   "metadata": {
    "id": "2X8ZZ0J4oek_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 57])\n",
      "torch.Size([128, 57])\n",
      "tensor([1832,   13,   17,  488, 2837,    3, 3074,    1, 5532,  512,   13,   23,\n",
      "          56,  143,    5,  170,  154,  273,   39,  157,  971,   44, 2212,  648,\n",
      "           2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "tensor([14,  4,  9, 12,  3,  6,  1,  1, 10, 17,  4,  3, 10, 13,  5, 13,  1, 10,\n",
      "        14,  9,  3,  5,  7,  7,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "for idx, (label, text) in enumerate(train_dataloader):\n",
    "      print(label.shape)\n",
    "      print(text.shape)\n",
    "      print(label[0])\n",
    "      print(text[0])\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jDy_wvjR_1Sg",
   "metadata": {
    "id": "jDy_wvjR_1Sg"
   },
   "source": [
    "Let's take a closer look at the data and the distribution of tags.\n",
    "Implement `tag_percentage`:\n",
    "\n",
    "*   Use the `collection.counter` to count the unique instances of each tag.\n",
    "\n",
    "*    Compute the percentage of each tag in the entire set, by using the counted frequencies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "273JqNZn_rRT",
   "metadata": {
    "id": "273JqNZn_rRT"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def tag_percentage(training_iterator):\n",
    "    counter = Counter()\n",
    "    #### your code to count the number of tags\n",
    "    for (_text, tags, _) in training_iterator:   \n",
    "        counter.update(tags)    #update counter with batch's tags\n",
    "\n",
    "    ### compute the tag percentages based on the counter object\n",
    "    total_tags = sum(counter.values())\n",
    "    tag_p = [(tag, count, (count/total_tags)) for tag, count in counter.items()]   #precentages\n",
    "\n",
    "    return tag_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fWzoEd7h_qRw",
   "metadata": {
    "id": "fWzoEd7h_qRw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag\t\tCount\t\tPercentage\n",
      "\n",
      "PROPN\t\t12946\t\t 6.3%\n",
      "PUNCT\t\t23679\t\t11.6%\n",
      "ADJ\t\t12477\t\t 6.1%\n",
      "NOUN\t\t34781\t\t17.0%\n",
      "VERB\t\t23081\t\t11.3%\n",
      "DET\t\t16285\t\t 8.0%\n",
      "ADP\t\t17638\t\t 8.6%\n",
      "AUX\t\t12343\t\t 6.0%\n",
      "PRON\t\t18577\t\t 9.1%\n",
      "PART\t\t5567\t\t 2.7%\n",
      "SCONJ\t\t3843\t\t 1.9%\n",
      "NUM\t\t3999\t\t 2.0%\n",
      "ADV\t\t10548\t\t 5.2%\n",
      "CCONJ\t\t6707\t\t 3.3%\n",
      "X\t\t847\t\t 0.4%\n",
      "INTJ\t\t688\t\t 0.3%\n",
      "SYM\t\t599\t\t 0.3%\n"
     ]
    }
   ],
   "source": [
    "print(\"Tag\\t\\tCount\\t\\tPercentage\\n\")\n",
    "\n",
    "for tag, count, percent in tag_percentage(UDPOS(split='train')):\n",
    "    print(f\"{tag}\\t\\t{count}\\t\\t{percent*100:4.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GKTQL0EsxSUU",
   "metadata": {
    "id": "GKTQL0EsxSUU"
   },
   "source": [
    "####${\\color{red}{Comments\\ 1.1}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "cross-feedback comment section\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gYHy3vSELfaN",
   "metadata": {
    "id": "gYHy3vSELfaN"
   },
   "source": [
    "### Subtask 2: The Model\n",
    "\n",
    "We start by creating a simple model and then make it more complex in later subtasks. The class `BiLSTMTagger` must subclass the `nn.Module` class of `PyTorch`. Fill the blank in the class by following the notes described below.\n",
    "1.   The input is a sequence of tokens, $X = \\{x_1, x_2,...,x_T\\}$.\n",
    "2.   Each token passes through  an embeddings layer, $e(X) = \\{e(x_1), e(x_2), ..., e(x_T)\\}$. Use `nn.Embedding` for the embedding layer and make sure to pass in the index of the pad token.\n",
    "3. Embedding is processed by forward and backward LSTMs from left to right and right to left.  The first input to the forward LSTM is $x_1$ and the first input to the backward LSTM is $x_T$. The hidden state of LSTMs is dependent on\n",
    "the hidden, $h$, and cell, $c$, states from the previous time-steps:\n",
    "$$h^{\\rightarrow}_t = \\text{LSTM}^{\\rightarrow}(e(x^{\\rightarrow}_t), h^{\\rightarrow}_{t-1}, c^{\\rightarrow}_{t-1})$$\n",
    "$$h^{\\leftarrow}_t=\\text{LSTM}^{\\leftarrow}(e(x^{\\leftarrow}_t), h^{\\leftarrow}_{t-1}, c^{\\leftarrow}_{t-1})$$\n",
    "4. The hidden, $h$, and cell, $c$ of each layer is passed to the next layer, where the $h_0$ and $c_0$, for each direction and layer, are initialized to a tensor full of zeros. Use `nn.LSTM` for LSTM cells. How can you make it bidirectional?\n",
    "5. Final hidden state is the concatenation of forward and backward hidden states from the final layer of the LSTM, $H = \\{h_1, h_2, ... h_T\\}$, where $h_1 = [h^{\\rightarrow}_1;h^{\\leftarrow}_T]$, $h_2 = [h^{\\rightarrow}_2;h^{\\leftarrow}_{T-1}]$. Use `nn.Linear` here.\n",
    "6. The last layer is linear layer $f$, which is used to make the prediction of which tag applies to this token, $\\hat{y}_t = f(h_t)$.\n",
    "7. Define a `nn.Dropout` layer to apply to the embeddings and the outputs of the final layer of the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "qE4GQE6NJ1k8",
   "metadata": {
    "id": "qE4GQE6NJ1k8"
   },
   "outputs": [],
   "source": [
    "class BiLSTMTagger(nn.Module):\n",
    "    def __init__(self, hyperparameters):\n",
    "      '''\n",
    "      hyperparameters: is a dictionary containing:\n",
    "                 input_dim: dimension of the input\n",
    "                 embedding_dim: dimension of the embedding layer\n",
    "                 lstm_hidden_dim: dimension of the hidden state of lstms\n",
    "                 output_dim: dimension of the output hidden layer\n",
    "                 n_layers: number of layers to stack\n",
    "                 bidirectional: is the lstm bi-directional\n",
    "                 dropout: probability for the drop out layer\n",
    "                 pad_idx: id of the pad token\n",
    "      '''\n",
    "      super().__init__()\n",
    "      #### your code ####\n",
    "      # Unpacking hyperparameters\n",
    "      input_dim = hyperparameters['input_dim']\n",
    "      embedding_dim = hyperparameters['embedding_dim']\n",
    "      lstm_hidden_dim = hyperparameters['lstm_hidden_dim']\n",
    "      output_dim = hyperparameters['output_dim']\n",
    "      n_layers = hyperparameters['n_layers']\n",
    "      bidirectional = hyperparameters['bidirectional']\n",
    "      dropout = hyperparameters['dropout']\n",
    "      pad_idx = hyperparameters['pad_idx']\n",
    "\n",
    "      # Embedding layer\n",
    "      self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "      # Bi-LSTM layer\n",
    "      #apply dropout if the number of layers is more than 1\n",
    "      self.lstm = nn.LSTM(embedding_dim, lstm_hidden_dim, num_layers=n_layers,\n",
    "                            bidirectional=bidirectional, dropout=(dropout if n_layers > 1 else 0))\n",
    "\n",
    "      # Fully connected layer\n",
    "      self.fc = nn.Linear(lstm_hidden_dim * 2 if bidirectional else lstm_hidden_dim, output_dim)\n",
    "\n",
    "      # Dropout layer\n",
    "      self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, text, debug=False): #(B,S)\n",
    "      '''\n",
    "      S: sentence len\n",
    "      B: batch size\n",
    "      E: embedding size\n",
    "      H: hidden size\n",
    "      O: output size\n",
    "      L: number of layers\n",
    "      '''\n",
    "      #### your code ####\n",
    "      # Embedding layer\n",
    "      embd = self.dropout(self.embedding(text))  # (S, B, E)\n",
    "\n",
    "      # LSTM layer\n",
    "      outputs, (hidden, cell) = self.lstm(embd)\n",
    "\n",
    "      # Apply dropout to the output of LSTM layer\n",
    "      outputs = self.dropout(outputs)\n",
    "\n",
    "      # Linear layer\n",
    "      predictions = self.fc(outputs)\n",
    "\n",
    "      if debug==True:\n",
    "        print(\"Input shape:\",text.shape)\n",
    "        print(\"Embedding shape:\",embd.shape)\n",
    "        print(\"LSTM output shape:\",outputs.shape)\n",
    "        print(\"LSTM hidden shape:\",hidden.shape)\n",
    "        print(\"LSTM cell shape:\",cell.shape)\n",
    "        print(\"Output shape:\",predictions.shape)\n",
    "\n",
    "      return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4OcQbD9LUkD5",
   "metadata": {
    "id": "4OcQbD9LUkD5"
   },
   "source": [
    "Response in plain text:\n",
    "1. Based on the notation defined in the forward function. What is the dimension of `outputs`, `hidden`, and `cell`?\n",
    "\n",
    "`outputs`: (sentence len, batch size, hidden size * 2)\n",
    "\n",
    "`hidden`: (num of layers * 2, batch size, hidden size)\n",
    "\n",
    "`cell`: (num of layers * 2, batch size, hidden size)\n",
    "\n",
    "(because the LSTM is bidirectional: 2 = num directions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ivB8Iv4yScVW",
   "metadata": {
    "id": "ivB8Iv4yScVW"
   },
   "outputs": [],
   "source": [
    "hyper_parameters={\n",
    "  'input_dim':  len(vocab),\n",
    "  'embedding_dim': 100,\n",
    "  'lstm_hidden_dim': 128,\n",
    "  'output_dim':len(ud_vocab),\n",
    "  'n_layers': 2 ,\n",
    "  'bidirectional':True,\n",
    "  'dropout': 0.25,\n",
    "  'pad_idx': vocab['<pad>']\n",
    "}\n",
    "model = BiLSTMTagger(hyper_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1XvNFfJBV7ya",
   "metadata": {
    "id": "1XvNFfJBV7ya"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 6])\n",
      "Embedding shape: torch.Size([2, 6, 100])\n",
      "LSTM output shape: torch.Size([2, 6, 256])\n",
      "LSTM hidden shape: torch.Size([4, 6, 128])\n",
      "LSTM cell shape: torch.Size([4, 6, 128])\n",
      "Output shape: torch.Size([2, 6, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 18])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=torch.tensor([[3, 9271, 35, 9097, 0, 1],\n",
    "                    [3, 9271, 35, 9097, 0, 1]])\n",
    "model(input,debug=True).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2XiJkG-NfrDV",
   "metadata": {
    "id": "2XiJkG-NfrDV"
   },
   "source": [
    "Weights of the network are initialized randomly, so let's make a more systematic initialization to help us with the optimization. For example,  Xavier Initialization creates weights such that the variance of the activations is the same across every layer. This constant variance helps prevent the gradient from exploding or vanishing. However, it does not apply to bias terms.\n",
    "\n",
    "Create a function that uses Xavier Initialization to initialize the weights of the network, for biases use a normal distribution with a mean of 0 and a standard deviation of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "PB78pCHpa758",
   "metadata": {
    "id": "PB78pCHpa758"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMTagger(\n",
       "  (embedding): Embedding(9875, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, num_layers=2, dropout=0.25, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=18, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "  ### you code ###\n",
    "  if isinstance(m, nn.LSTM):\n",
    "      for name, param in m.named_parameters():\n",
    "          if 'weight_ih' in name:\n",
    "              nn.init.xavier_uniform_(param.data)\n",
    "          elif 'weight_hh' in name:\n",
    "              nn.init.orthogonal_(param.data)\n",
    "          elif 'bias' in name:\n",
    "              nn.init.constant_(param.data, 0)\n",
    "  elif isinstance(m, nn.Linear):\n",
    "      nn.init.xavier_uniform_(m.weight.data)\n",
    "      nn.init.normal_(m.bias.data, mean=0, std=0.1)\n",
    "  elif isinstance(m, nn.Embedding):\n",
    "      nn.init.uniform_(m.weight.data, -0.1, 0.1)\n",
    "  ### your code ###\n",
    "model.apply(init_weights)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sdPx1mSOgy0V",
   "metadata": {
    "id": "sdPx1mSOgy0V"
   },
   "source": [
    "Let's count the number of trainable parameters in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "P5738nU2ew_O",
   "metadata": {
    "id": "P5738nU2ew_O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trainable parameters: 1622910\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "  ### your code ###\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "  ### your code ###\n",
    "\n",
    "print(\"number of trainable parameters:\", count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91uNA-vnyoUW",
   "metadata": {
    "id": "91uNA-vnyoUW"
   },
   "source": [
    "####${\\color{red}{Comments\\ 1.2}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "cross-feedback comment section\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-lVg08iTd0XN",
   "metadata": {
    "id": "-lVg08iTd0XN"
   },
   "source": [
    "### Subtask 3: Training\n",
    "\n",
    "We start by defining a loss function and an optimizer.\n",
    "\n",
    "\n",
    "*   **optimizer:** We use Adam with the learning rate=0.0001.\n",
    "*   **loss:** We use cross-entropy loss.\n",
    "\n",
    "Even though we have no `<unk>` tokens within our tag vocab, we still have `<pad>` tokens to create batches of the same size. However, we do not want to calculate loss on those tokens, so make sure you define your loss function in such a way that ignores the `<pad>` tokens.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8LEyNeKhmBvK",
   "metadata": {
    "id": "8LEyNeKhmBvK"
   },
   "outputs": [],
   "source": [
    "### your code ###\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# The CrossEntropyLoss will ignore the <pad> tokens in the loss calculation\n",
    "pad_idx = hyper_parameters['pad_idx']\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "### your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95Cf7ZcVgLHK",
   "metadata": {
    "id": "95Cf7ZcVgLHK"
   },
   "source": [
    "Watching the loss go down as you train a model is a good indication of the correct training procedure, but does not tell us how well we are doing on a given task.\n",
    "To this end, we also implement a categorical accuracy measure to keep track of how well our model is doing on a given task.\n",
    "Same as before: we don't want to calculate accuracy over the `<pad>` tokens as we aren't interested in predicting them.\n",
    "Implement the function `categorical_acc` to compare the prediction of non-pad tokens with labels count the correct ones and calculate the accuracy over a single batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "J5OpDKuBitk1",
   "metadata": {
    "id": "J5OpDKuBitk1"
   },
   "outputs": [],
   "source": [
    "def categorical_acc(preds, gt, pad_idx):\n",
    "    \"\"\"\n",
    "    Returns categorical accuracy per batch\n",
    "    preds: predictions from the model [batch size, sentence length, output dim] or [sentence length, output dim]\n",
    "    gt: ground truth labels [batch size, sentence length] or [sentence length]\n",
    "    pad_idx: index of the pad token\n",
    "    \"\"\"\n",
    "    ### your code ####\n",
    "    # Add a batch dimension if it's not present\n",
    "    if preds.dim() == 2:\n",
    "        preds = preds.unsqueeze(0)\n",
    "    if gt.dim() == 1:\n",
    "        gt = gt.unsqueeze(0)\n",
    "\n",
    "    # Get the index of the max probability\n",
    "    max_preds = preds.argmax(dim=2, keepdim=True)  # [batch size, sentence length, 1]\n",
    "    \n",
    "    # Flatten both max_preds and gt to compare element-wise; ignore <pad> tokens\n",
    "    non_pad_elements = (gt != pad_idx).nonzero(as_tuple=True)\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(gt[non_pad_elements])\n",
    "\n",
    "    # Calculate accuracy\n",
    "    return correct.sum() / torch.FloatTensor([gt[non_pad_elements].shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "WANOhA56kjY_",
   "metadata": {
    "id": "WANOhA56kjY_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6667])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummpy_input=torch.tensor([\n",
    "    [0.9,0,0,0],\n",
    "    [0.1,0.9,0,0],\n",
    "    [0.1,0,0,0.9],\n",
    "    [0.9,0.1,0,0],\n",
    "    [0.1,0.8,0,0]\n",
    "\n",
    "])\n",
    "categorical_acc(dummpy_input, torch.tensor([0,2,3,0,1]), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y_wngIs7jFrT",
   "metadata": {
    "id": "y_wngIs7jFrT"
   },
   "source": [
    "Define the `train` model that performs one epoch of training. You can refer to the Tutorial 2 of the course to get a sample workflow. The only difference to the tutorial is that we keep track of the batch-wise accuracy as well as the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "kyMs0FJNfGCp",
   "metadata": {
    "id": "kyMs0FJNfGCp"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_function, pad_idx):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    for length_dataloader, (text, tags) in enumerate(dataloader):\n",
    "        #### your code ####\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(text)\n",
    "\n",
    "        # Reshape predictions and tags for calculating loss and accuracy\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "\n",
    "        # Compute the loss and accuracy, ignoring pad tokens\n",
    "        loss = loss_function(predictions, tags)\n",
    "        acc = categorical_acc(predictions, tags, pad_idx)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss and accuracy\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        #### your code ####\n",
    "\n",
    "    end_time= time.time() - epoch_start_time\n",
    "\n",
    "    return epoch_loss / length_dataloader, epoch_acc / length_dataloader, end_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W0ytUn7vkdcR",
   "metadata": {
    "id": "W0ytUn7vkdcR"
   },
   "source": [
    "It is not enough to only look at the training loss and accuracy, since with more training, we can always do better on the training set, but lose the generalizability to unseen data, a phenomenon known as **overfitting**. Therefore, it is important to check the loss and accuracy on the validation set after each epoch and stop before  overfitting occurs. Moreover, we can use the validation metric as an indication of which checkpoint of our model is the best.\n",
    "\n",
    "Define an `evaluate` function that runs once through the validation set and computes loss and accuracy. **Note:** You should not be updating gradients here and your model should be in evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0CKzEqyAfktd",
   "metadata": {
    "id": "0CKzEqyAfktd"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, loss_function, pad_idx):\n",
    "\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "\n",
    "    ### your code ###\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for length_dataloader, (text, tags) in enumerate(dataloader):\n",
    "            # Forward pass\n",
    "            predictions = model(text)\n",
    "\n",
    "            # Reshape predictions and tags for calculating loss and accuracy\n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "\n",
    "            # Compute the loss and accuracy, ignoring pad tokens\n",
    "            loss = loss_function(predictions, tags)\n",
    "            acc = categorical_acc(predictions, tags, pad_idx)\n",
    "\n",
    "            # Accumulate loss and accuracy\n",
    "            val_loss += loss.item()\n",
    "            val_acc += acc.item()\n",
    "    ### your code ###\n",
    "\n",
    "    return val_loss / length_dataloader, val_acc / length_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3AZJidLFnOUW",
   "metadata": {
    "id": "3AZJidLFnOUW"
   },
   "source": [
    "Let's use the functions defined so far and train our model for `30` epochs. We suggest using GPU for this task, as it is quite slow on the CPU. Run the training loop for the given number of epochs and calculate the validation metric at the end of each epoch. Based on the validation loss, save the best checkpoint of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "NblN-U0inVYc",
   "metadata": {
    "id": "NblN-U0inVYc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combining.py:333: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 39s\n",
      "\tTrain Loss: 2.743 | Train Acc: 14.97%\n",
      "\t Validation Loss: 2.694 |  Validation Acc: 17.83%\n",
      "Epoch: 02 | Epoch Time: 0m 36s\n",
      "\tTrain Loss: 2.537 | Train Acc: 17.64%\n",
      "\t Validation Loss: 2.630 |  Validation Acc: 22.47%\n",
      "Epoch: 03 | Epoch Time: 0m 37s\n",
      "\tTrain Loss: 2.418 | Train Acc: 23.81%\n",
      "\t Validation Loss: 2.374 |  Validation Acc: 31.40%\n",
      "Epoch: 04 | Epoch Time: 0m 34s\n",
      "\tTrain Loss: 2.100 | Train Acc: 35.18%\n",
      "\t Validation Loss: 1.936 |  Validation Acc: 46.17%\n",
      "Epoch: 05 | Epoch Time: 0m 33s\n",
      "\tTrain Loss: 1.702 | Train Acc: 48.42%\n",
      "\t Validation Loss: 1.519 |  Validation Acc: 60.43%\n",
      "Epoch: 06 | Epoch Time: 0m 33s\n",
      "\tTrain Loss: 1.360 | Train Acc: 59.11%\n",
      "\t Validation Loss: 1.232 |  Validation Acc: 66.04%\n",
      "Epoch: 07 | Epoch Time: 0m 33s\n",
      "\tTrain Loss: 1.119 | Train Acc: 66.48%\n",
      "\t Validation Loss: 1.017 |  Validation Acc: 75.55%\n",
      "Epoch: 08 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.926 | Train Acc: 73.33%\n",
      "\t Validation Loss: 0.839 |  Validation Acc: 81.87%\n",
      "Epoch: 09 | Epoch Time: 0m 38s\n",
      "\tTrain Loss: 0.775 | Train Acc: 77.70%\n",
      "\t Validation Loss: 0.722 |  Validation Acc: 84.24%\n",
      "Epoch: 10 | Epoch Time: 0m 32s\n",
      "\tTrain Loss: 0.668 | Train Acc: 80.63%\n",
      "\t Validation Loss: 0.648 |  Validation Acc: 86.20%\n",
      "Epoch: 11 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.594 | Train Acc: 82.99%\n",
      "\t Validation Loss: 0.601 |  Validation Acc: 87.94%\n",
      "Epoch: 12 | Epoch Time: 0m 33s\n",
      "\tTrain Loss: 0.540 | Train Acc: 84.74%\n",
      "\t Validation Loss: 0.568 |  Validation Acc: 88.64%\n",
      "Epoch: 13 | Epoch Time: 0m 40s\n",
      "\tTrain Loss: 0.499 | Train Acc: 85.82%\n",
      "\t Validation Loss: 0.547 |  Validation Acc: 89.02%\n",
      "Epoch: 14 | Epoch Time: 0m 36s\n",
      "\tTrain Loss: 0.471 | Train Acc: 86.47%\n",
      "\t Validation Loss: 0.530 |  Validation Acc: 89.36%\n",
      "Epoch: 15 | Epoch Time: 0m 36s\n",
      "\tTrain Loss: 0.449 | Train Acc: 87.00%\n",
      "\t Validation Loss: 0.518 |  Validation Acc: 89.58%\n",
      "Epoch: 16 | Epoch Time: 0m 32s\n",
      "\tTrain Loss: 0.431 | Train Acc: 87.45%\n",
      "\t Validation Loss: 0.511 |  Validation Acc: 89.74%\n",
      "Epoch: 17 | Epoch Time: 0m 37s\n",
      "\tTrain Loss: 0.417 | Train Acc: 87.59%\n",
      "\t Validation Loss: 0.511 |  Validation Acc: 89.64%\n",
      "Epoch: 18 | Epoch Time: 0m 38s\n",
      "\tTrain Loss: 0.408 | Train Acc: 87.90%\n",
      "\t Validation Loss: 0.500 |  Validation Acc: 89.94%\n",
      "Epoch: 19 | Epoch Time: 0m 34s\n",
      "\tTrain Loss: 0.398 | Train Acc: 88.08%\n",
      "\t Validation Loss: 0.499 |  Validation Acc: 89.81%\n",
      "Epoch: 20 | Epoch Time: 0m 32s\n",
      "\tTrain Loss: 0.391 | Train Acc: 88.22%\n",
      "\t Validation Loss: 0.496 |  Validation Acc: 89.86%\n",
      "Epoch: 21 | Epoch Time: 0m 33s\n",
      "\tTrain Loss: 0.386 | Train Acc: 88.25%\n",
      "\t Validation Loss: 0.494 |  Validation Acc: 89.72%\n",
      "Epoch: 22 | Epoch Time: 0m 33s\n",
      "\tTrain Loss: 0.378 | Train Acc: 88.41%\n",
      "\t Validation Loss: 0.495 |  Validation Acc: 89.72%\n",
      "Epoch: 23 | Epoch Time: 0m 33s\n",
      "\tTrain Loss: 0.373 | Train Acc: 88.52%\n",
      "\t Validation Loss: 0.490 |  Validation Acc: 89.81%\n",
      "Epoch: 24 | Epoch Time: 0m 33s\n",
      "\tTrain Loss: 0.369 | Train Acc: 88.53%\n",
      "\t Validation Loss: 0.485 |  Validation Acc: 89.86%\n",
      "Epoch: 25 | Epoch Time: 0m 33s\n",
      "\tTrain Loss: 0.365 | Train Acc: 88.62%\n",
      "\t Validation Loss: 0.487 |  Validation Acc: 89.77%\n",
      "Epoch: 26 | Epoch Time: 0m 32s\n",
      "\tTrain Loss: 0.361 | Train Acc: 88.68%\n",
      "\t Validation Loss: 0.481 |  Validation Acc: 90.06%\n",
      "Epoch: 27 | Epoch Time: 0m 34s\n",
      "\tTrain Loss: 0.358 | Train Acc: 88.71%\n",
      "\t Validation Loss: 0.486 |  Validation Acc: 89.85%\n",
      "Epoch: 28 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.355 | Train Acc: 88.78%\n",
      "\t Validation Loss: 0.483 |  Validation Acc: 89.94%\n",
      "Epoch: 29 | Epoch Time: 0m 32s\n",
      "\tTrain Loss: 0.352 | Train Acc: 88.75%\n",
      "\t Validation Loss: 0.479 |  Validation Acc: 90.05%\n",
      "Epoch: 30 | Epoch Time: 0m 33s\n",
      "\tTrain Loss: 0.349 | Train Acc: 88.80%\n",
      "\t Validation Loss: 0.479 |  Validation Acc: 89.89%\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tnrange\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### your code ###\n",
    "    train_loss, train_acc, epoch_time = train(model, train_dataloader, optimizer, loss_function, pad_idx)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_dataloader, loss_function, pad_idx)\n",
    "\n",
    "    # Save the model if the validation loss is the best we've seen so far.\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best-model.pt')\n",
    "    ### your code ###\n",
    "    \n",
    "    elapsed_mins = int(epoch_time / 60)\n",
    "    elapsed_secs = int(epoch_time - (elapsed_mins * 60))\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {elapsed_mins}m {elapsed_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Validation Loss: {valid_loss:.3f} |  Validation Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dXTYFEbHzNL",
   "metadata": {
    "id": "7dXTYFEbHzNL"
   },
   "source": [
    "Question:\n",
    "\n",
    "1. Does overfitting occur? If so, after which epochs?\n",
    "\n",
    "2. How do you detect overfitting?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9qSbr8CrH9hD",
   "metadata": {
    "id": "9qSbr8CrH9hD"
   },
   "source": [
    "**Answer:**\n",
    "```\n",
    "1. Does overfitting occur? If so, after which epochs?\n",
    "\n",
    "    - No (due to the reasons/observations explained below).\n",
    "\n",
    "2. How do you detect overfitting?\n",
    "\n",
    "    - Check if the training loss decreases but the validation loss increases (which is not the case here)\n",
    "    - Check if high training accuracy but low validation accuracy (also not the case: val acc is even a little higher in most cases)\n",
    "\n",
    "    -> Both training and validation loss decrease and accuracies increase over epochs, which is a good sign that no overfitting occurs and the model learns effectively. Also, training and validation accuracy are quite close to each other, and their loss values are converging, which further suggests that the model is not overfitting significantly.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GmqNesqiMISb",
   "metadata": {
    "id": "GmqNesqiMISb"
   },
   "source": [
    "Let's see how well our model is doing on the test set. Load the best checkpoint and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "SgCFqby0m8sf",
   "metadata": {
    "id": "SgCFqby0m8sf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.466 | Test Acc: 89.93%\n"
     ]
    }
   ],
   "source": [
    "#### you code ####\n",
    "# Load best saved model checkpoint\n",
    "model.load_state_dict(torch.load('best-model.pt'))\n",
    "#### you code ####\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = evaluate(model, test_dataloader, loss_function, pad_idx)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tMIDBeSFyqJr",
   "metadata": {
    "id": "tMIDBeSFyqJr"
   },
   "source": [
    "####${\\color{red}{Comments\\ 1.3}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "cross-feedback comment section\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dPfzmVGMeSO",
   "metadata": {
    "id": "7dPfzmVGMeSO"
   },
   "source": [
    "### Subtask 4: Inference\n",
    "\n",
    "Let's use the model we trained to tag some actual sentences. We have the preprocessing pipeline ready from Subtask 1, now we need to map the predictions back to label texts for each token.\n",
    "\n",
    "Implement the `tag_sequence` function that takes a model and a sentence as input and generates POS tags. Keep in mind that you need to divide the sentence into tokens first. For this purpose, we just split each sentence on whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "Xe7_ROCyEslD",
   "metadata": {
    "id": "Xe7_ROCyEslD"
   },
   "outputs": [],
   "source": [
    "def tag_sentence(model, sentence):\n",
    "    ### your code ###\n",
    "    # Tokenize\n",
    "    tokens = sentence.split()\n",
    "\n",
    "    # Convert tokens to ids\n",
    "    token_idx = [vocab[token] if token in vocab else vocab[\"<unk>\"] for token in tokens]\n",
    "\n",
    "    # Convert to a tensor and add an extra dimension for batch\n",
    "    token_tensor = torch.LongTensor(token_idx).unsqueeze(-1).to(device) #add extra dimension to match expected input dimensions\n",
    "\n",
    "    # Predict with the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(token_tensor) # make predictions on the sentence\n",
    "\n",
    "    # Convert predictions to tag indices\n",
    "    #find index of max value, then remove unnecessary extra dimension, then move tensor to CPU to convert it to numpy array\n",
    "    predicted_idx = predictions.argmax(-1).squeeze(-1).cpu().numpy()   \n",
    "\n",
    "    # Get the mapping from indices to tags\n",
    "    idx_to_tags = ud_vocab.get_itos() \n",
    "\n",
    "    # Convert indices to tags\n",
    "    predicted_tags = [idx_to_tags[idx] for idx in predicted_idx] # get the tags\n",
    "\n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "JtiR75PFRR61",
   "metadata": {
    "id": "JtiR75PFRR61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  What if Google Morphed Into GoogleOS ?\n",
      "Predicted Tags:  ['PRON', 'SCONJ', 'PROPN', 'PROPN', 'PROPN', 'NUM', 'PUNCT']\n",
      "True Tags:  ['PRON', 'SCONJ', 'PROPN', 'VERB', 'ADP', 'PROPN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "text=\" \".join(list(UDPOS(split='test'))[0][0])\n",
    "label= list(UDPOS(split='test'))[0][1]\n",
    "predicted_tag=tag_sentence(model, text)\n",
    "print(\"Text: \", text)\n",
    "print(\"Predicted Tags: \", predicted_tag)\n",
    "print(\"True Tags: \", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bPriv78yuyQ",
   "metadata": {
    "id": "7bPriv78yuyQ"
   },
   "source": [
    "####${\\color{red}{Comments\\ 1.4}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "cross-feedback comment section\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X4n7Xi4TT_Ww",
   "metadata": {
    "id": "X4n7Xi4TT_Ww"
   },
   "source": [
    "## **Task 2: Theoretical Questions** (0.5+1.5+1+3=6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QbQJ3baXUHkQ",
   "metadata": {
    "id": "QbQJ3baXUHkQ"
   },
   "source": [
    "### Subtask 1:\n",
    "In beam search, if you increase the beam width, what will happen to a) the runtime and memory and b) the quality of results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ei5A-D_djZup",
   "metadata": {
    "id": "Ei5A-D_djZup"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "\n",
    "```\n",
    "a) Runtime and Memory: Increasing beam width leads to longer runtime and higher memory usage, as the algorithm evaluates and stores more candidate sequences: the number of paths considered at each step of the search increases and the algorithm needs to store a larger number of partial sequences.\n",
    "\n",
    "b) Quality of Results: A larger beam width generally improves result quality by exploring more sequences and making it less likely to miss the optimal or a high-quality sequence. But there's a diminishing return on quality improvement beyond a certain width as the increase in quality becomes marginal compared to the additional computational cost, and it could introduce noise.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RuzX2q7TywyW",
   "metadata": {
    "id": "RuzX2q7TywyW"
   },
   "source": [
    "####${\\color{red}{Comments\\ 2.1}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "cross-feedback comment section\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N7KlRPnhknbl",
   "metadata": {
    "id": "N7KlRPnhknbl"
   },
   "source": [
    "### Subtask 2:\n",
    "Except for beam search, there are other ways to create a more coherent output for generation tasks, one of which is adding a temperature to the softmax over the vocabulary. Temperature is a hyperparameter that is applied to the input of a softmax to affect the final probabilities. All values in the input are divided by the temperature before going through the softmax. What do you think will happen in these cases:\n",
    "\n",
    "1. A low temperature - below 1\n",
    "2. A high temperature - above 1\n",
    "3. Really small temperature - temperature $→$ 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uxuh5LOFnF3D",
   "metadata": {
    "id": "uxuh5LOFnF3D"
   },
   "source": [
    "**Answer:**\n",
    "```\n",
    "Low Temperature (below 1): Concentrates probability on the highest-scoring words, leading to more confident and less diverse choices, as it reduces the chances for less likely words.\n",
    "\n",
    "High Temperature (above 1): Results in a flatter output distribution by smoothing the probability, increasing diversity and randomness as it gives lower-scoring words a higher chance of being chosen.\n",
    "\n",
    "Really Small Temperature (approaching 0): Maximizes the probability of the top word, causing the model to almost always pick the most probable word and reducing randomness to nearly zero.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GmW4NNb4yyZF",
   "metadata": {
    "id": "GmW4NNb4yyZF"
   },
   "source": [
    "####${\\color{red}{Comments\\ 2.2}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "cross-feedback comment section\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tM2DmNOwod4r",
   "metadata": {
    "id": "tM2DmNOwod4r"
   },
   "source": [
    "### Subtask 3:\n",
    "Explain what the “bottleneck” of an encoder-decoder RNN is and how attention provides a way to get around this bottleneck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DNJ3f_MtdzrM",
   "metadata": {
    "id": "DNJ3f_MtdzrM"
   },
   "source": [
    "**Answer:**\n",
    "```\n",
    "The \"bottleneck\" happens because the entire input sequence is compressed into a fixed-length context vector in an RNN, which makes it difficult to keep all relevant information for long sequences. Attention overcomes this by as it lets the decoder selectively focus on various parts of the input sequence at each step of the output generation. It thus creates a dynamic, context-specific representation and avoids the limitations of single, fixed-length vectors.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JFUHVF40y0j-",
   "metadata": {
    "id": "JFUHVF40y0j-"
   },
   "source": [
    "####${\\color{red}{Comments\\ 2.3}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "cross-feedback comment section\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HaHhdLdJehL3",
   "metadata": {
    "id": "HaHhdLdJehL3"
   },
   "source": [
    "### Subtask 4:\n",
    "As mentioned, there are various way to remedy the repetitiveness and incoherence of generation outputs. One of the widely used methods is Nucleus sampling described the paper \"[The Curious Case of Neural Text DeGeneration](https://arxiv.org/pdf/1904.09751.pdf)\". Read the model section and introduction of the paper and use it as reference to answer the following questions:\n",
    "\n",
    "1. Describe top-k sampling in your own words, no need for mathematical notation.\n",
    "2. Describe Nucleus sampling in your own words, there is not need for mathematical notation.\n",
    "3. Why is beam search not a good strategy for human-like text generation and why don't these methods suffer from the problem of the beam search?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9Ojtbn1kgaYE",
   "metadata": {
    "id": "9Ojtbn1kgaYE"
   },
   "source": [
    "**Answer:**\n",
    "```\n",
    "1. Top-k sampling is a method in text generation where you pick from the top k most likely words at each step. The challenge is to to generate diverse but coherent text. The top k words can change based on the shape of the probability distribution at each time step. It usually gives better results than other methods like beam search. The tricky part is picking the right k - small k may lead to bland or generic text, while a large k may include inappropriate candidates, affecting the quality of the generated text\n",
    "\n",
    "2. Nucleus sampling is another way to generate text. It picks from a changing set of words, depending on how likely they are to come next, up to a certain probability (the p value). This method aims to address the limitations of top-k sampling by dynamically adjusting the size of the sampling set based on the shape of the probability distribution at each time step. This way, it can avoid some common issues like repeating stuff or using too many plain words, making the text sound more natural and interesting\n",
    "\n",
    "3. Using likelihood as the main goal for training language models can be smart, but when it comes to actually creating text, like with beam search, you can end up with stuff that doesn't sound quite right or repeats a lot.  This is counterintuitive, as one would expect good models to assign higher probability to more human-like, grammatical text. However, the text generated by beam search tends to be generic and less interesting, as it assigns high probability to generic and repetitive text. That's why methods like top-k or nucleus sampling are handy as they keep adjusting what words they choose from as they write, helping the text stay interesting and varied.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0wU67Iqpy2rg",
   "metadata": {
    "id": "0wU67Iqpy2rg"
   },
   "source": [
    "####${\\color{red}{Comments\\ 2.4}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "cross-feedback comment section\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IZl0-MMY6MWs",
   "metadata": {
    "id": "IZl0-MMY6MWs"
   },
   "source": [
    "## **Task 3: Scaled Dot-Product Attention** (4+1=5 points)\n",
    "In class, you learned about attention and Transformers as described in the 2017 paper\n",
    "[Attention Is All You Need](https://arxiv.org/abs/1706.03762).\n",
    "The base of the attention module is a scaled dot product with Queries, Keys, and Values.\n",
    "In this task, you will implement a simplified version of scaled dot-product attention and inspired by the translation task, aim to replicate word alignment between English and French.\n",
    "You will not be training the embedding from scratch, we provide you with pre-trained embedding for both languages.\n",
    "However, you need to know the details of scaled dot product attention, which mainly consists of two matrix multiplications and a softmax scaling.\n",
    "Refer to Figure 2 of the [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper.\n",
    "\n",
    "The inputs of the attention module are Queries, Keys, and Values. Mathematically, attention is defined as follows:\n",
    "\n",
    "$$\n",
    "\\large \\mathrm{Attention}\\left(Q, K, V\\right) = \\mathrm{softmax}\\left(\\frac{QK^{\\top}}{\\sqrt{d_k}}\\right)V\n",
    "$$\n",
    "\n",
    "\n",
    "*   $Q$, $K$, and $V$ are the Queries, Keys, and Values matrices.\n",
    "* $d_k$ is the dimension of the Keys (in practice dimensions of all matrices are the same).\n",
    "*   $QK^{\\top}$ is a measure of the similarity between the Queries and the Keys\n",
    "* softmax transforms the similarity into weights.\n",
    "* Weights multiplied by the Values are the output of the attention, defining how much importance should be given to each token of the input.\n",
    "\n",
    "In the case of self-attention, both Queries and Keys come from the encoder, however, for cross attention between encoder and decoder, decoder states are used as the queries while encoder states are the Keys and Values.\n",
    "In our case, we need the cross attention between one language to another to find the correct alignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "gOP3Fa8IfkMK",
   "metadata": {
    "id": "gOP3Fa8IfkMK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from matplotlib) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sandrafriebolin/miniconda3/envs/nlp-transformers/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tB6RD3wssHe9",
   "metadata": {
    "id": "tB6RD3wssHe9",
    "ExecuteTime": {
     "end_time": "2023-11-24T20:49:52.013841Z",
     "start_time": "2023-11-24T20:49:51.650360Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#load the dictionaries (dictionary of words to ids)\n",
    "with open(\"./word2int_en.pkl\", \"rb\") as f:\n",
    "    en_dict = pickle.load(f)\n",
    "\n",
    "with open(\"./word2int_fr.pkl\", \"rb\") as f:\n",
    "    fr_dict = pickle.load(f)\n",
    "\n",
    "# load word embeddings (dictionary of token ids to embeddings)\n",
    "en_embeddings = np.load(\"./embeddings_en.npz\")[\"embeddings\"]\n",
    "fr_embeddings = np.load(\"./embeddings_fr.npz\")[\"embeddings\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7VYjN1xHsbYj",
   "metadata": {
    "id": "7VYjN1xHsbYj"
   },
   "source": [
    "### Subtask 1: Attention Weights\n",
    "Fill the blanks in `tokenize` to tokenize a sentence and convert it to ids and `embed` function to create an embedding of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cwS_M10nwOBH",
   "metadata": {
    "id": "cwS_M10nwOBH",
    "ExecuteTime": {
     "end_time": "2023-11-24T20:49:52.021657Z",
     "start_time": "2023-11-24T20:49:52.015365Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(sentence, token_mapping):\n",
    "   # we stick to simple blank space tokenization\n",
    "   tokenized = []\n",
    "   for word in sentence.lower().split(\" \"):\n",
    "       \n",
    "       if word in token_mapping:\n",
    "           token = token_mapping[word]\n",
    "       else:\n",
    "           token = -1\n",
    "       tokenized.append(token)\n",
    "\n",
    "   return tokenized\n",
    "\n",
    "def embed(tokens, embeddings):\n",
    "    \"\"\" get the embedding for the tokens in a sentence stacked in a simple matrix (sequence length, embedding size)\n",
    "        tokens: tokenized sentence\n",
    "        embeddings: dictionary of token to embeddings.\n",
    "    \"\"\"\n",
    "    embed_size = embeddings.shape[1]\n",
    "    embed_list = []\n",
    "    for token in tokens:\n",
    "        if token == -1:\n",
    "            embed_list.append(np.zeros(embed_size))\n",
    "        else:\n",
    "            embed_list.append(embeddings[token])\n",
    "        output = np.stack(embed_list)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dkAulXarueT_",
   "metadata": {
    "id": "dkAulXarueT_",
    "ExecuteTime": {
     "end_time": "2023-11-24T20:49:52.423056Z",
     "start_time": "2023-11-24T20:49:52.400953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized english: [59, 40, 9355, 6, 158, -1]\n",
      "embedding english: (6, 300)\n",
      "Tokenized french: [21, 73, 192, 16, 8652, -1, 558, -1]\n",
      "embedding french: (8, 300)\n"
     ]
    }
   ],
   "source": [
    "sentence_en = \"there were clouds in my coffeeeeee.\"\n",
    "tokenized_en = tokenize(sentence_en, en_dict)\n",
    "embedded_en = embed(tokenized_en, en_embeddings)\n",
    "print(\"Tokenized english:\",tokenized_en)\n",
    "print(\"embedding english:\",embedded_en.shape)\n",
    "\n",
    "sentence_fr = \"il y avait des nuages ​​dans mon ccafé.\"\n",
    "tokenized_fr = tokenize(sentence_fr, fr_dict)\n",
    "embedded_fr = embed(tokenized_fr, fr_embeddings)\n",
    "print(\"Tokenized french:\",tokenized_fr)\n",
    "print(\"embedding french:\",embedded_fr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WJ58FCMpsHJP",
   "metadata": {
    "id": "WJ58FCMpsHJP"
   },
   "source": [
    "\n",
    "Implement the `softmax` function with `Numpy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caOjXfbxon9h",
   "metadata": {
    "id": "caOjXfbxon9h",
    "ExecuteTime": {
     "end_time": "2023-11-24T20:49:53.577675Z",
     "start_time": "2023-11-24T20:49:53.571601Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x, axis=0):\n",
    "    \"\"\"\n",
    "    x: input matrix\n",
    "    axis: defines which axis to compute the softmax over 0 for rows and 1 for columns\n",
    "        axis=0 calculates softmax across rows which means each column sums to 1\n",
    "        axis=1 calculates softmax across columns which means each row sums to 1\n",
    "    \"\"\"\n",
    "\n",
    "    # softmax(x_i) = e^{x_i} / \\sum{j=1}^{K}e^{x_j}\n",
    "    dividend = np.exp(x)\n",
    "    divisor = np.sum(np.exp(x), axis=axis, keepdims=True)\n",
    "\n",
    "    softmax_x = dividend / divisor\n",
    "\n",
    "    return softmax_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "kCbjmG49p-v0",
   "metadata": {
    "id": "kCbjmG49p-v0",
    "ExecuteTime": {
     "end_time": "2023-11-24T20:49:54.080356Z",
     "start_time": "2023-11-24T20:49:54.062747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w=softmax(np.array([[1,3,4,1], [24,3,2,3]]),axis=0)\n",
    "w.sum(axis=0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oNqtNPB9orLr",
   "metadata": {
    "id": "oNqtNPB9orLr"
   },
   "source": [
    "Use the `softmax` function to calculate the weights.\n",
    "$$ \\mathrm{softmax}\\left(\\frac{QK^{\\top}}{\\sqrt{d_k}}\\right)$$\n",
    "Assume the queries and keys are 2D matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ysRdVCnP7Qir",
   "metadata": {
    "id": "ysRdVCnP7Qir",
    "ExecuteTime": {
     "end_time": "2023-11-24T20:49:55.239954Z",
     "start_time": "2023-11-24T20:49:55.235353Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_weights(queries, keys):\n",
    "    \"\"\"\n",
    "    queries: queries matrix\n",
    "    keys: keys matrix\n",
    "    \"\"\"\n",
    "    d_k = keys.shape[1]\n",
    "    dot_product = np.dot(queries, keys.T)\n",
    "    weights = softmax(dot_product / np.sqrt(d_k), axis=1)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "LVYGelEsqsoo",
   "metadata": {
    "id": "LVYGelEsqsoo",
    "ExecuteTime": {
     "end_time": "2023-11-24T20:49:55.940074Z",
     "start_time": "2023-11-24T20:49:55.934558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19557032 0.80442968]\n",
      " [0.19557032 0.80442968]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights=calc_weights(np.array([[1,3],[1,3]]),np.array([[0,3],[2,3]]))\n",
    "print(weights)\n",
    "weights.sum(axis=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16V5yFAew1Hx",
   "metadata": {
    "id": "16V5yFAew1Hx"
   },
   "source": [
    "Use the `calcu_weights` to compute the attention matrix between two sentences from English and French and visualize the weights to check for alignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "miW865arw9Fv",
   "metadata": {
    "id": "miW865arw9Fv",
    "ExecuteTime": {
     "end_time": "2023-11-24T20:49:57.385643Z",
     "start_time": "2023-11-24T20:49:57.213179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2) -> nuages, clouds, prob: 0.0937\n",
      "(7, 5) -> café, coffee, prob: 0.0932\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 500x500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_en = \"there were clouds in my coffee and unicorns in the sky.\"\n",
    "tokenized_en = tokenize(sentence_en, en_dict)\n",
    "embedded_en = embed(tokenized_en, en_embeddings)\n",
    "\n",
    "sentence_fr = \"il y avait des nuages ​​dans mon café et des licornes dans le ciel.\"\n",
    "tokenized_fr = tokenize(sentence_fr, fr_dict)\n",
    "embedded_fr = embed(tokenized_fr, fr_embeddings)\n",
    "\n",
    "alignment = calc_weights(embedded_fr, embedded_en)\n",
    "# visualize weights\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.imshow(alignment,cmap='gray')\n",
    "ax.xaxis.tick_top()\n",
    "ax.set_xticks(np.arange(alignment.shape[1]))\n",
    "ax.set_xticklabels(sentence_en.split(\" \"), rotation=90, size=12);\n",
    "ax.set_yticks(np.arange(alignment.shape[0]));\n",
    "ax.set_yticklabels(sentence_fr.split(\" \"), size=12);\n",
    "\n",
    "\n",
    "### your code to compute the top-2 ###\n",
    "top_n_words = 2\n",
    "\n",
    "# Flatten the alignment array and get the indices of the top-n words\n",
    "flat_alignment = alignment.flatten()\n",
    "top_indices = np.argsort(flat_alignment)[-top_n_words:][::-1]\n",
    "\n",
    "# Splitting sentences into words\n",
    "english_words = sentence_en.split()\n",
    "french_words = sentence_fr.split()\n",
    "\n",
    "# Iterate through the top indices to find the corresponding words and their probabilities\n",
    "for idx in top_indices:\n",
    "    row = idx // alignment.shape[1]\n",
    "    col = idx % alignment.shape[1]\n",
    "    prob = flat_alignment[idx]\n",
    "    print(f\"({row}, {col}) -> {french_words[row]}, {english_words[col]}, prob: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0BxnOJJ2xhIZ",
   "metadata": {
    "id": "0BxnOJJ2xhIZ"
   },
   "source": [
    "1. What are the top 2 alignments shown in the figure?\n",
    "2. On the rows you see flat lines for `ciel` and `dans` and `licornes`, why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QUwdKXhZxqUP",
   "metadata": {
    "id": "QUwdKXhZxqUP"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "```\n",
    "1. Top 2 Alignments:\n",
    "    1. nuages - clouds\n",
    "    2. café, coffee\n",
    "\n",
    "2. The flat lines for ciel, dans, and licornes in the rows of the visualization occur because these words are not recognized by our tokenizer. \n",
    "Specifically, the punctuated forms \"ciel.\" and \"\\u200b\\u200bdans\", along with \"licornes\", are absent from our French dictionary (fr_dict). \n",
    "As a result, these words are assigned zero embeddings.\n",
    "\n",
    "When calculating the alignment between the French and English sentences, the corresponding rows for these unrecognized words contain only zeros. \n",
    "After applying the softmax function, which normalizes values across columns (because it was called with the axis 1), each cell in these rows gets an equal, small value (0.09090909090909091). \n",
    "This uniformity across the row creates the appearance of flat lines in the visualization.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C2TnQmsxy70i",
   "metadata": {
    "id": "C2TnQmsxy70i"
   },
   "source": [
    "####${\\color{red}{Comments\\ 3.1}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "cross-feedback comment section\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eqXwL4MpzW--",
   "metadata": {
    "id": "eqXwL4MpzW--"
   },
   "source": [
    "### Subtask 2: Scaled Dot-product\n",
    "Implement the scaled dot-product attention using the functions from above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8iQTr4KCzqZk",
   "metadata": {
    "id": "8iQTr4KCzqZk",
    "ExecuteTime": {
     "end_time": "2023-11-24T20:58:37.155951Z",
     "start_time": "2023-11-24T20:58:37.148444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 300)\n",
      "[[-0.0077802  -0.00345834 -0.01493142  0.05936939 -0.02286767 -0.00835552\n",
      "   0.00079745 -0.03737862  0.0270674   0.05374082]\n",
      " [-0.00777829 -0.00336843 -0.01498988  0.05937157 -0.02285948 -0.00835695\n",
      "   0.00085725 -0.03740797  0.02706951  0.05377672]]\n"
     ]
    }
   ],
   "source": [
    "def attention(queries, keys, values):\n",
    "    \"\"\"  scaled dot-product attention\n",
    "    queries: query matrix\n",
    "    keys: key matrix\n",
    "    value: value matrix\n",
    "    \"\"\"\n",
    "\n",
    "    weights = calc_weights(queries, keys)\n",
    "    attention = np.matmul(weights, values)\n",
    "    \n",
    "    return attention\n",
    "\n",
    "\n",
    "attention_result = attention(embedded_fr, embedded_en, embedded_en)\n",
    "print(attention_result.shape)\n",
    "print(attention_result[0:2,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vlwGjAWMy_OX",
   "metadata": {
    "id": "vlwGjAWMy_OX"
   },
   "source": [
    "####${\\color{red}{Comments\\ 3.2}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "cross-feedback comment section\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qDx8DrnVzAR1",
   "metadata": {
    "id": "qDx8DrnVzAR1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
