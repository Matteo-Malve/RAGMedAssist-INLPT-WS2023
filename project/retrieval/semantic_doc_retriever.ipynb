{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if6PoaZqnSUr",
        "outputId": "1462dea7-1f3f-435a-e27c-7c95d58be998"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain\n",
        "%pip install transformers\n",
        "%pip install sentence-transformers\n",
        "%pip install pinecone-client==2.2.4\n",
        "%pip install bitsandbytes\n",
        "%pip install pandas\n",
        "%pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab5Gf-08q_ZT",
        "outputId": "35979d3a-b842-4b0c-d1ff-0e5b496d859b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.2-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.14 (from langchain)\n",
            "  Downloading langchain_community-0.0.14-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.14 (from langchain)\n",
            "  Downloading langchain_core-0.1.14-py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.5/229.5 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.0.84,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.83-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.14->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.14->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.14->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.14->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.2 langchain-community-0.0.14 langchain-core-0.1.14 langsmith-0.0.83 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-3.0.1-py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.0/201.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2023.11.17)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.5.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Installing collected packages: pinecone-client\n",
            "Successfully installed pinecone-client-3.0.1\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "LqkyAMrnm5Ff"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from langchain_community.document_loaders.merge import MergedDataLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "import pinecone\n",
        "from langchain.vectorstores import Pinecone\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdKQyWoSm5Fh",
        "outputId": "a6791c22-3e86-41ae-fa69-42434f6539a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n",
            "746bacd9-6938-442e-a01f-61bb4cbd681b\n"
          ]
        }
      ],
      "source": [
        "# load environment variables from .env file\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "huggingface_token = os.environ.get('HF_AUTH')\n",
        "pinecone_token = os.environ.get('PINECONE_API_KEY')\n",
        "print(huggingface_token)\n",
        "print(pinecone_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTEB3Welm5Fi",
        "outputId": "5164882d-0081-43e3-b5a7-f297504a2229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58845\n",
            "Page Content: Abstract: SUMMARY Several lines of evidence support the involvement of inflammatory and immunologic abnormalities in chronic fatigue syndrome CFS Since recent studies have shown that α1 antitrypsin AAT possesses antiinflammatory properties the potential therapeutic effect of AAT treatment on CFS has been investigated A 49yearold woman diagnosed with CFS was treated with intravenous infusions of a human plasmaderived AAT concentrate 60 mgkg body weight weekly for 8 consecutive weeks The patients monocyte elastase a regulator of inflammatory processes was 1170 Umg At completion of treatment improvement in maximal workload was observed 540717 of predicted Additionally amelioration in working memory scores 8394 and perceptual organization scores 7583 were detected on the Wechsler Adult Intelligence ScaleIII test Monocyte elastase decreased to a normal range 150 Umg Improvement in functional capacity allowed the patient to work in parttime employment These findings suggest a possible role for AAT in the treatment of CFS\n",
            "Metadata: {'source': '/content/drive/MyDrive/processed_data_part1.csv', 'row': 0, 'PMID': '24645995', 'Title': 'α-1 antitrypsin and chronic fatigue syndrome: a case study from pathophysiology to clinical practice.', 'Authors': 'Jose Alegre Sandra Camprubi Ana GarciaQuintana', 'Publication Date': '2013-Mar', 'DOI': '10.2217/pmt.12.84'}\n"
          ]
        }
      ],
      "source": [
        "loader_1 = CSVLoader(\n",
        "    file_path='/content/drive/MyDrive/processed_data_part1.csv',\n",
        "    metadata_columns=['PMID', 'Title', 'Authors', 'Publication Date', 'DOI'])\n",
        "\n",
        "loader_2 = CSVLoader(\n",
        "    file_path='/content/drive/MyDrive/processed_data_part2.csv',\n",
        "    metadata_columns=['PMID', 'Title', 'Authors', 'Publication Date', 'DOI'])\n",
        "\n",
        "loader_all = MergedDataLoader(loaders=[loader_1, loader_2])\n",
        "docs_all = loader_all.load()\n",
        "\n",
        "print(len(docs_all))\n",
        "print(\"Page Content:\", docs_all[0].page_content)\n",
        "print(\"Metadata:\", docs_all[0].metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "0MfXAnOtm5Fi"
      },
      "outputs": [],
      "source": [
        "# Tokenize input text with BioBERT\n",
        "model_id = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# # Tokenize input text with Llama-2\n",
        "# model_id = 'meta-llama/Llama-2-13b-chat-hf'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_id, token=os.environ.get('HF_AUTH'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "oyxbkqBOm5Fj"
      },
      "outputs": [],
      "source": [
        "def token_len(text):\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  tokens_length = len(tokens)\n",
        "\n",
        "  return tokens_length\n",
        "\n",
        "# token_counts = [token_len(doc.page_content) for doc in docs_all]\n",
        "\n",
        "# min_tokens = np.min(token_counts)\n",
        "# avg_tokens = np.average(token_counts)\n",
        "# max_tokens = np.max(token_counts)\n",
        "\n",
        "# print(f\"\"\"Min: {min_tokens}\n",
        "# Avg: {avg_tokens}\n",
        "# Max: {max_tokens}\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW7Fr-OGm5Fj"
      },
      "source": [
        "Idea: since shortest doc is only 3 tokens - should we discard all docs containing... less than e.g. 15 tokens?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "J8mbqOX6m5Fk"
      },
      "outputs": [],
      "source": [
        "# Apply text splitting into chunks to prevent truncation of longer abstracts\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512,              #target size for each chunk of text\n",
        "                                               chunk_overlap=100,            #specifies how much overlap there should be between consecutive chunks\n",
        "                                               length_function=token_len,   #counts the number of characters in the text using the token_len function\n",
        "                                               is_separator_regex=False,)   #whether the splitter should treat the separators as regular expressions\n",
        "\n",
        "# chunks = text_splitter.split_documents(docs_all)\n",
        "\n",
        "# print(len(chunks))\n",
        "# print(token_len(chunks[0]))\n",
        "# chunks[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HURru7iYm5Fm"
      },
      "outputs": [],
      "source": [
        "# Try out SentenceTransformersTokenTextSplitter:\n",
        "# splits the text into chunks that fit the token window of the sentence transformer model\n",
        "\n",
        "# from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
        "\n",
        "# splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0)\n",
        "\n",
        "# count_start_and_stop_tokens = 2\n",
        "# text = \"Lorem \"\n",
        "# text_token_count = splitter.count_tokens(text=text) - count_start_and_stop_tokens\n",
        "# print(text_token_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U9RfE6Nm5Fk",
        "outputId": "eb113fd7-cea8-462a-fde7-d54158ebc603"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60591"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# Assign unique IDs to the abstracts\n",
        "chunked_docs = []\n",
        "\n",
        "for doc in docs_all:\n",
        "    pmid = doc.metadata['PMID']\n",
        "    chunks = text_splitter.split_text(doc.page_content)\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk_id = f\"{pmid}-{i}\"\n",
        "        chunked_docs.append({\n",
        "            'chunk_id': chunk_id,\n",
        "            'Abstract':chunk,\n",
        "            'Metadata':{\n",
        "                'PMID': pmid,\n",
        "                'Title': doc.metadata['Title'],\n",
        "                'Authors': doc.metadata['Authors'],\n",
        "                'Publication Date': doc.metadata['Publication Date'],\n",
        "                'DOI': doc.metadata['DOI']\n",
        "            }\n",
        "        })\n",
        "\n",
        "len(chunked_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gevp8ZG_m5Fk",
        "outputId": "3496c478-9af1-475e-f24d-ecf712a0f6d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chunk_id': '24505723-0',\n",
              " 'Abstract': 'Abstract: Human brain connectivity can be studied using graph theory Many connectivity studies parcellate the brain into regions and count fibres extracted between them The resulting network analyses require validation of the tractography as well as region and parameter selection Here we investigate whole brain connectivity from a different perspective We propose a mathematical formulation based on studying the eigenvalues of the Laplacian matrix of the diffusion tensor field at the voxel level This voxelwise matrix has over a million parameters but we derive the Kirchhoff complexity and eigenspectrum through elegant mathematical theorems without heavy computation We use these novel measures to accurately estimate the voxelwise connectivity in multiple biomedical applications such as Alzheimers disease and intelligence prediction',\n",
              " 'Metadata': {'PMID': '24505723',\n",
              "  'Title': \"Voxelwise spectral diffusional connectivity and its applications to Alzheimer's disease and intelligence prediction.\",\n",
              "  'Authors': 'Junning Li Yan Jin Yonggang Shi Ivo D Dinov Danny J Wang Arthur W Toga Paul M Thompson',\n",
              "  'Publication Date': '2013',\n",
              "  'DOI': '10.1007/978-3-642-40811-3_82'}}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "chunked_docs[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "xamj6qNTm5Fl",
        "outputId": "28c0198d-e33b-4ee0-ee84-526baa311a58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     chunk_id  \\\n",
              "0  24645995-0   \n",
              "1  24565439-0   \n",
              "2  24505723-0   \n",
              "3  24472488-0   \n",
              "4  24460364-0   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Abstract  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Abstract: SUMMARY Several lines of evidence support the involvement of inflammatory and immunologic abnormalities in chronic fatigue syndrome CFS Since recent studies have shown that α1 antitrypsin AAT possesses antiinflammatory properties the potential therapeutic effect of AAT treatment on CFS has been investigated A 49yearold woman diagnosed with CFS was treated with intravenous infusions of a human plasmaderived AAT concentrate 60 mgkg body weight weekly for 8 consecutive weeks The patients monocyte elastase a regulator of inflammatory processes was 1170 Umg At completion of treatment improvement in maximal workload was observed 540717 of predicted Additionally amelioration in working memory scores 8394 and perceptual organization scores 7583 were detected on the Wechsler Adult Intelligence ScaleIII test Monocyte elastase decreased to a normal range 150 Umg Improvement in functional capacity allowed the patient to work in parttime employment These findings suggest a possible role for AAT in the treatment of CFS   \n",
              "1  Abstract: Acute inflammation is a severe medical condition defined as an inflammatory response of the body to an infection Its rapid progression requires quick and accurate decisions from clinicians Inadequate and delayed decisions makes acute inflammation the 10th leading cause of death overall in United States with the estimated cost of treatment about 17 billion annually However despite the need there are limited number of methods that could assist clinicians to determine optimal therapies for acute inflammation We developed a datadriven method for suggesting optimal therapy by using machine learning model that is learned on historical patients behaviors To reduce both the risk of failure and the expense for clinical trials our method is evaluated on a virtual patients generated by a mathematical model that emulates inflammatory response In conducted experiments acute inflammation was handled with two complimentary pro and antiinflammatory medications which adequate timing and doses are crucial for the successful outcome Our experiments show that the dosage regimen assigned with our datadriven method significantly improves the percentage of healthy patients when compared to results by other methods used in clinical practice and found in literature Our method saved 88 of patients that would otherwise die within a week while the best method found in literature saved only 73 of patients At the same time our method used lower doses of medications than alternatives In addition our method achieved better results than alternatives when only incomplete or noisy measurements were available over time as well as it was less affected by therapy delay The presented results provide strong evidence that models from the artificial intelligence community have a potential for development of personalized treatment strategies for acute inflammation   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Abstract: Human brain connectivity can be studied using graph theory Many connectivity studies parcellate the brain into regions and count fibres extracted between them The resulting network analyses require validation of the tractography as well as region and parameter selection Here we investigate whole brain connectivity from a different perspective We propose a mathematical formulation based on studying the eigenvalues of the Laplacian matrix of the diffusion tensor field at the voxel level This voxelwise matrix has over a million parameters but we derive the Kirchhoff complexity and eigenspectrum through elegant mathematical theorems without heavy computation We use these novel measures to accurately estimate the voxelwise connectivity in multiple biomedical applications such as Alzheimers disease and intelligence prediction   \n",
              "3                                                                                                  Abstract: Human lifespan is positively correlated with childhood intelligence as measured by psychometric IQ tests The strength of this correlation is similar to the negative effect that smoking has on the life course This result suggests that people who perform well on psychometric tests in childhood may remain healthier and live longer The correlation however is debated is it caused exclusively by socialenvironmental factors or could it also have a biological component Biological traits of systems integrity that might result in correlations between brain function and lifespan have been suggested but are not wellestablished and it is questioned what useful knowledge can come from understanding such mechanisms In a recent study we found a positive correlation between brain function and longevity in honey bees Honey bees are highly social but relevant socialenvironmental factors that contribute to cognitionsurvival correlations in humans are largely absent from insect colonies Our results therefore suggest a biological explanation for the correlation in the bee Here we argue that individual differences in stress handling coping mechanisms which both affect the bees performance in tests of brain function and their survival could be a trait of systems integrity Individual differences in coping are much studied in vertebrates and several species provide attractive models Here we discuss how pigs are an interesting model for studying behavioural physiological and molecular mechanisms that are recruited during stress and that can drive correlations between health cognition and longevity traits By revealing biological factors that make individuals susceptible to stress it might be possible to alleviate health and longevity disparities in people   \n",
              "4                                                            Abstract: Physicians in order to study the causes of cancer detect cancer earlier prevent or determine the effectiveness of treatment and specify the reasons for the treatment ineffectiveness need to access accurate comprehensive and timely cancer data The cancer care environment has become more complex because of the need for coordination and communication among health care professionals with different skills in a variety of roles and the existence of large amounts of data with various formats The goals of health care systems in such a complex environment are correct health data management providing appropriate information needs of users to enhance the integrity and quality of health care timely access to accurate information and reducing medical errors These roles in new systems with use of agents efficiently perform well Because of the potential capability of agent systems to solve complex and dynamic health problems health care system in order to gain full advantage of E health steps must be taken to make use of this technology Multiagent systems have effective roles in health service quality improvement especially in telemedicine emergency situations and management of chronic diseases such as cancer In the design and implementation of agent based systems planning items such as information confidentiality and privacy architecture communication standards ethical and legal aspects identification opportunities and barriers should be considered It should be noted that usage of agent systems only with a technical view is associated with many problems such as lack of user acceptance The aim of this commentary is to survey applications opportunities and barriers of this new artificial intelligence tool for cancer care information as an approach to improve cancer care management   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                        Metadata  \n",
              "0                                                                {'PMID': '24645995', 'Title': 'α-1 antitrypsin and chronic fatigue syndrome: a case study from pathophysiology to clinical practice.', 'Authors': 'Jose Alegre Sandra Camprubi Ana GarciaQuintana', 'Publication Date': '2013-Mar', 'DOI': '10.2217/pmt.12.84'}  \n",
              "1                                                                                                                  {'PMID': '24565439', 'Title': 'A data-driven acute inflammation therapy.', 'Authors': 'Vladan Radosavljevic Kosta Ristovski Zoran Obradovic', 'Publication Date': '2013', 'DOI': '10.1186/1755-8794-6-S3-S7'}  \n",
              "2  {'PMID': '24505723', 'Title': 'Voxelwise spectral diffusional connectivity and its applications to Alzheimer's disease and intelligence prediction.', 'Authors': 'Junning Li Yan Jin Yonggang Shi Ivo D Dinov Danny J Wang Arthur W Toga Paul M Thompson', 'Publication Date': '2013', 'DOI': '10.1007/978-3-642-40811-3_82'}  \n",
              "3                                                                                                              {'PMID': '24472488', 'Title': 'Systems integrity in health and aging - an animal model approach.', 'Authors': 'Marije Oostindjer Gro V Amdam', 'Publication Date': '2013-Jan-07', 'DOI': '10.1186/2046-2395-2-2'}  \n",
              "4                                                                             {'PMID': '24460364', 'Title': 'Multi-agent systems: effective approach for cancer care information management.', 'Authors': 'Niloofar Mohammadzadeh Reza Safdari Azin Rahimi', 'Publication Date': '2013', 'DOI': '10.7314/apjcp.2013.14.12.7757'}  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3759f28f-8752-407a-b98f-5781d8772f9e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunk_id</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24645995-0</td>\n",
              "      <td>Abstract: SUMMARY Several lines of evidence support the involvement of inflammatory and immunologic abnormalities in chronic fatigue syndrome CFS Since recent studies have shown that α1 antitrypsin AAT possesses antiinflammatory properties the potential therapeutic effect of AAT treatment on CFS has been investigated A 49yearold woman diagnosed with CFS was treated with intravenous infusions of a human plasmaderived AAT concentrate 60 mgkg body weight weekly for 8 consecutive weeks The patients monocyte elastase a regulator of inflammatory processes was 1170 Umg At completion of treatment improvement in maximal workload was observed 540717 of predicted Additionally amelioration in working memory scores 8394 and perceptual organization scores 7583 were detected on the Wechsler Adult Intelligence ScaleIII test Monocyte elastase decreased to a normal range 150 Umg Improvement in functional capacity allowed the patient to work in parttime employment These findings suggest a possible role for AAT in the treatment of CFS</td>\n",
              "      <td>{'PMID': '24645995', 'Title': 'α-1 antitrypsin and chronic fatigue syndrome: a case study from pathophysiology to clinical practice.', 'Authors': 'Jose Alegre Sandra Camprubi Ana GarciaQuintana', 'Publication Date': '2013-Mar', 'DOI': '10.2217/pmt.12.84'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24565439-0</td>\n",
              "      <td>Abstract: Acute inflammation is a severe medical condition defined as an inflammatory response of the body to an infection Its rapid progression requires quick and accurate decisions from clinicians Inadequate and delayed decisions makes acute inflammation the 10th leading cause of death overall in United States with the estimated cost of treatment about 17 billion annually However despite the need there are limited number of methods that could assist clinicians to determine optimal therapies for acute inflammation We developed a datadriven method for suggesting optimal therapy by using machine learning model that is learned on historical patients behaviors To reduce both the risk of failure and the expense for clinical trials our method is evaluated on a virtual patients generated by a mathematical model that emulates inflammatory response In conducted experiments acute inflammation was handled with two complimentary pro and antiinflammatory medications which adequate timing and doses are crucial for the successful outcome Our experiments show that the dosage regimen assigned with our datadriven method significantly improves the percentage of healthy patients when compared to results by other methods used in clinical practice and found in literature Our method saved 88 of patients that would otherwise die within a week while the best method found in literature saved only 73 of patients At the same time our method used lower doses of medications than alternatives In addition our method achieved better results than alternatives when only incomplete or noisy measurements were available over time as well as it was less affected by therapy delay The presented results provide strong evidence that models from the artificial intelligence community have a potential for development of personalized treatment strategies for acute inflammation</td>\n",
              "      <td>{'PMID': '24565439', 'Title': 'A data-driven acute inflammation therapy.', 'Authors': 'Vladan Radosavljevic Kosta Ristovski Zoran Obradovic', 'Publication Date': '2013', 'DOI': '10.1186/1755-8794-6-S3-S7'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24505723-0</td>\n",
              "      <td>Abstract: Human brain connectivity can be studied using graph theory Many connectivity studies parcellate the brain into regions and count fibres extracted between them The resulting network analyses require validation of the tractography as well as region and parameter selection Here we investigate whole brain connectivity from a different perspective We propose a mathematical formulation based on studying the eigenvalues of the Laplacian matrix of the diffusion tensor field at the voxel level This voxelwise matrix has over a million parameters but we derive the Kirchhoff complexity and eigenspectrum through elegant mathematical theorems without heavy computation We use these novel measures to accurately estimate the voxelwise connectivity in multiple biomedical applications such as Alzheimers disease and intelligence prediction</td>\n",
              "      <td>{'PMID': '24505723', 'Title': 'Voxelwise spectral diffusional connectivity and its applications to Alzheimer's disease and intelligence prediction.', 'Authors': 'Junning Li Yan Jin Yonggang Shi Ivo D Dinov Danny J Wang Arthur W Toga Paul M Thompson', 'Publication Date': '2013', 'DOI': '10.1007/978-3-642-40811-3_82'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24472488-0</td>\n",
              "      <td>Abstract: Human lifespan is positively correlated with childhood intelligence as measured by psychometric IQ tests The strength of this correlation is similar to the negative effect that smoking has on the life course This result suggests that people who perform well on psychometric tests in childhood may remain healthier and live longer The correlation however is debated is it caused exclusively by socialenvironmental factors or could it also have a biological component Biological traits of systems integrity that might result in correlations between brain function and lifespan have been suggested but are not wellestablished and it is questioned what useful knowledge can come from understanding such mechanisms In a recent study we found a positive correlation between brain function and longevity in honey bees Honey bees are highly social but relevant socialenvironmental factors that contribute to cognitionsurvival correlations in humans are largely absent from insect colonies Our results therefore suggest a biological explanation for the correlation in the bee Here we argue that individual differences in stress handling coping mechanisms which both affect the bees performance in tests of brain function and their survival could be a trait of systems integrity Individual differences in coping are much studied in vertebrates and several species provide attractive models Here we discuss how pigs are an interesting model for studying behavioural physiological and molecular mechanisms that are recruited during stress and that can drive correlations between health cognition and longevity traits By revealing biological factors that make individuals susceptible to stress it might be possible to alleviate health and longevity disparities in people</td>\n",
              "      <td>{'PMID': '24472488', 'Title': 'Systems integrity in health and aging - an animal model approach.', 'Authors': 'Marije Oostindjer Gro V Amdam', 'Publication Date': '2013-Jan-07', 'DOI': '10.1186/2046-2395-2-2'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24460364-0</td>\n",
              "      <td>Abstract: Physicians in order to study the causes of cancer detect cancer earlier prevent or determine the effectiveness of treatment and specify the reasons for the treatment ineffectiveness need to access accurate comprehensive and timely cancer data The cancer care environment has become more complex because of the need for coordination and communication among health care professionals with different skills in a variety of roles and the existence of large amounts of data with various formats The goals of health care systems in such a complex environment are correct health data management providing appropriate information needs of users to enhance the integrity and quality of health care timely access to accurate information and reducing medical errors These roles in new systems with use of agents efficiently perform well Because of the potential capability of agent systems to solve complex and dynamic health problems health care system in order to gain full advantage of E health steps must be taken to make use of this technology Multiagent systems have effective roles in health service quality improvement especially in telemedicine emergency situations and management of chronic diseases such as cancer In the design and implementation of agent based systems planning items such as information confidentiality and privacy architecture communication standards ethical and legal aspects identification opportunities and barriers should be considered It should be noted that usage of agent systems only with a technical view is associated with many problems such as lack of user acceptance The aim of this commentary is to survey applications opportunities and barriers of this new artificial intelligence tool for cancer care information as an approach to improve cancer care management</td>\n",
              "      <td>{'PMID': '24460364', 'Title': 'Multi-agent systems: effective approach for cancer care information management.', 'Authors': 'Niloofar Mohammadzadeh Reza Safdari Azin Rahimi', 'Publication Date': '2013', 'DOI': '10.7314/apjcp.2013.14.12.7757'}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3759f28f-8752-407a-b98f-5781d8772f9e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3759f28f-8752-407a-b98f-5781d8772f9e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3759f28f-8752-407a-b98f-5781d8772f9e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-36944b08-ddb5-4de2-9190-8099019ed6ed\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36944b08-ddb5-4de2-9190-8099019ed6ed')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-36944b08-ddb5-4de2-9190-8099019ed6ed button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "data = pd.DataFrame(chunked_docs)\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "YQoCAu5xm5Fl"
      },
      "outputs": [],
      "source": [
        "#Save chunked data\n",
        "data.to_csv('/content/drive/MyDrive/chunked_BioBERT_texts.csv', index=False)\n",
        "\n",
        "#Load chunked data\n",
        "#pd.set_option('display.max_colwidth', None)\n",
        "#data = pd.read_csv('/content/drive/MyDrive/chunked_BioBERT_texts.csv')\n",
        "#data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RuQj1e5m5Fm",
        "outputId": "3b49a283-12ae-4372-a2fe-0b8dd5be77dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Check device\n",
        "has_gpu = torch.cuda.is_available()\n",
        "has_mps = torch.backends.mps.is_built()\n",
        "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy9LJCMdm5Fm",
        "outputId": "5d08b551-8e20-4ba0-eed0-3beec4445c0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/dmis-lab_biobert-base-cased-v1.1. Creating a new one with MEAN pooling.\n"
          ]
        }
      ],
      "source": [
        "# Generate embeddings and store them in vector database\n",
        "docs = [\n",
        "    \"An example document\",\n",
        "    \"A second document as an example\"\n",
        "]\n",
        "\n",
        "#hf_auth_key = os.environ.get('HF_AUTH')\n",
        "model_kwargs = {'device': device}\n",
        "encode_kwargs = {'normalize_embeddings': True}\n",
        "\n",
        "embed_model = HuggingFaceEmbeddings(\n",
        "    model_name=model_id,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_embeddings = embed_model.embed_documents(docs)\n",
        "\n",
        "print(\"number of docs:\",len(test_embeddings))\n",
        "print(\"dimension of docs:\",len(test_embeddings[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoBodxd_uhWA",
        "outputId": "1788ca57-8cd6-43fe-ba21-de76a66c840a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of docs: 2\n",
            "dimension of docs: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Pinecone env\n",
        "pinecone.init(api_key=pinecone_token, environment=\"gcp-starter\")"
      ],
      "metadata": {
        "id": "BpOcXNDS9Xry"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"rag-biobert\"\n",
        "\n",
        "try:\n",
        "  if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(name=index_name, dimension=len(test_embeddings[0]), metric=\"cosine\", shards=1)\n",
        "    index = pinecone.Index(index_name=index_name)\n",
        "except Exception as e:\n",
        "  print(f\"Error initializing Pinecone index: {e}\")\n",
        "  print(f\"Index: {pinecone.list_indexes()}\")"
      ],
      "metadata": {
        "id": "bSnPh2z2v6OT"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = pinecone.Index(index_name)\n",
        "index.describe_index_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptPmFvlO-b0L",
        "outputId": "8c2c6e3e-e139-4b7f-df65-3cfefb9a371f"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 768,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload data in batches\n",
        "batch_size = 32\n",
        "\n",
        "for i in tqdm(range(0, len(data), batch_size)):\n",
        "    batch = data.iloc[i:i+batch_size]\n",
        "\n",
        "    ids = batch[\"chunk_id\"].tolist()\n",
        "    texts = batch[\"Abstract\"].tolist()\n",
        "    metadata = [{'text': text} for text in texts]   #later we'll need to maybe include more metadata\n",
        "\n",
        "    embeddings = embed_model.embed_documents(texts)\n",
        "\n",
        "    # Format data for indexing and upsert\n",
        "    index.upsert(vectors=zip(ids, embeddings, metadata))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV4VZn4szBzF",
        "outputId": "50c41be8-d39a-4d6e-cf61-2f93ff768b1e"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1894/1894 [40:14<00:00,  1.27s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem: Pinecone does not offer enough space"
      ],
      "metadata": {
        "id": "cZEcIImzg3vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index.describe_index_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epK2ZXWgu5Pd",
        "outputId": "92fc6b00-ec5d-4bca-bc21-00372b9793a8"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 768,\n",
              " 'index_fullness': 0.60589,\n",
              " 'namespaces': {'': {'vector_count': 60589}},\n",
              " 'total_vector_count': 60589}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve relevant chunks\n",
        "vectorstore = Pinecone.from_existing_index(index_name, embed_model)\n",
        "\n",
        "query = \"behavioral intelligence\"\n",
        "\n",
        "#relevant_docs = vectorstore.max_marginal_relevance_search(query, k=3, fetch_k=10)\n",
        "relevant_docs = vectorstore.similarity_search(query, k=3)\n",
        "\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"{i + 1}.\", doc.page_content, \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aljRIEkRPAOH",
        "outputId": "e0bdbe4d-704a-486a-d108-76577f61c02b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Abstract: Clinical thoughts for In the Media \n",
            "\n",
            "2. Abstract: NA \n",
            "\n",
            "3. Abstract: Regarding Dr Makaryuss interesting review study \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantization (will be relevant when laoding a chat model for generation)\n",
        "\n",
        "bitsAndBites_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,                  #enables 4-bit quantization\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,      #sets computation to bfloat16 for speedups\n",
        "    bnb_4bit_quant_type=\"fp4\",          #sets the quantization data type to FP4\n",
        "    bnb_4bit_use_double_quant=True,     #enables nested quantization\n",
        ")"
      ],
      "metadata": {
        "id": "apdRABlYOtuu"
      },
      "execution_count": 37,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}