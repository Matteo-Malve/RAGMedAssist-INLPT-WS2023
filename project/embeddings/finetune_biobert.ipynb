{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "from datasets import DatasetDict, load_dataset, Dataset\n",
    "\n",
    "\n",
    "path_to_data_folder=\"/Users/matteom/shared-folder/nlpt_group/project/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Abstract\n",
      "0  SUMMARY Several lines of evidence support the ...\n",
      "1  Acute inflammation is a severe medical conditi...\n",
      "2  Human brain connectivity can be studied using ...\n"
     ]
    }
   ],
   "source": [
    "# Read in abstracts\n",
    "df_part1 = pd.read_csv(os.path.join(path_to_data_folder,\"processed_data_part1.csv\"))\n",
    "df_part2 = pd.read_csv(os.path.join(path_to_data_folder,\"processed_data_part2.csv\"))\n",
    "df=pd.concat([df_part1,df_part2])\n",
    "abstracts = df[['Abstract']] #.tolist()\n",
    "print(abstracts[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Abstract', '__index_level_0__'],\n",
       "    num_rows: 58849\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts = abstracts.dropna()\n",
    "abstracts_dataset = Dataset.from_pandas(abstracts)\n",
    "abstracts_dataset.set_format(\"torch\")\n",
    "abstracts_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained tokenizer for BioBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['Abstract', '__index_level_0__'],\n",
       " 'val': ['Abstract', '__index_level_0__']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split=int(np.floor(0.7*len(abstracts)))\n",
    "\n",
    "# Take 70% of abstracts for train and 30% for validation\n",
    "abstracts_dataset_dict = DatasetDict(\n",
    "    train=abstracts_dataset.shuffle(seed=19).select(range(split)),\n",
    "    val=abstracts_dataset.shuffle(seed=19).select(range(split, len(abstracts))),\n",
    ")\n",
    "abstracts_dataset_dict.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abstract': ['Radiomics is a newcomer field that has opened new windows for precision medicine It is related to extraction of a large number of quantitative features from medical images which may be difficult to detect visually Underlying tumor biology can change physical properties of tissues which affect patterns of image pixels and radiomics features The main advantage of radiomics is that it can characterize the whole tumor noninvasively even after a single sampling from an image Therefore it can be linked to a digital biopsy Physicians need to know about radiomics features to determine how their values correlate with the appearance of lesions and diseases Indeed physicians need practical references to conceive of basics and concepts of each radiomics feature without knowing their sophisticated mathematical formulas In this review commonly used radiomics features are illustrated with practical examples to help physicians in their routine diagnostic procedures',\n",
       "  'Lignocellulosic biomass is mainly composed of cellulose hemicellulose and lignin Fuzzy logic in turn is a branch of manyvalued logic based on the paradigm of inference under vagueness This paper presents a methodology based on computational intelligence for modeling the kinetics of a complex reactional system The design of a fuzzy interpolator to model cellulose hydrolysis is reported within the perspective of applying kinetic models in bioreactor engineering Experimental data for various types of lignocellulosic materials were used to develop the interpolator New experimental data from the enzymatic hydrolysis of a synthetic substrate on the other hand were used to validate the methodology The accuracy of the results indicates that this is a promising approach to extend the application of models fitted for specific situations to different cases thus enhancing their generality',\n",
       "  'Accurate early detection of the human papillomavirus HPV status in head and neck cancer HNC is crucial to identify atrisk populations stratify patients personalized treatment options and predict prognosis Artificial intelligence AI is an emerging tool to dissect imaging features This systematic review and metaanalysis aimed to evaluate the performance of AI to predict the HPV positivity through the HPVassociated diseased images in HNC patients A systematic literature search was conducted in databases including OvidMEDLINE Embase and Web of Science Core Collection for studies continuously published from inception up to October 30 2022 Search strategies included keywords such as artificial intelligence head and neck cancer HPV and sensitivity specificity Duplicates articles without HPV predictions letters scientific reports conference abstracts or reviews were excluded Binary diagnostic data were then extracted to generate contingency tables and then used to calculate the pooled sensitivity SE specificity SP area under the curve AUC and their 95 confidence interval CI A randomeffects model was used for metaanalysis four subgroup analyses were further explored Totally 22 original studies were included in the systematic review 15 of which were eligible to generate 33 contingency tables for metaanalysis The pooled SE and SP for all studies were 79 95 CI 7582 and 74 95 CI 6978 respectively with an AUC of 083 95 CI 079086 When only selecting one contingency table with the highest accuracy from each study our analysis revealed a pooled SE of 79 95 CI 7583 SP of 75 95 CI 6979 and an AUC of 084 95 CI 081087 The respective heterogeneities were moderate Isup2sup for SE and SP were 5170 and 5101 and only low 3599 and 2144 This evidencebased study showed an acceptable and promising performance for AI algorithms to predict HPV status in HNC but was not comparable to the routine p16 immunohistochemistry The exploitation and optimization of AI algorithms warrant further research Compared with previous studies future studies anticipate to make progress in the selection of databases improvement of international reporting guidelines and application of highquality deep learning algorithms'],\n",
       " '__index_level_0__': tensor([29191,  2446, 23827])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts_dataset_dict['train'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dd97deff62446fb0cf41ba6dcd48c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/41194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4478673d67654f528d322ad3af61bfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/17655 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Abstract', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 41194\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['Abstract', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 17655\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_abstracts = abstracts_dataset_dict.map(\n",
    "    lambda example: tokenizer(example['Abstract'], return_tensors=\"pt\", truncation=True, padding=True, max_length=512),\n",
    "    batched=True,  #so the function is applied to multiple elements of our dataset at once, and not on each element separately,\n",
    "    batch_size=16,\n",
    "    num_proc=4# number of workers\n",
    ")\n",
    "tokenized_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_abstracts['train'], batch_size=16)\n",
    "eval_dataloader = DataLoader(tokenized_abstracts['val'], batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Load pretrained BioBert model\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\")\n",
    "\n",
    "arguments = TrainingArguments(\n",
    "    output_dir=\"abstracts_trainer\", #where to save the logs and checkpoints\n",
    "    per_device_train_batch_size=16,# batch size per GPU or CPU\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    evaluation_strategy=\"epoch\",# steps\" (evaluate every eval_steps) or \"epoch\" (evaluate at the end of each epoch)\n",
    "    save_strategy=\"epoch\", # save the model at the end of each epoch\n",
    "    learning_rate=2e-5,\n",
    "    load_best_model_at_end=True, # the best model based on the metric\n",
    "    seed=224,\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "# I got crash error:\n",
    "# The Kernel crashed while executing code in the the current cell or a previous cell.\n",
    "# It happens when I call the import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Called at the end of validation. Gives accuracy\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # calculates the accuracy\n",
    "    return {\"accuracy\": np.mean(predictions == labels)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=arguments,\n",
    "    train_dataset=abstracts_dataset_dict['train'],\n",
    "    eval_dataset=abstracts_dataset_dict['val'], # change to test when you do your final evaluation!\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
