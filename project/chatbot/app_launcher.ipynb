{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Locally (VScode)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.223:8501\u001b[0m\n","\u001b[0m\n","\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n","\n","  $ xcode-select --install\n","  $ pip install watchdog\n","            \u001b[0m\n","/Users/matteom/miniconda3/envs/torch/lib/python3.9/site-packages/langchain/__init__.py:29: UserWarning: Importing HuggingFacePipeline from langchain root module is no longer supported. Please use langchain_community.llms.huggingface_pipeline.HuggingFacePipeline instead.\n","  warnings.warn(\n","/Users/matteom/miniconda3/envs/torch/lib/python3.9/site-packages/langchain/retrievers/__init__.py:46: LangChainDeprecationWarning: Importing this retriever from langchain is deprecated. Importing it from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n","\n","`from langchain_community.retrievers import BM25Retriever`.\n","\n","To install langchain-community run `pip install -U langchain-community`.\n","  warnings.warn(\n","cuda is available: False\n","mps is available: True\n","LLaMA ERROR: The prompt is 2571 tokens and the context window is 2048!\n","^C\n","\u001b[34m  Stopping...\u001b[0m\n"]}],"source":["!streamlit run app.py"]},{"cell_type":"markdown","metadata":{},"source":["### Colab:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oQEkQX656yuy","outputId":"0f13cffd-819f-4c67-d28d-c984e2cdfb81"},"outputs":[],"source":["%pip install xformer --quiet\n","%pip install langchain --quiet\n","%pip install accelerate --quiet\n","%pip install git+https://github.com/huggingface/transformers --quiet\n","%pip install bitsandbytes --quiet\n","%pip install unstructured --quiet\n","%pip install sentence-transformers --quiet\n","%pip install -U faiss-gpu tiktoken\n","%pip install langchainhub --quiet\n","%pip install streamlit -quiet\n","!pip install streamlit-chat --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C9-Tvndw6QLk"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/nlp_project/chatbot"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":419518,"status":"ok","timestamp":1708007453820,"user":{"displayName":"Seed 19","userId":"12712001482791270809"},"user_tz":-60},"id":"rjmmkXGm5nc8","outputId":"ec528bd8-0dda-42ce-f060-c7e1b0ca8c4f"},"outputs":[],"source":["!wget -q -O - ipv4.icanhazip.com\n","!streamlit run app.py & npx localtunnel --port 8501"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNEPMt/JiOkBBFnHAMU0nxR","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
