retrievers:
  bm25 :
      topk: 4
      path: "chunked_docs.pkl"

  faiss :
      faiss_index_path: "faiss_indices/"
      search_type: "similarity_score_threshold"
      score_threshold: 0.77
      topk: 4

#  pinecone :
#      index_name: "pubmed"
#      search_type: "similarity_score_threshold"
#      score_threshold: 0.88  # sim. scores are higher on pinecone compared to on faiss
#      topk: 4


ensemble:
  weights:
    - 0.4
    - 0.6


llm_model:
  name: "mistralai/Mistral-7B-Instruct-v0.1"
  local_path: ""
  #  local_path: "/Users/yusuf/Library/Application Support/nomic.ai/GPT4All/gpt4all-falcon-newbpe-q4_0.gguf" (example)
  #  Provide the local path only if you have downloaded the model using GPT4ALL on your device
  temperature: 0.001
  top_p: 0.95
  repetition_penalty: 1.15


embedding_model: "thenlper/gte-base"

use_qa_chain: True
use_conversational_qa_chain: True
use_multi_query_qa_chain: True

conversational_chain:
  conversation_depth: 2  # The number of recent query-answer pairs to consider for generating the response
