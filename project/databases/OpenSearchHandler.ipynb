{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to serve as interface with Opensearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contributions:\n",
    "- Matteo: \\\n",
    "-- Docker Setup \\\n",
    "-- Task oriented completions of the script \\\n",
    "-- Loading of data on OpenSearch. \n",
    "- Yusuf: \\\n",
    "-- Solving issue of connection with curl, switching to python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and basic definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opensearch-py\n",
    "from opensearchpy import OpenSearch, helpers\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path_to_data_folder=\"/Users/matteom/shared-folder/nlpt_group/project/data\"          # <======================\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenSearchHandler:\n",
    "    def __init__(self, host='localhost', port='9200', username='admin', password='admin', index_name='pubmed_data'):\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.index_name = index_name\n",
    "        self.client = self.create_connection()\n",
    "\n",
    "    def create_connection(self):\n",
    "        return OpenSearch(\n",
    "            hosts=f\"https://{self.host}:{self.port}\",\n",
    "            http_auth=(self.username, self.password),\n",
    "            verify_certs=False  # Set to True if you have a valid SSL certificate\n",
    "        )\n",
    "\n",
    "    def create_index(self, index_body=None):\n",
    "        if not self.client.indices.exists(index=self.index_name):\n",
    "            self.client.indices.create(index=self.index_name, body=index_body)\n",
    "        else:\n",
    "            print(\"It has already been created\")\n",
    "\n",
    "    def generate_data(self, df):\n",
    "        for _, row in df.iterrows():\n",
    "            yield {\n",
    "                \"_index\": self.index_name,\n",
    "                \"_source\": row.to_dict(),\n",
    "            }\n",
    "\n",
    "    def bulk_upload(self, df):\n",
    "        helpers.bulk(self.client, self.generate_data(df))\n",
    "        print(\"Data uploaded to OpenSearch successfully.\")\n",
    "\n",
    "    def search(self, query):\n",
    "        response = self.client.search(index=self.index_name, body=query)\n",
    "        for doc in response['hits']['hits']:\n",
    "            print(doc['_source'])\n",
    "        return response\n",
    "\n",
    "    @staticmethod\n",
    "    def response_to_dataframe(response):\n",
    "        # Extract data from response\n",
    "        data = [doc['_source'] for doc in response['hits']['hits']]\n",
    "        # Create a DataFrame\n",
    "        return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import DataFrames and define OpenSearchHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part1 = pd.read_csv(os.path.join(path_to_data_folder,\"processed_data_part1.csv\"))\n",
    "df_part2 = pd.read_csv(os.path.join(path_to_data_folder,\"processed_data_part2.csv\"))\n",
    "\n",
    "os_handler = OpenSearchHandler(index_name=\"pubmed_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility: Wipe out all documents fromo index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_query = {\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "}\n",
    "os_handler.client.delete_by_query(\"pubmed_data\",delete_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically create index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_handler.create_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last refinment of the DataFrame from previously escaped impurities due to csv conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part1.loc[df_part1['Abstract'].isnull(),'Abstract']='missing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload in two tranches the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_handler.bulk_upload(df_part1)\n",
    "os_handler.bulk_upload(df_part2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
